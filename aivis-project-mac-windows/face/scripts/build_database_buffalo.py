#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
buffalo_l ê¸°ë°˜ ì–¼êµ´ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
- InsightFace buffalo_l ëª¨ë¸ ì‚¬ìš© (ì–¼êµ´ ê°ì§€ + ì„ë² ë”© í†µí•©)
- ë‹¤ì–‘í•œ ì¡°ëª…/ê°ë„ ì¦ê°• í¬í•¨
"""

import os
import sys
import cv2
import numpy as np
import faiss
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(script_dir)
project_root = os.path.dirname(parent_dir)
sys.path.insert(0, project_root)

# ============================================================
# ì„¤ì •
# ============================================================
DB_PATH = os.path.join(parent_dir, "data", "images")  # ì–¼êµ´ ì´ë¯¸ì§€ í´ë”
FAISS_INDEX_FILE = os.path.join(project_root, "src", "backend", "face_index.faiss")
FAISS_LABELS_FILE = FAISS_INDEX_FILE + ".labels.npy"
AUGMENTED_IMAGES_DIR = os.path.join(parent_dir, "data", "augmented_buffalo")

# ì¦ê°• ëª¨ë“œ: "full" (23ì¢…), "balanced" (10ì¢…), "fast" (7ì¢…)
AUGMENTATION_MODE = "full"
SAVE_AUGMENTED_IMAGES = True

# í’ˆì§ˆ ì²´í¬
ENABLE_CLAHE = True
MIN_BLUR_VARIANCE = 40.0
MIN_BRIGHTNESS = 20.0
MAX_BRIGHTNESS = 235.0
MIN_FACE_SIZE = 30  # ìµœì†Œ ì–¼êµ´ í¬ê¸° (í”½ì…€)

# ëŒ€í‘œ ì„ë² ë”© ì„¤ì •
USE_REPRESENTATIVE_EMBEDDING = False  # False = ëª¨ë“  ì„ë² ë”© ì €ì¥ (ì¸ì‹ë¥  í–¥ìƒ)
TOP_N_PER_PERSON = 15


def is_low_quality(img: np.ndarray) -> bool:
    """í’ˆì§ˆ ì²´í¬: ë¸”ëŸ¬/ë°ê¸° ê¸°ì¤€"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        var = cv2.Laplacian(gray, cv2.CV_64F).var()
        mean_brightness = float(np.mean(gray))
        if var < MIN_BLUR_VARIANCE:
            return True
        if mean_brightness < MIN_BRIGHTNESS or mean_brightness > MAX_BRIGHTNESS:
            return True
        return False
    except Exception:
        return False


def apply_clahe_bgr(img: np.ndarray) -> np.ndarray:
    """Y ì±„ë„ CLAHEë¡œ ì¡°ëª… í‘œì¤€í™”"""
    if img is None or img.size == 0:
        return img
    try:
        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        ycrcb[:, :, 0] = clahe.apply(ycrcb[:, :, 0])
        return cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)
    except Exception:
        return img


def create_augmentations(img: np.ndarray, mode: str = "full") -> list:
    """
    ì´ë¯¸ì§€ ì¦ê°• ìƒì„±
    Returns: [(augmented_img, label), ...]
    """
    augmented = []
    h, w = img.shape[:2]
    
    # ê¸°ë³¸ ì¦ê°• (í•­ìƒ í¬í•¨)
    augmented.append((img, "original"))
    augmented.append((cv2.flip(img, 1), "flip"))
    
    # 90ë„ íšŒì „ (ë„˜ì–´ì§„ ì‚¬ëŒ ì¸ì‹ìš©)
    augmented.append((cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE), "rotate_90_cw"))
    augmented.append((cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE), "rotate_90_ccw"))
    
    if mode in ["full", "balanced"]:
        # ë°ê¸° ì¦ê°•
        augmented.append((cv2.convertScaleAbs(img, alpha=1.0, beta=30), "bright_+30"))
        augmented.append((cv2.convertScaleAbs(img, alpha=1.0, beta=-30), "bright_-30"))
        
        # ëŒ€ë¹„ ì¦ê°•
        augmented.append((cv2.convertScaleAbs(img, alpha=1.2, beta=0), "contrast_+1.2"))
        augmented.append((cv2.convertScaleAbs(img, alpha=0.8, beta=0), "contrast_0.8"))
        
        # ìƒ¤í”„ë‹
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        augmented.append((cv2.filter2D(img, -1, kernel), "sharpen"))
        
        # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
        yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
        augmented.append((cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR), "hist_equal"))
    
    if mode == "full":
        # ì¶”ê°€ ë°ê¸°
        augmented.append((cv2.convertScaleAbs(img, alpha=1.0, beta=45), "bright_+45"))
        augmented.append((cv2.convertScaleAbs(img, alpha=1.0, beta=-45), "bright_-45"))
        
        # ë¸”ëŸ¬
        augmented.append((cv2.GaussianBlur(img, (3, 3), 0), "blur"))
        
        # ì¹´ë©”ë¼ í•´ìƒë„ ì‹œë®¬ë ˆì´ì…˜
        if h > 400 or w > 400:
            for target, label in [(640, "cam_sim_640"), (480, "cam_sim_480")]:
                scale = target / max(h, w)
                new_h, new_w = int(h * scale), int(w * scale)
                down = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
                up = cv2.resize(down, (w, h), interpolation=cv2.INTER_LINEAR)
                augmented.append((up, label))
        
        # ===== ì¶”ê°€ ì¡°ëª… ì¦ê°• =====
        
        # ê°ë§ˆ ë³´ì • (ì‹¤ë‚´/ì‹¤ì™¸ ì¡°ëª… ì°¨ì´)
        for gamma_val, gamma_label in [(0.7, "gamma_0.7"), (1.5, "gamma_1.5"), (2.0, "gamma_2.0")]:
            inv_gamma = 1.0 / gamma_val
            table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            augmented.append((cv2.LUT(img, table), gamma_label))
        
        # ìƒ‰ì˜¨ë„ ë³€ê²½
        # ë”°ëœ»í•œ (ë°±ì—´ë“±)
        warm = img.copy()
        warm[:,:,2] = np.clip(warm[:,:,2] * 1.1, 0, 255).astype(np.uint8)
        warm[:,:,0] = np.clip(warm[:,:,0] * 0.9, 0, 255).astype(np.uint8)
        augmented.append((warm, "color_warm"))
        
        # ì°¨ê°€ìš´ (í˜•ê´‘ë“±)
        cool = img.copy()
        cool[:,:,0] = np.clip(cool[:,:,0] * 1.15, 0, 255).astype(np.uint8)
        cool[:,:,2] = np.clip(cool[:,:,2] * 0.85, 0, 255).astype(np.uint8)
        augmented.append((cool, "color_cool"))
        
        # ê·¸ë¦¼ì í•©ì„±
        # ì™¼ìª½ ê·¸ë¦¼ì
        shadow_left = img.copy().astype(np.float32)
        for col in range(w // 2):
            factor = 0.5 + (col / (w // 2)) * 0.5
            shadow_left[:, col] = shadow_left[:, col] * factor
        augmented.append((np.clip(shadow_left, 0, 255).astype(np.uint8), "shadow_left"))
        
        # ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì
        shadow_right = img.copy().astype(np.float32)
        for col in range(w // 2, w):
            factor = 1.0 - ((col - w // 2) / (w // 2)) * 0.5
            shadow_right[:, col] = shadow_right[:, col] * factor
        augmented.append((np.clip(shadow_right, 0, 255).astype(np.uint8), "shadow_right"))
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€ (ì €ì¡°ë„ ì‹œë®¬ë ˆì´ì…˜)
        noise_img = img.copy().astype(np.float32)
        noise = np.random.normal(0, 15, noise_img.shape).astype(np.float32)
        augmented.append((np.clip(noise_img + noise, 0, 255).astype(np.uint8), "noise_low_light"))
        
        noise_heavy = img.copy().astype(np.float32)
        noise2 = np.random.normal(0, 25, noise_heavy.shape).astype(np.float32)
        augmented.append((np.clip(noise_heavy + noise2, 0, 255).astype(np.uint8), "noise_very_low"))
    
    return augmented


def build_database():
    """buffalo_lì„ ì‚¬ìš©í•œ ì–¼êµ´ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"""
    print("=" * 60)
    print("ğŸ¦¬ buffalo_l ê¸°ë°˜ ì–¼êµ´ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±")
    print("=" * 60)
    print(f"ì´ë¯¸ì§€ í´ë”: {DB_PATH}")
    print(f"ì¦ê°• ëª¨ë“œ: {AUGMENTATION_MODE}")
    print(f"CLAHE ì ìš©: {ENABLE_CLAHE}")
    print("-" * 60)
    
    # buffalo_l ëª¨ë¸ ë¡œë“œ
    print("\nğŸ¦¬ buffalo_l ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        from insightface.app import FaceAnalysis
        face_analyzer = FaceAnalysis(
            name='buffalo_l',
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],
            allowed_modules=['detection', 'recognition']
        )
        face_analyzer.prepare(ctx_id=0, det_size=(640, 640))
        print("âœ… buffalo_l ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ buffalo_l ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # ì´ë¯¸ì§€ í´ë” í™•ì¸
    if not os.path.exists(DB_PATH):
        print(f"âŒ ì´ë¯¸ì§€ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {DB_PATH}")
        return
    
    # ì¸ë¬¼ë³„ í´ë” íƒìƒ‰
    person_folders = [f for f in os.listdir(DB_PATH) 
                      if os.path.isdir(os.path.join(DB_PATH, f))]
    
    if not person_folders:
        print(f"âŒ ì¸ë¬¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {DB_PATH}")
        return
    
    print(f"\nğŸ“ ë°œê²¬ëœ ì¸ë¬¼: {len(person_folders)}ëª…")
    for pf in person_folders:
        print(f"   - {pf}")
    
    # ì„ë² ë”© ì €ì¥ìš©
    all_embeddings = []
    all_labels = []
    stats = {"total_images": 0, "total_faces": 0, "failed": 0}
    
    # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í´ë”
    if SAVE_AUGMENTED_IMAGES:
        os.makedirs(AUGMENTED_IMAGES_DIR, exist_ok=True)
    
    # ê° ì¸ë¬¼ë³„ ì²˜ë¦¬
    for person_name in person_folders:
        person_path = os.path.join(DB_PATH, person_name)
        print(f"\nğŸ‘¤ ì²˜ë¦¬ ì¤‘: {person_name}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        image_files = [f for f in os.listdir(person_path) 
                       if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            print(f"   âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ")
            continue
        
        print(f"   ğŸ“· ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}")
        person_embeddings = []
        
        # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í´ë”
        if SAVE_AUGMENTED_IMAGES:
            person_aug_dir = os.path.join(AUGMENTED_IMAGES_DIR, person_name)
            os.makedirs(person_aug_dir, exist_ok=True)
        
        for img_file in image_files:
            img_path = os.path.join(person_path, img_file)
            stats["total_images"] += 1
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imdecode(np.fromfile(img_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if img is None:
                print(f"      âŒ ë¡œë“œ ì‹¤íŒ¨: {img_file}")
                stats["failed"] += 1
                continue
            
            # í’ˆì§ˆ ì²´í¬
            if is_low_quality(img):
                print(f"      âš ï¸ ì €í’ˆì§ˆ ìŠ¤í‚µ: {img_file}")
                continue
            
            # CLAHE ì ìš©
            if ENABLE_CLAHE:
                img = apply_clahe_bgr(img)
            
            # ì¦ê°• ìƒì„±
            augmented_images = create_augmentations(img, AUGMENTATION_MODE)
            
            # ê° ì¦ê°• ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê°ì§€ ë° ì„ë² ë”© ì¶”ì¶œ
            for aug_img, aug_label in augmented_images:
                try:
                    # buffalo_lë¡œ ì–¼êµ´ ê°ì§€ + ì„ë² ë”© ì¶”ì¶œ
                    faces = face_analyzer.get(aug_img)
                    
                    if not faces:
                        continue
                    
                    # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                    best_face = max(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]))
                    
                    # ì–¼êµ´ í¬ê¸° ì²´í¬
                    face_w = best_face.bbox[2] - best_face.bbox[0]
                    face_h = best_face.bbox[3] - best_face.bbox[1]
                    if face_w < MIN_FACE_SIZE or face_h < MIN_FACE_SIZE:
                        continue
                    
                    # ì„ë² ë”© ì¶”ì¶œ
                    embedding = best_face.embedding
                    if embedding is None:
                        continue
                    
                    # ì •ê·œí™”
                    embedding = embedding / np.linalg.norm(embedding)
                    person_embeddings.append(embedding)
                    stats["total_faces"] += 1
                    
                    # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥
                    if SAVE_AUGMENTED_IMAGES:
                        base_name = os.path.splitext(img_file)[0]
                        aug_path = os.path.join(person_aug_dir, f"{base_name}_{aug_label}.jpg")
                        cv2.imencode('.jpg', aug_img)[1].tofile(aug_path)
                        
                except Exception as e:
                    continue
        
        print(f"   âœ… ì¶”ì¶œëœ ì„ë² ë”©: {len(person_embeddings)}ê°œ")
        
        # ëŒ€í‘œ ì„ë² ë”© ë˜ëŠ” ì „ì²´ ì €ì¥
        if person_embeddings:
            if USE_REPRESENTATIVE_EMBEDDING and len(person_embeddings) > TOP_N_PER_PERSON:
                # ì„¼íŠ¸ë¡œì´ë“œ + Top-N
                centroid = np.mean(person_embeddings, axis=0)
                centroid = centroid / np.linalg.norm(centroid)
                
                # ì„¼íŠ¸ë¡œì´ë“œì™€ ê°€ì¥ ìœ ì‚¬í•œ Nê°œ ì„ íƒ
                similarities = [np.dot(centroid, emb) for emb in person_embeddings]
                top_indices = np.argsort(similarities)[-TOP_N_PER_PERSON:]
                
                all_embeddings.append(centroid)
                all_labels.append(person_name)
                
                for idx in top_indices:
                    all_embeddings.append(person_embeddings[idx])
                    all_labels.append(person_name)
            else:
                # ì „ì²´ ì €ì¥
                for emb in person_embeddings:
                    all_embeddings.append(emb)
                    all_labels.append(person_name)
    
    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    print("\n" + "=" * 60)
    print("ğŸ“Š FAISS ì¸ë±ìŠ¤ ìƒì„±")
    print("=" * 60)
    
    if not all_embeddings:
        print("âŒ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    embeddings_array = np.array(all_embeddings).astype('float32')
    labels_array = np.array(all_labels)
    
    # L2 ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ìš©)
    faiss.normalize_L2(embeddings_array)
    
    # Inner Product ì¸ë±ìŠ¤ (ì •ê·œí™”ëœ ë²¡í„°ì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë™ì¼)
    dimension = embeddings_array.shape[1]
    index = faiss.IndexFlatIP(dimension)
    index.add(embeddings_array)
    
    # ì €ì¥
    faiss.write_index(index, FAISS_INDEX_FILE)
    np.save(FAISS_LABELS_FILE, labels_array)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!")
    print("-" * 60)
    print(f"ì´ ì´ë¯¸ì§€: {stats['total_images']}ê°œ")
    print(f"ì´ ì–¼êµ´ ê°ì§€: {stats['total_faces']}ê°œ")
    print(f"ì‹¤íŒ¨: {stats['failed']}ê°œ")
    print(f"ì¸ë¬¼ ìˆ˜: {len(set(all_labels))}ëª…")
    print(f"ì´ ì„ë² ë”©: {index.ntotal}ê°œ")
    print("-" * 60)
    print(f"ì €ì¥ëœ íŒŒì¼:")
    print(f"  - {FAISS_INDEX_FILE}")
    print(f"  - {FAISS_LABELS_FILE}")
    if SAVE_AUGMENTED_IMAGES:
        print(f"  - ì¦ê°• ì´ë¯¸ì§€: {AUGMENTED_IMAGES_DIR}")
    print("=" * 60)


if __name__ == "__main__":
    build_database()

