# ai_processors.py - AI ì²˜ë¦¬ ë¡œì§
"""
AI ëª¨ë¸ ì²˜ë¦¬ í•¨ìˆ˜ ëª¨ë“ˆ
PPE ê°ì§€, ì–¼êµ´ ì¸ì‹, ìœ„í—˜ í–‰ë™ ê°ì§€ ë“±
"""
import logging
import time
from typing import Dict, List, Tuple, Optional, Any, Set

import cv2
import numpy as np
from ultralytics.engine.results import Keypoints

import utils
import config
from utils import find_best_match_faiss
from exceptions import (
    ProcessingError,
    FaceRecognitionError
)
from state import (
    fall_start_times,
    FALL_DURATION_THRESHOLD
)
from fast_face_recognizer import FastIndustrialRecognizer


def _process_ppe_detection(
    person_box: Tuple[int, int, int, int], 
    all_detections: Dict[str, List[Dict[str, Any]]],
    used_ppe_boxes: Optional[Set[Tuple[int, int, int, int]]] = None
) -> Tuple[List[str], List[Dict[str, Any]]]:
    """
    PPE ê°ì§€ ì „ìš© í•¨ìˆ˜ (ì–¼êµ´ ì¸ì‹ê³¼ ë…ë¦½ì ìœ¼ë¡œ í•­ìƒ ì‹¤í–‰)
    ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒë„ ì˜ ì¡ê¸° ìœ„í•´ ìµœê³  ì„±ëŠ¥ ì„¤ì •
    
    Returns:
        ppe_violations: PPE ìœ„ë°˜ ëª©ë¡ (ì˜ˆ: ["ì•ˆì „ëª¨", "ë§ˆìŠ¤í¬"])
        ppe_boxes: PPE ê°ì§€ëœ ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"bbox": (x1,y1,x2,y2), "class": "Safety Vest", "conf": 0.9}, ...]
    """
    ppe_violations = []
    ppe_boxes: List[Dict[str, Any]] = []  # PPE ê°ì§€ ë°•ìŠ¤ ì •ë³´
    
    if used_ppe_boxes is None:
        used_ppe_boxes = set()
    
    try:
        x1, y1, x2, y2 = person_box
        box_w = x2 - x1
        box_h = y2 - y1
        box_area = box_w * box_h
        box_center_x = (x1 + x2) / 2
        box_center_y = (y1 + y2) / 2
        
        # ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒ(ì‘ì€ ë°•ìŠ¤)ì„ ìœ„í•œ ë™ì  IoU ì„ê³„ê°’ ì¡°ì • (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
        # ì‘ì€ ë°•ìŠ¤ì¼ìˆ˜ë¡ ë” ë‚®ì€ IoU ì„ê³„ê°’ ì‚¬ìš©í•˜ë˜, ë„ˆë¬´ ë‚®ìœ¼ë©´ ë‹¤ë¥¸ ì‚¬ëŒ PPEë„ ë§¤ì¹­ë¨
        if box_area < 5000:  # ë§¤ìš° ì‘ì€ ë°•ìŠ¤ (ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒ)
            ppe_iou_threshold = 0.05  # 0.0001 -> 0.05 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
        elif box_area < 10000:  # ì‘ì€ ë°•ìŠ¤
            ppe_iou_threshold = 0.08  # 0.001 -> 0.08
        elif box_area < 20000:  # ì¤‘ê°„ ë°•ìŠ¤
            ppe_iou_threshold = 0.10  # 0.005 -> 0.10
        else:
            ppe_iou_threshold = 0.15  # 0.01 -> 0.15 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€ ê°•í™”)
        
        # ëª¨ë“  PPE í´ë˜ìŠ¤ ìˆ˜ì§‘ (ì¤€ìˆ˜ ë° ìœ„ë°˜ ëª¨ë‘)
        ppe_class_names = set()
        for rule, classes in config.Constants.SAFETY_RULES_MAP.items():
            ppe_class_names.add(classes["compliance"])
            ppe_class_names.add(classes["violation"])
        
        # person_boxì™€ ê²¹ì¹˜ëŠ” ëª¨ë“  PPE ë°•ìŠ¤ ìˆ˜ì§‘
        for ppe_class in ppe_class_names:
            if ppe_class in all_detections and all_detections[ppe_class]:
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€: ë” ì—„ê²©í•˜ê²Œ)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                distance_threshold = box_diagonal * (0.6 if box_area < 10000 else 0.5)  # 1.3->0.6, 1.0->0.5 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                
                for det in all_detections[ppe_class]:
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            continue
                        
                        conf = det.get('conf', 0.9)
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ
                        
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        is_match = False
                        if center_distance < distance_threshold:
                            is_match = True
                        else:
                            # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                            iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                            if iou > ppe_iou_threshold:
                                is_match = True
                        
                        if is_match:
                            # PPE ë°•ìŠ¤ ì •ë³´ ì €ì¥
                            ppe_boxes.append({
                                "bbox": det_bbox_tuple,
                                "class": ppe_class,
                                "conf": conf
                            })
        
        # PPE ë°•ìŠ¤ ì¤‘ë³µ ì œê±° (IoU ê¸°ë°˜, ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œë§Œ)
        if len(ppe_boxes) > 1:
            # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
            ppe_by_class: Dict[str, List[Dict[str, Any]]] = {}
            for ppe_box in ppe_boxes:
                ppe_class = ppe_box['class']
                if ppe_class not in ppe_by_class:
                    ppe_by_class[ppe_class] = []
                ppe_by_class[ppe_class].append(ppe_box)
            
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¤‘ë³µ ì œê±° (IoU > 0.6ì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼, confidenceê°€ ë†’ì€ ê²ƒë§Œ ìœ ì§€)
            # IoU ì„ê³„ê°’ì„ 0.5 -> 0.6ìœ¼ë¡œ ìƒí–¥í•˜ì—¬ ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°
            filtered_ppe_boxes: List[Dict[str, Any]] = []
            for ppe_class, boxes in ppe_by_class.items():
                if len(boxes) == 1:
                    filtered_ppe_boxes.append(boxes[0])
                else:
                    # confidence ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ê²ƒë¶€í„°)
                    boxes_sorted = sorted(boxes, key=lambda x: x['conf'], reverse=True)
                    kept_indices: List[int] = []
                    
                    for i, box1 in enumerate(boxes_sorted):
                        bx1, by1, bx2, by2 = box1['bbox']
                        is_duplicate = False
                        
                        # ì´ë¯¸ ìœ ì§€ëœ ë°•ìŠ¤ì™€ IoU ê³„ì‚°
                        for j in kept_indices:
                            box2 = boxes_sorted[j]
                            bx3, by3, bx4, by4 = box2['bbox']
                            iou = utils.calculate_iou((bx1, by1, bx2, by2), (bx3, by3, bx4, by4))
                            
                            # IoUê°€ 0.6 ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼ (0.5 -> 0.6, ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°)
                            if iou > 0.6:
                                is_duplicate = True
                                break
                        
                        if not is_duplicate:
                            kept_indices.append(i)
                    
                    # ìœ ì§€ëœ ë°•ìŠ¤ë§Œ ì¶”ê°€
                    for idx in kept_indices:
                        filtered_ppe_boxes.append(boxes_sorted[idx])
            
            ppe_boxes = filtered_ppe_boxes
        
        # ìœ„ë°˜ íŒì • ë¡œì§ (origin ë²„ì „ ì‚¬ìš©)
        for rule, classes in config.Constants.SAFETY_RULES_MAP.items():
            comp_cls, viol_cls = classes["compliance"], classes["violation"]
            is_compliance = False
            is_violation = False
            
            # ì¤€ìˆ˜(ì°©ìš©) íŒì •: ì¤‘ì‹¬ì  ê±°ë¦¬ ë¨¼ì € ê³„ì‚°, IoUëŠ” ë‚˜ì¤‘ì— (ì„±ëŠ¥ ìµœì í™”)
            if comp_cls in all_detections and all_detections[comp_cls]:
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€: ë” ì—„ê²©í•˜ê²Œ)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                distance_threshold = box_diagonal * (0.6 if box_area < 10000 else 0.5)  # 1.3->0.6, 1.0->0.5 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                
                for det in all_detections[comp_cls]:
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            continue
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ
                        
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        if center_distance < distance_threshold:
                            is_compliance = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            logging.debug(f"âœ… PPE ì¤€ìˆ˜ ë§¤ì¹­ ì„±ê³µ: {rule} - ê±°ë¦¬={center_distance:.1f}, ppe_box={det_bbox_tuple}, person_box=({x1},{y1},{x2},{y2})")
                            break
                        
                        # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                        iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                        if iou > ppe_iou_threshold:
                            is_compliance = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            logging.debug(f"âœ… PPE ì¤€ìˆ˜ ë§¤ì¹­ ì„±ê³µ: {rule} - IoU={iou:.4f}, ppe_box={det_bbox_tuple}, person_box=({x1},{y1},{x2},{y2})")
                            break
            
            # ìœ„ë°˜(ë¯¸ì°©ìš©) íŒì •: ì¤‘ì‹¬ì  ê±°ë¦¬ ë¨¼ì € ê³„ì‚°, IoUëŠ” ë‚˜ì¤‘ì— (ì„±ëŠ¥ ìµœì í™”)
            if viol_cls in all_detections and all_detections[viol_cls]:
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€: ë” ì—„ê²©í•˜ê²Œ)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                distance_threshold = box_diagonal * (0.6 if box_area < 10000 else 0.5)  # 1.3->0.6, 1.0->0.5 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                
                for det in all_detections[viol_cls]:
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            continue
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ
                        
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        if center_distance < distance_threshold:
                            is_violation = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            break
                        
                        # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                        iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                        if iou > ppe_iou_threshold:
                            is_violation = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            break
            
            # [ìˆ˜ì •] ì¤€ìˆ˜ ìš°ì„  ì •ì±… (Compliance Priority)
            # ì°©ìš©(Compliance)ì´ ê°ì§€ë˜ì—ˆë‹¤ë©´, ìœ„ë°˜(Violation) ê°ì§€ê°€ ìˆë”ë¼ë„ ë¬´ì‹œ (ì˜¤íƒì§€ ë°©ì§€)
            # ì˜ˆ: ì¡°ë¼ë¥¼ ì…ì—ˆëŠ”ë° ì¡°ë¼ ì£¼ë¦„ ë•Œë¬¸ì— NO-Vestë¡œ ì˜¤ì¸ì‹ë˜ëŠ” ê²½ìš° ë°©ì§€
            if is_compliance:
                is_violation = False
                logging.debug(f"PPE ì¤€ìˆ˜ ê°ì§€: {rule} (Compliance Priority ì ìš©, ìœ„ë°˜ ë¬´ì‹œ)")

            if is_violation:
                ppe_violations.append(rule)
                # ìœ„ë°˜ ê°ì§€ëŠ” ì¤‘ìš”í•˜ë¯€ë¡œ info ë ˆë²¨ ìœ ì§€ (ë‹¨, ë§¤ í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ ì¡°ì ˆ í•„ìš”)
                logging.debug(f"PPE ìœ„ë°˜ ê°ì§€: {rule}")
        
        return ppe_violations, ppe_boxes
    except Exception as e:
        logging.warning(f"PPE ê°ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return [], []


def _process_face_recognition(
    person_img_for_detection: np.ndarray, 
    person_id_text: str,
    face_model: Any, 
    face_database: Any,
    fast_recognizer: Optional[Any] = None,
    pre_detected_face: Optional[Any] = None,
    original_frame: Optional[np.ndarray] = None
) -> Tuple[str, float, Optional[np.ndarray], Optional[Tuple[int, int, int, int]]]:
    """
    ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥, ìµœì í™” ë²„ì „)
    ì´ì œ ì´ í•¨ìˆ˜ëŠ” ì„ë² ë”© ì¶”ì¶œê¹Œì§€ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """
    try:
        import time
        import numpy as np
        
        # 0. Fast Path: ë¯¸ë¦¬ ê°ì§€ëœ ì–¼êµ´ ì •ë³´ ì‚¬ìš© (ì¤‘ë³µ ê°ì§€ ì œê±°)
        if pre_detected_face and original_frame is not None and fast_recognizer is not None:
            has_kps = hasattr(pre_detected_face, 'kps') and pre_detected_face.kps is not None
            if has_kps:
                try:
                    result = fast_recognizer.get_embedding_fast(
                        original_frame, 
                        pre_detected_face.kps
                    )
                    if result is not None:
                        embedding, _ = result
                        if embedding is not None:
                            face_bbox = tuple(map(int, pre_detected_face.bbox))
                            return "Unknown", 0.0, embedding, face_bbox
                except Exception as e:
                    logging.error(f"âš ï¸ {person_id_text} Fast Path ì‹¤íŒ¨ (Fallback ì§„í–‰): {e}", exc_info=True)

        # Fallback: YOLOë¡œ ë‹¤ì‹œ ê°ì§€í•˜ì—¬ ëœë“œë§ˆí¬ ì¶”ì¶œ (ì¸¡ë©´ ì–¼êµ´ ì§€ì›)
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê°œì„ : ë°ê¸°/ëŒ€ë¹„ ì¡°ì • ë° ì—…ìŠ¤ì¼€ì¼ë§
        import cv2
        img_h, img_w = person_img_for_detection.shape[:2]
        min_size = 64  # ìµœì†Œ 64x64 í”½ì…€ (32 -> 64ë¡œ ì¦ê°€)
        
        # ì´ë¯¸ì§€ê°€ ì‘ìœ¼ë©´ ì—…ìŠ¤ì¼€ì¼ë§ (ë” í° í•´ìƒë„ë¡œ ê°ì§€ ì„±ê³µë¥  í–¥ìƒ)
        processed_img = person_img_for_detection.copy()
        if img_h < min_size or img_w < min_size:
            scale = max(min_size / img_h, min_size / img_w)
            new_h, new_w = int(img_h * scale), int(img_w * scale)
            processed_img = cv2.resize(processed_img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
            logging.debug(f"ğŸ” {person_id_text} ì´ë¯¸ì§€ í™•ëŒ€: {img_h}x{img_w} -> {new_h}x{new_w}")
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ : CLAHE (ëŒ€ë¹„ í–¥ìƒ) ë° ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì œê±° (ìƒ¤í”„ë‹)
        # ì‘ì€ ì–¼êµ´ ê°ì§€ë¥¼ ìœ„í•´ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
        if processed_img.shape[0] < 128 or processed_img.shape[1] < 128:
            # ì‘ì€ ì´ë¯¸ì§€ëŠ” CLAHEë¡œ ëŒ€ë¹„ í–¥ìƒ
            lab = cv2.cvtColor(processed_img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            processed_img = cv2.merge([l, a, b])
            processed_img = cv2.cvtColor(processed_img, cv2.COLOR_LAB2BGR)
            logging.debug(f"ğŸ” {person_id_text} CLAHE ì ìš©: ëŒ€ë¹„ í–¥ìƒ")
        
        # confidenceë¥¼ ë§¤ìš° ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ìµœëŒ€í•œ ì–¼êµ´ ê°ì§€ ì‹œë„ (0.01 -> 0.005)
        # YOLO Face ëª¨ë¸ì€ 640x640ìœ¼ë¡œ ONNX ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ 640ë§Œ ì‚¬ìš©
        yolo_results = None
        conf_levels = [0.005, 0.01, 0.02]  # ë‚®ì€ confidenceë¶€í„° ì‹œë„
        imgsz_options = [640]  # YOLO Face ëª¨ë¸ì€ 640x640ìœ¼ë¡œ ê³ ì • (ONNX ë³€í™˜ ì‹œ í•´ìƒë„)
        
        for conf in conf_levels:
            for imgsz in imgsz_options:
                try:
                    yolo_results = face_model(processed_img, verbose=False, imgsz=imgsz, conf=conf)
                    if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                        logging.debug(f"ğŸ” {person_id_text} YOLO Face ê°ì§€ ì„±ê³µ: conf={conf}, imgsz={imgsz}")
                        break
                except Exception as e:
                    logging.debug(f"ğŸ” {person_id_text} YOLO Face ì‹œë„ ì‹¤íŒ¨: conf={conf}, imgsz={imgsz}, error={e}")
                    continue
                if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                    break
            if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                break
        
        # ë””ë²„ê¹…: YOLO Face ê°ì§€ ê²°ê³¼ í™•ì¸
        if yolo_results and len(yolo_results) > 0:
            result = yolo_results[0]
            box_count = len(result.boxes) if result.boxes is not None else 0
            has_keypoints = result.keypoints is not None
            kp_count = 0
            if has_keypoints and box_count > 0:
                try:
                    kp_count = len(result.keypoints.xy[0]) if len(result.keypoints.xy) > 0 else 0
                except:
                    pass
            logging.debug(f"ğŸ” {person_id_text} YOLO Face ê²°ê³¼: ë°•ìŠ¤={box_count}ê°œ, í‚¤í¬ì¸íŠ¸={kp_count}ê°œ")
        
        if yolo_results and yolo_results[0].boxes:
            best_idx = yolo_results[0].boxes.xywh.prod(1).argmax()
            face_bbox_raw = yolo_results[0].boxes.xyxy[best_idx].cpu().numpy()
            face_bbox = tuple(map(int, face_bbox_raw))
            
            # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (ì¸¡ë©´ ì–¼êµ´ ì§€ì›: 2ê°œ ì´ìƒì´ë©´ ì‚¬ìš©)
            kps = None
            if yolo_results[0].keypoints is not None:
                try:
                    kps = yolo_results[0].keypoints.xy[best_idx].cpu().numpy()
                    # ì¸¡ë©´ ì–¼êµ´ ì§€ì›: ìµœì†Œ 2ê°œ í‚¤í¬ì¸íŠ¸ë§Œ ìˆì–´ë„ ì²˜ë¦¬
                    if kps.shape[0] < 2:
                        kps = None
                except Exception as e:
                    logging.debug(f"Fallback í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    kps = None
            
            # í‚¤í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ ì •ë ¬ ì‹œë„
            if kps is not None:
                result = fast_recognizer.get_embedding_fast(
                    processed_img, 
                    kps,
                    use_enhanced_preprocessing=False,  # aivis-project1 ë°©ì‹: ê¸°ë³¸ ì „ì²˜ë¦¬ë§Œ ì‚¬ìš© (CLAHE)
                    use_tta=False  # ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì‹œì™€ ë™ì¼ (USE_TTA_FOR_DATABASE=False)
                )
                if result is not None:
                    embedding, _ = result
                    if embedding is not None:
                        return "Unknown", 0.0, embedding, face_bbox
            else:
                # í‚¤í¬ì¸íŠ¸ê°€ ì—†ì–´ë„ ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì‹œë„ (ì¸¡ë©´ ì–¼êµ´)
                # ì–¼êµ´ ë°•ìŠ¤ ì¤‘ì‹¬ì„ í‚¤í¬ì¸íŠ¸ë¡œ ì‚¬ìš©
                fx1, fy1, fx2, fy2 = face_bbox
                face_center = np.array([(fx1 + fx2) / 2, (fy1 + fy2) / 2], dtype=np.float32)
                face_size = max(fx2 - fx1, fy2 - fy1) * 0.3
                # ê°€ìƒ í‚¤í¬ì¸íŠ¸ ìƒì„± (ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜)
                fake_kps = np.array([
                    [face_center[0] - face_size, face_center[1] - face_size * 0.3],  # ì™¼ìª½ ëˆˆ ìœ„ì¹˜ ì¶”ì •
                    [face_center[0] + face_size, face_center[1] - face_size * 0.3],  # ì˜¤ë¥¸ìª½ ëˆˆ ìœ„ì¹˜ ì¶”ì •
                    [face_center[0], face_center[1]],  # ì½”
                    [face_center[0] - face_size * 0.5, face_center[1] + face_size * 0.5],  # ì™¼ìª½ ì…ê¼¬ë¦¬
                    [face_center[0] + face_size * 0.5, face_center[1] + face_size * 0.5],  # ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬
                ], dtype=np.float32)
                
                result = fast_recognizer.get_embedding_fast(
                    processed_img, 
                    fake_kps
                )
                if result is not None:
                    embedding, _ = result
                    if embedding is not None:
                        logging.debug(f"ì¸¡ë©´ ì–¼êµ´: ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ")
                        return "Unknown", 0.0, embedding, face_bbox
        
        # ìµœì¢… ì‹œë„: person_img_for_detection ì „ì²´ ì˜ì—­ì„ ì–¼êµ´ë¡œ ê°„ì£¼í•˜ê³  ì‹œë„
        # (YOLO Faceê°€ ì‹¤íŒ¨í•´ë„ person_box ì˜ì—­ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ìˆì„ ìˆ˜ ìˆìŒ)
        if processed_img.shape[0] >= 32 and processed_img.shape[1] >= 32:
            try:
                # person_boxì˜ ìƒë‹¨ 1/3 ì˜ì—­ì„ ì–¼êµ´ë¡œ ê°„ì£¼ (ì¼ë°˜ì ì¸ ì–¼êµ´ ìœ„ì¹˜)
                face_region = processed_img[:processed_img.shape[0] // 3, :]
                if face_region.shape[0] >= 32 and face_region.shape[1] >= 32:
                    # ì–¼êµ´ ì˜ì—­ ì¤‘ì‹¬ì„ í‚¤í¬ì¸íŠ¸ë¡œ ì‚¬ìš©
                    face_center = np.array([face_region.shape[1] / 2, face_region.shape[0] / 2], dtype=np.float32)
                    face_size = min(face_region.shape[0], face_region.shape[1]) * 0.3
                    fake_kps = np.array([
                        [face_center[0] - face_size, face_center[1] - face_size * 0.3],
                        [face_center[0] + face_size, face_center[1] - face_size * 0.3],
                        [face_center[0], face_center[1]],
                        [face_center[0] - face_size * 0.5, face_center[1] + face_size * 0.5],
                        [face_center[0] + face_size * 0.5, face_center[1] + face_size * 0.5],
                    ], dtype=np.float32)
                    
                    result = fast_recognizer.get_embedding_fast(
                        face_region, 
                        fake_kps
                    )
                    if result is not None:
                        embedding, _ = result
                        if embedding is not None:
                            # ì–¼êµ´ ì˜ì—­ì˜ bbox ê³„ì‚° (ì›ë³¸ person_img ê¸°ì¤€)
                            face_bbox = (0, 0, processed_img.shape[1], processed_img.shape[0] // 3)
                            logging.debug(f"ìµœì¢… ì‹œë„ ì„±ê³µ: person_box ìƒë‹¨ ì˜ì—­ ê¸°ë°˜ ì„ë² ë”© ì¶”ì¶œ")
                            return "Unknown", 0.0, embedding, face_bbox
            except Exception as e:
                logging.debug(f"ìµœì¢… ì‹œë„ ì‹¤íŒ¨: {e}")
        
        raise FaceRecognitionError("ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨. ëœë“œë§ˆí¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        logging.error(f"âŒ {person_id_text} ì–¼êµ´ ì¸ì‹ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise FaceRecognitionError(f"ì–¼êµ´ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}") from e


def _process_dangerous_behavior(
    keypoints: Keypoints, 
    person_box: Tuple[int, int, int, int], 
    cam_id: int, 
    person_box_key: str,
    person_crop: Optional[np.ndarray] = None,
    fall_model: Optional[Any] = None
) -> Tuple[bool, str]:
    """
    ìœ„í—˜ í–‰ë™ ê°ì§€ ì²˜ë¦¬ í•¨ìˆ˜ (ë„˜ì–´ì§ ë“±) - ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
    ìœ„í—˜í•  ë•Œë§Œ True ë°˜í™˜í•˜ì—¬ ì•Œë¦¼ ìƒì„±
    
    Args:
        keypoints: í‚¤í¬ì¸íŠ¸ ê°ì²´
        person_box: ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤
        cam_id: ì¹´ë©”ë¼ ID
        person_box_key: ì‚¬ëŒ ë°•ìŠ¤ í‚¤
        person_crop: ì‚¬ëŒ ì˜ì—­ í¬ë¡­ ì´ë¯¸ì§€ (FallSafe ëª¨ë¸ìš©, ì„ íƒì )
        fall_model: FallSafe ëª¨ë¸ ê°ì²´ (ì„ íƒì )
    
    Returns:
        (is_dangerous, violation_type)
        - is_dangerous: ìœ„í—˜ í–‰ë™ ê°ì§€ ì—¬ë¶€ (ìœ„í—˜í•  ë•Œë§Œ True)
        - violation_type: ìœ„ë°˜ ìœ í˜• (ì˜ˆ: "ë„˜ì–´ì§")
    """
    try:
        x1, y1, x2, y2 = person_box
        
        # í‚¤í¬ì¸íŠ¸ê°€ ì—†ì–´ë„ ë°•ìŠ¤ ë¹„ìœ¨ë¡œ ë„˜ì–´ì§ ê°ì§€ ì‹œë„
        # ë°•ìŠ¤ ë¹„ìœ¨ì´ ë§¤ìš° ë†’ìœ¼ë©´ (ê°€ë¡œê°€ ì„¸ë¡œë³´ë‹¤ 2ë°° ì´ìƒ) ë„˜ì–´ì§ í›„ë³´
        box_w = x2 - x1
        box_h = y2 - y1
        box_ratio = box_w / box_h if box_h > 0 else 0
        
        if keypoints is None and box_ratio < 1.5:
            # í‚¤í¬ì¸íŠ¸ë„ ì—†ê³  ë°•ìŠ¤ ë¹„ìœ¨ë„ ë‚®ìœ¼ë©´ ìŠ¤í‚µ
            return False, ""
        
        is_fallen_horizontal = utils.is_person_horizontal(
            keypoints, (x1, y1, x2, y2),
            person_crop=person_crop,
            fall_model=fall_model
        )
        
        now_ts = time.time()
        
        # ë””ë²„ê¹…: í‚¤í¬ì¸íŠ¸ ìƒíƒœ í™•ì¸ (dict ë˜ëŠ” Keypoints ê°ì²´ ëª¨ë‘ ì§€ì›)
        if keypoints is not None:
            try:
                if isinstance(keypoints, dict):
                    # dict í˜•íƒœ (frame_processorì—ì„œ ì „ë‹¬)
                    points = keypoints.get('xy')
                    confidences = keypoints.get('conf')
                    if points is not None and confidences is not None:
                        valid_count = (confidences > config.Thresholds.POSE_CONFIDENCE).sum()
                        logging.debug(f"ğŸ” ìœ„í—˜ ê°ì§€ ë¶„ì„ (dict): person_box_key={person_box_key}, "
                                    f"ìœ íš¨ í‚¤í¬ì¸íŠ¸={valid_count}/{len(confidences)}, "
                                    f"ë„˜ì–´ì§ ìì„¸={is_fallen_horizontal}")
                elif hasattr(keypoints, 'data') and keypoints.data is not None:
                    # Keypoints ê°ì²´
                    points = keypoints.xy[0].cpu().numpy()
                    confidences = keypoints.conf[0].cpu().numpy()
                    valid_count = (confidences > config.Thresholds.POSE_CONFIDENCE).sum()
                    logging.debug(f"ğŸ” ìœ„í—˜ ê°ì§€ ë¶„ì„: person_box_key={person_box_key}, "
                            f"ìœ íš¨ í‚¤í¬ì¸íŠ¸={valid_count}/{len(confidences)}, "
                            f"ë„˜ì–´ì§ ìì„¸={is_fallen_horizontal}")
            except Exception as e:
                logging.debug(f"í‚¤í¬ì¸íŠ¸ ë””ë²„ê¹… ì˜¤ë¥˜: {e}")
        
        if is_fallen_horizontal:
            # ë„˜ì–´ì§ ê°ì§€ ì‹œê°„ ì¶”ì 
            if cam_id not in fall_start_times:
                fall_start_times[cam_id] = {}
            if person_box_key not in fall_start_times[cam_id]:
                fall_start_times[cam_id][person_box_key] = now_ts
            
            # 0.5ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ë„˜ì–´ì§ìœ¼ë¡œ íŒì • (ìœ„í—˜í•  ë•Œë§Œ True ë°˜í™˜)
            fall_duration = now_ts - fall_start_times[cam_id][person_box_key]
            if fall_duration >= FALL_DURATION_THRESHOLD:
                # ìœ„í—˜ ê°ì§€: ì•Œë¦¼ ìƒì„±
                logging.warning(f"âš ï¸ ìœ„í—˜ í–‰ë™ ê°ì§€: {person_box_key} - ë„˜ì–´ì§ (ì§€ì† ì‹œê°„: {fall_duration:.2f}ì´ˆ)")
                return True, "ë„˜ì–´ì§"
            else:
                # ì•„ì§ ì‹œê°„ì´ ë¶€ì¡±í•˜ë©´ False (ìœ„í—˜í•˜ì§€ ì•ŠìŒ)
                return False, ""
        else:
            # ë„˜ì–´ì§ì´ ì•„ë‹ˆë©´ ì‹œê°„ ì¶”ì  ì´ˆê¸°í™”
            if cam_id in fall_start_times and person_box_key in fall_start_times[cam_id]:
                del fall_start_times[cam_id][person_box_key]
        
        return False, ""
    except Exception as e:
        logging.debug(f"ìœ„í—˜ í–‰ë™ ê°ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return False, ""
