# core.py - SafetySystem í´ë˜ìŠ¤ (ëª¨ë¸ ë¡œë”© ë° ê´€ë¦¬)
import os
import sys
import cv2
import torch
import logging
import numpy as np
import platform
from collections import defaultdict
from typing import List, Dict, Tuple, Optional, Any
from ultralytics import YOLO
from ultralytics.engine.results import Keypoints

# Conda í™˜ê²½ì˜ faiss-gpuë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€ (venvì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡)
_conda_paths_added = False
if not _conda_paths_added:
    import site
    # ì¼ë°˜ì ì¸ conda ì„¤ì¹˜ ê²½ë¡œ í™•ì¸
    _possible_conda_paths = [
        os.path.join(os.environ.get('USERPROFILE', ''), 'anaconda3', 'Lib', 'site-packages'),
        os.path.join(os.environ.get('USERPROFILE', ''), 'miniconda3', 'Lib', 'site-packages'),
        os.path.join('C:', 'ProgramData', 'anaconda3', 'Lib', 'site-packages'),
        os.path.join('C:', 'ProgramData', 'miniconda3', 'Lib', 'site-packages'),
    ]
    # í˜„ì¬ Python ì‹¤í–‰ íŒŒì¼ ê²½ë¡œì—ì„œ conda ê²½ë¡œ ì¶”ì¶œ
    _python_dir = os.path.dirname(sys.executable)
    if 'conda' in _python_dir.lower() or 'anaconda' in _python_dir.lower():
        _conda_base = _python_dir
        while _conda_base and os.path.basename(_conda_base).lower() not in ['anaconda3', 'miniconda3', 'conda']:
            _conda_base = os.path.dirname(_conda_base)
        if _conda_base:
            _conda_site_packages = os.path.join(_conda_base, 'Lib', 'site-packages')
            if os.path.exists(_conda_site_packages) and _conda_site_packages not in sys.path:
                sys.path.insert(0, _conda_site_packages)
                _conda_paths_added = True
    
    # ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
    if not _conda_paths_added:
        for _conda_path in _possible_conda_paths:
            if os.path.exists(_conda_path) and _conda_path not in sys.path:
                sys.path.insert(0, _conda_path)
                _conda_paths_added = True
                break

# faiss ì„í¬íŠ¸ (conda ê²½ë¡œ ì¶”ê°€ í›„)
try:
    import faiss
except ImportError:
    faiss = None
    logging.warning("âš ï¸ FAISSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# InsightFaceëŠ” ì„ íƒì  (ì„¤ì¹˜ ì‹¤íŒ¨ ì‹œ ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ ë¹„í™œì„±í™”)
try:
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False
    FaceAnalysis = None
    logging.warning("insightface ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    logging.warning("ì„¤ì¹˜ ë°©ë²•: .\\install_insightface.bat")

import config
from utils import calculate_iou, clip_bbox_xyxy, is_person_horizontal, log_violation



class SafetySystem:
    def __init__(self):
        # 0. ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        if torch.cuda.is_available():
            # ê³ ì •ëœ ì…ë ¥ í¬ê¸°ì—ì„œ ìµœì ì˜ ì•Œê³ ë¦¬ì¦˜ì„ ì°¾ì•„ ì†ë„ í–¥ìƒ
            torch.backends.cudnn.benchmark = True
            # TensorFloat-32(TF32) í™œì„±í™” (Ampere ì´ìƒ GPUì—ì„œ ì„±ëŠ¥ í–¥ìƒ, 2080TiëŠ” ë¬´ì‹œë¨)
            if hasattr(torch.backends.cuda, 'matmul'):
                torch.backends.cuda.matmul.allow_tf32 = True
            if hasattr(torch.backends.cudnn, 'allow_tf32'):
                torch.backends.cudnn.allow_tf32 = True
            logging.info("âœ… GPU ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì™„ë£Œ (CuDNN Benchmark=True)")
        elif torch.backends.mps.is_available():
            # MPS ìµœì í™” ì„¤ì • (ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
            # MPSëŠ” ìë™ìœ¼ë¡œ ìµœì í™”ë˜ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥í•œ ì˜µì…˜ë“¤
            try:
                # MPS ìºì‹œ í™œì„±í™” (ë°˜ë³µ ì—°ì‚° ì†ë„ í–¥ìƒ)
                if hasattr(torch.backends.mps, 'is_built'):
                    logging.info("âœ… MPS (Metal Performance Shaders) ìµœì í™” í™œì„±í™”")
                    logging.info("  - í†µí•© ë©”ëª¨ë¦¬ ì•„í‚¤í…ì²˜ í™œìš©")
                    logging.info("  - Metal GPU ê°€ì† í™œì„±í™”")
                    logging.info("  - MPS ìºì‹œ í™œì„±í™” (ë°˜ë³µ ì—°ì‚° ìµœì í™”)")
                
                # MPS ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
                # MPSëŠ” í†µí•© ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ëª…ì‹œì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë¶ˆí•„ìš”
                # í•˜ì§€ë§Œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”ë¥¼ ìœ„í•´ íŒíŠ¸ ì œê³µ
                import gc
                gc.collect()  # ì´ˆê¸°í™” ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
                
            except Exception as e:
                logging.warning(f"MPS ìµœì í™” ì„¤ì • ì¤‘ ê²½ê³ : {e}")
            
            logging.info("âœ… MPS (Metal Performance Shaders) ìµœì í™” í™œì„±í™”")
            logging.info("  - í†µí•© ë©”ëª¨ë¦¬ ì•„í‚¤í…ì²˜ í™œìš©")
            logging.info("  - Metal GPU ê°€ì† í™œì„±í™”")

        # 1. ì¥ì¹˜ ì„¤ì • (ë©€í‹° GPU ì§€ì›)
        self.device_config = config.SystemConfig.get_device_config()
        self.device = self.device_config['device']  # GPU 0: YOLO Violation, Pose
        self.device_face = self.device_config.get('device_face', self.device)  # GPU 1: YOLO Face, InsightFace
        self.gpu_count = self.device_config.get('gpu_count', 0)
        logging.info(f"SafetySystem: YOLO Violation/Pose ì¥ì¹˜: {self.device.upper()}")
        logging.info(f"SafetySystem: ì–¼êµ´ ì¸ì‹ ì¥ì¹˜: {self.device_face.upper()}")

        # 2. ëª¨ë¸ ë¡œë”©
        (self.violation_model,
         self.pose_model,
         self.violation_uses_trt,
         self.pose_uses_trt) = self._initialize_tracking_models()
        (self.face_model,
         self.face_analyzer,
         self.face_database,
         self.face_uses_trt,
         self.use_adaface,
         self.adaface_model_path) = self._initialize_face_recognition_models()
        
        # FastIndustrialRecognizer ì´ˆê¸°í™” (ëœë“œë§ˆí¬ ê¸°ë°˜ ê³ ì† ì²˜ë¦¬ìš©)
        self.fast_recognizer = None
        # MPS/CUDA ë””ë°”ì´ìŠ¤ì— ë§ëŠ” ctx_id ì„¤ì •
        if 'mps' in str(self.device_face):
            ctx_id_face = 0  # MPSëŠ” ë‹¨ì¼ GPU
        elif 'cuda' in str(self.device_face):
            ctx_id_face = int(self.device_face.split(':')[-1]) if ':' in str(self.device_face) else 0
        else:
            ctx_id_face = -1  # CPU
        
        if self.use_adaface and self.adaface_model_path:
            try:
                from fast_face_recognizer import FastIndustrialRecognizer
                self.fast_recognizer = FastIndustrialRecognizer(
                    model_path=self.adaface_model_path,
                    ctx_id=ctx_id_face,
                    use_adaface=True
                )
                logging.info(f"âœ… FastIndustrialRecognizer ì´ˆê¸°í™” ì™„ë£Œ (AdaFace ëª¨ë¸: {self.adaface_model_path})")
            except Exception as e:
                logging.warning(f"âš ï¸ FastIndustrialRecognizer ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
                self.fast_recognizer = None
        elif self.face_analyzer is not None:
            # AdaFaceê°€ ì•„ë‹ˆì–´ë„ FastIndustrialRecognizer ì‚¬ìš© ê°€ëŠ¥ (ëœë“œë§ˆí¬ ê¸°ë°˜ ì²˜ë¦¬)
            try:
                from fast_face_recognizer import FastIndustrialRecognizer
                self.fast_recognizer = FastIndustrialRecognizer(
                    model_path=None,  # InsightFace ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
                    ctx_id=ctx_id_face,
                    use_adaface=False
                )
                logging.info(f"âœ… FastIndustrialRecognizer ì´ˆê¸°í™” ì™„ë£Œ (buffalo_l ëª¨ë¸, ëœë“œë§ˆí¬ ê¸°ë°˜ ì²˜ë¦¬)")
            except Exception as e:
                logging.warning(f"âš ï¸ FastIndustrialRecognizer ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
                self.fast_recognizer = None

        if self.violation_model is None or self.pose_model is None:
            logging.error("í•„ìˆ˜ ëª¨ë¸(Violation or Pose) ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
             logging.info("YOLO ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")

        if self.face_model is None or self.face_analyzer is None or self.face_database is None:
            logging.warning("=" * 80)
            logging.warning("âš ï¸  ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ë˜ëŠ” DB ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            logging.warning("âš ï¸  ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            if not INSIGHTFACE_AVAILABLE:
                logging.warning("âš ï¸  InsightFace ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                logging.warning("âš ï¸  ì„¤ì¹˜ ë°©ë²•: .\\install_insightface.bat")
            logging.warning("=" * 80)
        else:
            logging.info("âœ… ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ë° DB ë¡œë”© ì™„ë£Œ (YOLO ì–¼êµ´ ê°ì§€ + InsightFace ì„ë² ë”©).")

    def _load_yolo_variant(self, weight_path: str, engine_path: str, task_description: str, task_type: str) -> Tuple[Optional[YOLO], bool]:
        """
        YOLO ëª¨ë¸ ë¡œë“œ (PyTorch .pt íŒŒì¼ ì§ì ‘ ì‚¬ìš©, MPS/CUDA ìµœì í™”)
        
        :param weight_path: PyTorch ëª¨ë¸ ê²½ë¡œ (.pt)
        :param engine_path: TensorRT ì—”ì§„ ê²½ë¡œ (.engine) - ì‚¬ìš© ì•ˆ í•¨
        :param task_description: ì‘ì—… ì„¤ëª… (ë¡œê¹…ìš©)
        :param task_type: ì‘ì—… íƒ€ì… ('detect', 'pose', 'segment')
        :return: (ëª¨ë¸, TensorRT ì‚¬ìš© ì—¬ë¶€) íŠœí”Œ - í•­ìƒ False ë°˜í™˜
        """
        # PyTorch ëª¨ë¸ ì§ì ‘ ë¡œë“œ (ONNX/Engine ìš°íšŒ)
        if not os.path.exists(weight_path):
            raise FileNotFoundError(f"{task_description} ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {weight_path}")
        
        try:
            logging.info(f"{task_description} PyTorch ëª¨ë¸ ë¡œë“œ: {weight_path}")
            model = YOLO(weight_path, task=task_type)
            # ë””ë°”ì´ìŠ¤ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ì‹¤ì œ ì´ë™ í›„ ë¡œê¹…ë¨
            return model, False  # TensorRT ì‚¬ìš© ì•ˆ í•¨
        except Exception as e:
            logging.error(f"{task_description} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
            return None, False
    
    @staticmethod
    def _is_onnx_model(model_path: str) -> bool:
        """ëª¨ë¸ ê²½ë¡œê°€ ONNX ëª¨ë¸ì¸ì§€ í™•ì¸"""
        if model_path.endswith('.onnx'):
            return True
        onnx_path = os.path.splitext(model_path)[0] + ".onnx"
        return os.path.exists(onnx_path)

    def _initialize_tracking_models(self) -> Tuple[Optional[YOLO], Optional[YOLO], bool, bool]:
        try:
            violation_model, violation_trt = self._load_yolo_variant(
                config.Paths.YOLO_VIOLATION_MODEL,
                config.Paths.YOLO_VIOLATION_ENGINE,
                "Violation",
                "detect"
            )
            pose_model, pose_trt = self._load_yolo_variant(
                config.Paths.YOLO_POSE_MODEL,
                config.Paths.YOLO_POSE_ENGINE,
                "Pose",
                "pose"
            )

            if violation_model is None or pose_model is None:
                raise RuntimeError("í•„ìˆ˜ YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # MPSì˜ ê²½ìš° Pose ëª¨ë¸ì€ CPU ì‚¬ìš© (ì•Œë ¤ì§„ ë²„ê·¸)
            import torch
            pose_device = self.device
            if 'mps' in str(self.device) and torch.backends.mps.is_available():
                # MPS Pose ëª¨ë¸ ë²„ê·¸ë¡œ ì¸í•´ CPU ì‚¬ìš©
                pose_device = 'cpu'
                logging.warning("âš ï¸ MPS Pose ëª¨ë¸ ì•Œë ¤ì§„ ë²„ê·¸ë¡œ ì¸í•´ CPU ëª¨ë“œ ì‚¬ìš© (https://github.com/ultralytics/ultralytics/issues/4031)")
            
            if not violation_trt:
                # PyTorch ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ float() ë° .to() í˜¸ì¶œ
                underlying_violation = getattr(violation_model, "model", None)
                if underlying_violation is not None:
                    # ë¬¸ìì—´ì´ ì•„ë‹ˆê³  float() ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í˜¸ì¶œ (PyTorch ëª¨ë¸)
                    if not isinstance(underlying_violation, str) and hasattr(underlying_violation, "float"):
                        try:
                            underlying_violation.float()
                        except (AttributeError, TypeError):
                            pass  # ONNX ëª¨ë¸ì´ê±°ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš° ë¬´ì‹œ
                
                # .to() ë©”ì„œë“œ í˜¸ì¶œ (MPS ë””ë°”ì´ìŠ¤ë¡œ ëª…ì‹œì  ì´ë™)
                try:
                    violation_model.to(self.device)
                    # MPS ìµœì í™”: ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì • (ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™” ìµœì í™”)
                    if hasattr(violation_model, 'eval'):
                        violation_model.eval()
                    logging.info(f"âœ… Violation ëª¨ë¸ì„ {self.device} ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ ì™„ë£Œ (ì¶”ë¡  ëª¨ë“œ í™œì„±í™”)")
                except (AttributeError, TypeError) as e:
                    logging.warning(f"âš ï¸ Violation ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}")
                except Exception as e:
                    logging.error(f"âŒ Violation ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì˜¤ë¥˜: {e}")

            if not pose_trt:
                # PyTorch ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ float() ë° .to() í˜¸ì¶œ
                underlying_pose = getattr(pose_model, "model", None)
                if underlying_pose is not None:
                    # ë¬¸ìì—´ì´ ì•„ë‹ˆê³  float() ë©”ì„œë“œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í˜¸ì¶œ (PyTorch ëª¨ë¸)
                    if not isinstance(underlying_pose, str) and hasattr(underlying_pose, "float"):
                        try:
                            underlying_pose.float()
                        except (AttributeError, TypeError):
                            pass  # ONNX ëª¨ë¸ì´ê±°ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì¸ ê²½ìš° ë¬´ì‹œ
                
                # .to() ë©”ì„œë“œ í˜¸ì¶œ (MPSì¸ ê²½ìš° CPU ì‚¬ìš©)
                try:
                    pose_model.to(pose_device)
                    logging.info(f"âœ… Pose ëª¨ë¸ì„ {pose_device} ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ ì™„ë£Œ")
                except (AttributeError, TypeError) as e:
                    logging.warning(f"âš ï¸ Pose ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}")
                except Exception as e:
                    logging.error(f"âŒ Pose ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì˜¤ë¥˜: {e}")

            if 'cuda' in str(self.device) and (not violation_trt or not pose_trt):
                import torch
                if torch.cuda.is_available():
                    # GPU 0 ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    gpu_id = int(self.device.split(':')[-1]) if ':' in str(self.device) else 0
                    gpu_name = torch.cuda.get_device_name(gpu_id)
                    gpu_memory = torch.cuda.get_device_properties(gpu_id).total_memory / (1024**3)  # GB
                    logging.info(f"GPU {gpu_id} ({gpu_name}) ìµœì í™”: YOLO Violation/Pose ëª¨ë¸ ì‹¤í–‰ (ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB)")
                    torch.backends.cudnn.benchmark = True
                    torch.backends.cudnn.deterministic = False
                    logging.info("âœ… cuDNN ìµœì í™” í™œì„±í™”")
            elif 'mps' in str(self.device) and (not violation_trt or not pose_trt):
                import torch
                if torch.backends.mps.is_available():
                    device_config = config.SystemConfig.get_device_config()
                    gpu_memory = device_config.get('gpu_memory_gb', 8)
                    logging.info(f"MPS ìµœì í™”: YOLO Violation/Pose ëª¨ë¸ ì‹¤í–‰ (ì¶”ì • ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB)")
                    logging.info("âœ… MPS Metal GPU ê°€ì† í™œì„±í™”")
                    # MPS ìµœì í™”: ë©”ëª¨ë¦¬ ê´€ë¦¬ íŒíŠ¸
                    try:
                        # MPSëŠ” í†µí•© ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ëª…ì‹œì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë¶ˆí•„ìš”
                        # í•˜ì§€ë§Œ PyTorchì— íŒíŠ¸ ì œê³µ
                        if hasattr(torch, 'mps'):
                            logging.info("  - MPS ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™” í™œì„±í™”")
                    except:
                        pass

            # ëª¨ë¸ íƒ€ì… ë¡œê¹… (ëª¨ë‘ PyTorch)
            violation_device_str = str(self.device).upper()
            if 'mps' in violation_device_str:
                violation_device_info = "MPS (Metal GPU)"
            elif 'cuda' in violation_device_str:
                violation_device_info = "CUDA GPU"
            else:
                violation_device_info = "CPU"
            
            pose_device_str = str(pose_device).upper()
            if 'mps' in pose_device_str:
                pose_device_info = "MPS (Metal GPU)"
            elif 'cuda' in pose_device_str:
                pose_device_info = "CUDA GPU"
            else:
                pose_device_info = "CPU"
            
            logging.info(f"âœ… Violation ëª¨ë¸: PyTorch ({violation_device_info})")
            logging.info(f"âœ… Pose ëª¨ë¸: PyTorch ({pose_device_info})")

            return violation_model, pose_model, violation_trt, pose_trt
        except Exception as e:
            logging.error(f"YOLO ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            return None, None, False, False

    def _initialize_face_recognition_models(self):
        face_model = None
        face_analyzer = None
        face_database = None
        face_uses_trt = False
        use_adaface = False
        adaface_model_path = None
        face_model_name = 'buffalo_l'  # ê¸°ë³¸ê°’ ì„¤ì • (InsightFace detection ëª¨ë“ˆìš©)

        # InsightFaceê°€ ì—†ìœ¼ë©´ ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ ë¹„í™œì„±í™”
        if not INSIGHTFACE_AVAILABLE:
            logging.warning("InsightFaceê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì–¼êµ´ ì¸ì‹ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            logging.warning("ì„¤ì¹˜ ë°©ë²•: .\\install_insightface.bat")
            return None, None, None, False, False, None

        try:
            # 1. YOLO ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë¡œë“œ (PyTorch .pt íŒŒì¼ ì§ì ‘ ì‚¬ìš©, MPS/CUDA ìµœì í™”)
            face_model, face_uses_trt = self._load_yolo_variant(
                config.Paths.YOLO_FACE_MODEL,
                config.Paths.YOLO_FACE_ENGINE,
                "Face",
                "detect"
            )
            
            if face_model is None:
                raise RuntimeError("YOLO ì–¼êµ´ ê°ì§€ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # PyTorch ëª¨ë¸ ìµœì í™”: float() ë° .to() í˜¸ì¶œ
            underlying_face = getattr(face_model, "model", None)
            if underlying_face is not None:
                # float() ë©”ì„œë“œë¡œ ëª¨ë¸ì„ float32ë¡œ ë³€í™˜ (MPS/CUDA ìµœì í™”)
                if not isinstance(underlying_face, str) and hasattr(underlying_face, "float"):
                    try:
                        underlying_face.float()
                    except (AttributeError, TypeError):
                        pass
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ (MPS/CUDA/CPU)
            try:
                face_model.to(self.device_face)
                # MPS ìµœì í™”: ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì • (ë“œë¡­ì•„ì›ƒ, ë°°ì¹˜ ì •ê·œí™” ìµœì í™”)
                if hasattr(face_model, 'eval'):
                    face_model.eval()
                logging.info(f"âœ… Face ëª¨ë¸ì„ {self.device_face} ë””ë°”ì´ìŠ¤ë¡œ ì´ë™ ì™„ë£Œ (ì¶”ë¡  ëª¨ë“œ í™œì„±í™”)")
            except (AttributeError, TypeError) as e:
                logging.warning(f"âš ï¸ Face ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}")
            except Exception as e:
                logging.error(f"âŒ Face ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì˜¤ë¥˜: {e}")
            
            # ë””ë°”ì´ìŠ¤ ì •ë³´ ë¡œê¹…
            device_str = str(self.device_face).upper()
            if 'mps' in device_str:
                device_info = "MPS (Metal GPU)"
            elif 'cuda' in device_str:
                gpu_id_face = int(self.device_face.split(':')[-1]) if ':' in str(self.device_face) else 0
                device_info = f"CUDA GPU {gpu_id_face}"
            else:
                device_info = "CPU"
            
            logging.info(f"âœ… YOLO ì–¼êµ´ ê°ì§€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: PyTorch ({device_info})")
            
            # 2. InsightFace ëª¨ë¸ ê²½ë¡œ ì„¤ì •
            # InsightFaceëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ~/.insightface/models/ ê²½ë¡œë¥¼ ì°¾ìŒ
            # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œê°€ ìˆìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •
            insightface_models_dir = os.path.normpath(os.path.join(config.BASE_DIR, "../../models/insightface"))
            if os.path.exists(insightface_models_dir):
                # í™˜ê²½ ë³€ìˆ˜ë¡œ InsightFace ëª¨ë¸ ê²½ë¡œ ì„¤ì •
                os.environ['INSIGHTFACE_ROOT'] = os.path.normpath(os.path.join(config.BASE_DIR, "../../models"))
                logging.info(f"InsightFace ëª¨ë¸ ê²½ë¡œ ì„¤ì •: {insightface_models_dir}")
            else:
                # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬)
                default_insightface_dir = os.path.expanduser("~/.insightface/models")
                logging.info(f"ë¡œì»¬ InsightFace ëª¨ë¸ ê²½ë¡œ ì—†ìŒ. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {default_insightface_dir}")
            
            # 2. AdaFace ëª¨ë¸ ì§€ì› í™•ì¸ (í™˜ê²½ ë³€ìˆ˜ë¡œ í™œì„±í™”)
            # ê¸°ë³¸ê°’ì„ trueë¡œ ë³€ê²½í•˜ì—¬ adaface_ir50_ms1mv2 ëª¨ë¸ ìš°ì„  ì‚¬ìš©
            use_adaface = os.getenv('USE_ADA_FACE', 'true').lower() == 'true'
            adaface_model_path = config.Paths.ADAFACE_MODEL if hasattr(config.Paths, 'ADAFACE_MODEL') else None
            
            # AdaFace ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if use_adaface and adaface_model_path:
                if os.path.exists(adaface_model_path):
                    logging.info(f"âœ… AdaFace ëª¨ë¸ íŒŒì¼ ë°œê²¬: {adaface_model_path}")
                else:
                    logging.warning(f"âš ï¸ AdaFace ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {adaface_model_path}")
                    logging.info("ğŸ’¡ buffalo_l ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
                    use_adaface = False
                    adaface_model_path = None
            else:
                use_adaface = False
                adaface_model_path = None
            
            # InsightFaceëŠ” í•­ìƒ 'buffalo_l' ëª¨ë¸ì„ ì‚¬ìš© (detection ëª¨ë“ˆìš©)
            # ì‹¤ì œ ì„ë² ë”© ì¶”ì¶œì€ FastIndustrialRecognizerë¥¼ í†µí•´ AdaFaceë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            face_model_name = 'buffalo_l'
            
            # 3. buffalo_L ëª¨ë¸ ë¡œë“œ (InsightFace - ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œìš©)
            # ì‹œìŠ¤í…œ íë¦„: yolov11n-face.ptë¡œ ì–¼êµ´ ê°ì§€ â†’ ì–¼êµ´ ìë¥´ê¸° â†’ buffalo_Lë¡œ ì„ë² ë”© ì¶”ì¶œ â†’ FAISS ë§¤ì¹­
            # AdaFaceë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°: yolov11n-face.ptë¡œ ì–¼êµ´ ê°ì§€ + ëœë“œë§ˆí¬ ì¶”ì¶œ â†’ FastIndustrialRecognizerë¡œ AdaFace ì„ë² ë”© ì¶”ì¶œ
            import platform
            if 'cuda' in str(self.device_face):
                # CUDA ìš°ì„ , ì‹¤íŒ¨ ì‹œ CPU í´ë°±
                # GPU 1 ì‚¬ìš© (ë©€í‹° GPUì¸ ê²½ìš°)
                gpu_id_face = int(self.device_face.split(':')[-1]) if ':' in str(self.device_face) else 0
                
                # InsightFaceëŠ” CUDAExecutionProviderë¥¼ ì‚¬ìš©í•˜ê³  device_id ì˜µì…˜ìœ¼ë¡œ GPU ì§€ì •
                # ctx_idëŠ” prepare()ì—ì„œ ì‚¬ìš©í•˜ì§€ë§Œ, CUDAExecutionProviderì—ë„ device_idë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
                providers = [
                    ('CUDAExecutionProvider', {'device_id': gpu_id_face}),  # GPU ID ëª…ì‹œì  ì§€ì •
                    'CPUExecutionProvider'
                ]
                ctx_id = gpu_id_face  # ctx_idë¡œ íŠ¹ì • GPU ì§€ì •
                model_info = f"AdaFace ëª¨ë¸" if use_adaface else "buffalo_L ëª¨ë¸"
                logging.info(f"InsightFace GPU {gpu_id_face} ëª¨ë“œ í™œì„±í™” ({model_info} - ì„ë² ë”© ì¶”ì¶œìš©, ctx_id={gpu_id_face}, device_id={gpu_id_face})")
            elif 'mps' in str(self.device_face) and platform.system() == 'Darwin':
                # Mac MPS ì§€ì›: CoreML Execution Provider ì‚¬ìš©
                try:
                    import onnxruntime
                    available_providers = onnxruntime.get_available_providers()
                    if 'CoreMLExecutionProvider' in available_providers:
                        providers = ['CoreMLExecutionProvider', 'CPUExecutionProvider']
                        ctx_id = 0  # MPSëŠ” ë‹¨ì¼ GPUë¡œ ì²˜ë¦¬
                        model_info = f"AdaFace ëª¨ë¸" if use_adaface else "buffalo_L ëª¨ë¸"
                        logging.info(f"InsightFace MPS ëª¨ë“œ í™œì„±í™” ({model_info} - ì„ë² ë”© ì¶”ì¶œìš©, CoreML ì‚¬ìš©)")
                    else:
                        providers = ['CPUExecutionProvider']
                        ctx_id = -1
                        model_info = f"AdaFace ëª¨ë¸" if use_adaface else "buffalo_L ëª¨ë¸"
                        logging.warning(f"CoreML Providerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ ({model_info})")
                except ImportError:
                    providers = ['CPUExecutionProvider']
                    ctx_id = -1
                    model_info = f"AdaFace ëª¨ë¸" if use_adaface else "buffalo_L ëª¨ë¸"
                    logging.warning(f"onnxruntimeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ ({model_info})")
            else:
                providers = ['CPUExecutionProvider']
                ctx_id = -1  # CPU ì‚¬ìš©
                model_info = f"AdaFace ëª¨ë¸" if use_adaface else "buffalo_L ëª¨ë¸"
                logging.info(f"InsightFace CPU ëª¨ë“œ í™œì„±í™” ({model_info} - ì„ë² ë”© ì¶”ì¶œìš©)")
            
            # InsightFace ì´ˆê¸°í™” (buffalo_l ëª¨ë¸ ì‚¬ìš© - detection ëª¨ë“ˆìš©)
            # ì‹¤ì œ ì–¼êµ´ ê°ì§€ëŠ” YOLO(yolov11n-face.pt)ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, 
            # InsightFaceëŠ” detection ëª¨ë“ˆì´ ìˆì–´ì•¼ ì •ìƒ ì‘ë™í•˜ë¯€ë¡œ í¬í•¨
            # AdaFaceë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì—ë„ InsightFaceëŠ” 'buffalo_l'ì„ ì‚¬ìš©í•˜ê³ , 
            # ì‹¤ì œ ì„ë² ë”© ì¶”ì¶œì€ FastIndustrialRecognizerë¥¼ í†µí•´ AdaFaceë¥¼ ì‚¬ìš©
            face_analyzer = FaceAnalysis(
                name=face_model_name,  # í•­ìƒ 'buffalo_l' (detection ëª¨ë“ˆìš©)
                providers=providers,
                allowed_modules=['detection', 'recognition']  # detection ëª¨ë“ˆ í¬í•¨ (í•„ìˆ˜)
            )
            
            # det_size ì„¤ì • (ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”)
            # ctx_idë¡œ íŠ¹ì • GPU ì§€ì • (ë©€í‹° GPU ì§€ì›)
            det_size = config.Thresholds.FACE_DETECTION_SIZE
            face_analyzer.prepare(ctx_id=ctx_id, det_size=det_size)
            
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ Provider í™•ì¸
            try:
                actual_providers = face_analyzer.models['recognition'].session.get_providers()
                logging.info(f"{face_model_name} ëª¨ë¸(InsightFace) ë¡œë“œ ì™„ë£Œ (Provider: {actual_providers}, ctx_id={ctx_id})")
            except Exception as e:
                logging.info(f"{face_model_name} ëª¨ë¸(InsightFace) ë¡œë“œ ì™„ë£Œ (Provider: {providers}, ctx_id={ctx_id})")
            
            # AdaFace ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ ë¡œê¹…
            if use_adaface and adaface_model_path:
                logging.info(f"âœ… AdaFace ëª¨ë¸ í™œì„±í™”: {adaface_model_path}")
                logging.info("ğŸ’¡ ì‹¤ì œ ì„ë² ë”© ì¶”ì¶œì€ FastIndustrialRecognizerë¥¼ í†µí•´ AdaFaceë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                logging.info("âœ… buffalo_l ëª¨ë¸ ì‚¬ìš© (InsightFace ê¸°ë³¸ ëª¨ë¸)")

            # 3. FAISS ì¸ë±ìŠ¤ ë¡œë“œ (face_index.faiss, face_index.faiss.labels.npy)
            # face_embeddings.npyëŠ” FAISS ì¸ë±ìŠ¤ì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ
            logging.info(f"ğŸ” FAISS ì¸ë±ìŠ¤ ê²½ë¡œ í™•ì¸: {config.Paths.FAISS_INDEX} (ì¡´ì¬: {os.path.exists(config.Paths.FAISS_INDEX)})")
            logging.info(f"ğŸ” FAISS ë ˆì´ë¸” ê²½ë¡œ í™•ì¸: {config.Paths.FAISS_LABELS} (ì¡´ì¬: {os.path.exists(config.Paths.FAISS_LABELS)})")
            face_index, face_labels = self._load_face_database(config.Paths.FAISS_INDEX)
            face_database = (face_index, face_labels)  # íŠœí”Œë¡œ ì €ì¥
            logging.info(f"âœ… FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ: ì¸ë±ìŠ¤={face_index.ntotal if face_index else 0}ê°œ, ë ˆì´ë¸”={len(face_labels) if face_labels is not None else 0}ê°œ")
            if face_index is None or (hasattr(face_index, 'ntotal') and face_index.ntotal == 0):
                logging.error(f"âŒ FAISS ì¸ë±ìŠ¤ê°€ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ì–¼êµ´ ì¸ì‹ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            if face_labels is None or len(face_labels) == 0:
                logging.error(f"âŒ FAISS ë ˆì´ë¸”ì´ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ì–¼êµ´ ì¸ì‹ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        except Exception as e:
            logging.error(f"ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", exc_info=True)
            face_model = None
            face_analyzer = None # ì‹¤íŒ¨ ì‹œ Noneìœ¼ë¡œ ì„¤ì •
            face_database = None
            face_uses_trt = False
            use_adaface = False
            adaface_model_path = None

        return face_model, face_analyzer, face_database, face_uses_trt, use_adaface, adaface_model_path

    @staticmethod
    def _load_face_database(index_path: str) -> Tuple[Optional[object], Optional[np.ndarray]]:
        """
        FAISS ì¸ë±ìŠ¤ì™€ ë ˆì´ë¸” íŒŒì¼ì„ í•¨ê»˜ ë¡œë“œ
        
        ë¡œë“œí•˜ëŠ” íŒŒì¼:
        - face_index.faiss: FAISS ì¸ë±ìŠ¤ (face_embeddings.npyì˜ ë°ì´í„°ê°€ í¬í•¨ë¨)
        - face_index.faiss.labels.npy: ì¸ë¬¼ ì´ë¦„ ë ˆì´ë¸”
        
        Returns:
            (faiss_index, labels): FAISS ì¸ë±ìŠ¤ì™€ ë ˆì´ë¸” ë°°ì—´ íŠœí”Œ
        """
        try:
            # configì—ì„œ ì„¤ì •ëœ ê²½ë¡œ ì‚¬ìš© (face/data/face_index.faiss)
            if not os.path.exists(index_path):
                # í´ë°± 1: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸° (í•˜ìœ„ í˜¸í™˜ì„±)
                project_root_index = os.path.normpath(os.path.join(config.BASE_DIR, "../..", "face_index.faiss"))
                if os.path.exists(project_root_index):
                    index_path = project_root_index
                    logging.info(f"âœ… FAISS ì¸ë±ìŠ¤ ë°œê²¬ (í”„ë¡œì íŠ¸ ë£¨íŠ¸): {index_path}")
                else:
                    # í´ë°± 2: face/data í´ë”ì—ì„œ ì°¾ê¸° (ìƒˆ ê²½ë¡œ)
                    face_data_index = os.path.normpath(os.path.join(config.BASE_DIR, "../..", "face", "data", "face_index.faiss"))
                    if os.path.exists(face_data_index):
                        index_path = face_data_index
                        logging.info(f"âœ… FAISS ì¸ë±ìŠ¤ ë°œê²¬ (face/data): {index_path}")
                    else:
                        logging.warning(f"Faiss ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config.Paths.FAISS_INDEX}")
                        # ë¹ˆ ì¸ë±ìŠ¤ ë°˜í™˜
                        empty_index = faiss.IndexFlatIP(512)
                        empty_labels = np.array([])
                        return empty_index, empty_labels

            # ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            labels_path = config.Paths.FAISS_LABELS
            logging.info(f"FAISS ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œ í™•ì¸: {labels_path} (ì¡´ì¬: {os.path.exists(labels_path)})")
            if not os.path.exists(labels_path):
                # í´ë°± 1: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸° (í•˜ìœ„ í˜¸í™˜ì„±)
                project_root_labels = os.path.normpath(os.path.join(config.BASE_DIR, "../..", "face_index.faiss.labels.npy"))
                if os.path.exists(project_root_labels):
                    labels_path = project_root_labels
                    logging.info(f"âœ… FAISS ë ˆì´ë¸” ë°œê²¬ (í”„ë¡œì íŠ¸ ë£¨íŠ¸): {labels_path}")
                else:
                    # í´ë°± 2: face/data í´ë”ì—ì„œ ì°¾ê¸° (ìƒˆ ê²½ë¡œ)
                    face_data_labels = os.path.normpath(os.path.join(config.BASE_DIR, "../..", "face", "data", "face_index.faiss.labels.npy"))
                    if os.path.exists(face_data_labels):
                        labels_path = face_data_labels
                        logging.info(f"âœ… FAISS ë ˆì´ë¸” ë°œê²¬ (face/data): {labels_path}")
                    else:
                        abs_path = os.path.abspath(labels_path)
                        logging.warning(f"Faiss ë ˆì´ë¸” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labels_path} (ì ˆëŒ€ ê²½ë¡œ: {abs_path})")
                        labels_path = None

            # ì¸ë±ìŠ¤ ë¡œë“œ
            dimension = 512  # InsightFace ì„ë² ë”© ì°¨ì›
            index = faiss.read_index(index_path)

            # FAISS ì¸ë±ìŠ¤ë¥¼ GPUë¡œ ì´ì „ (ê¸°ë³¸ í™œì„±í™”: ì„±ëŠ¥ í–¥ìƒ)
            # ì–¼êµ´ ì¸ì‹ì´ GPU 1ì„ ì‚¬ìš©í•˜ë¯€ë¡œ FAISSë„ GPU 1ì„ ì‚¬ìš©í•˜ì—¬ ë¶€í•˜ ë¶„ì‚°
            try:
                import torch as _torch
                if config.Thresholds.USE_FAISS_GPU and _torch.cuda.is_available():
                    # ì–¼êµ´ ì¸ì‹ì´ ì‚¬ìš©í•˜ëŠ” GPU ID í™•ì¸ (ë©€í‹° GPUì¸ ê²½ìš° GPU 1)
                    gpu_count = _torch.cuda.device_count()
                    faiss_gpu_id = 1 if gpu_count >= 2 else 0  # GPU 1 ì‚¬ìš© (ë©€í‹° GPUì¸ ê²½ìš°)
                    
                    # faiss-gpu íŒ¨í‚¤ì§€ í™•ì¸
                    try:
                        gpu_res = faiss.StandardGpuResources()
                    except AttributeError:
                        # faiss-cpuë§Œ ì„¤ì¹˜ëœ ê²½ìš°
                        logging.warning("âš ï¸ FAISS GPU ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (faiss-cpuë§Œ ì„¤ì¹˜ë¨)")
                        logging.info("ğŸ’¡ FAISS GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
                        logging.info("   1. Conda ì‚¬ìš©: conda install -c pytorch faiss-gpu")
                        logging.info("   2. CPU ë²„ì „ ê³„ì† ì‚¬ìš© (í˜„ì¬ ì„¤ì •)")
                        logging.info("   3. .env íŒŒì¼ì— USE_FAISS_GPU=0 ì„¤ì •í•˜ì—¬ CPU ëª¨ë“œ ëª…ì‹œ")
                        raise AttributeError("faiss.StandardGpuResources not available (faiss-cpu only)")
                    
                    # ì„ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì†Œí™”ë¡œ ì•ˆì •ì„± í–¥ìƒ
                    try:
                        gpu_res.setTempMemory(0)
                    except Exception:
                        pass
                    index = faiss.index_cpu_to_gpu(gpu_res, faiss_gpu_id, index)
                    logging.info(f"âœ… FAISS ì¸ë±ìŠ¤ë¥¼ GPU {faiss_gpu_id}ë¡œ ì´ì „ ì™„ë£Œ (ì„±ëŠ¥ í–¥ìƒ, USE_FAISS_GPU=1)")
                else:
                    logging.info("FAISS CPU ì¸ë±ìŠ¤ ì‚¬ìš© (USE_FAISS_GPU=0 ë˜ëŠ” CUDA ë¹„í™œì„±)")
            except AttributeError as attr_e:
                # faiss-gpuê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
                logging.warning(f"âš ï¸ FAISS GPU ì´ì „ ì‹¤íŒ¨: {attr_e}")
                logging.info("ğŸ’¡ CPU ëª¨ë“œë¡œ ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤ (ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)")
                logging.info("   FAISS GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ condaë¥¼ í†µí•´ faiss-gpuë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”")
            except Exception as gpu_e:
                logging.warning(f"âš ï¸ FAISS GPU ì´ì „ ì‹¤íŒ¨, CPU ì¸ë±ìŠ¤ ì‚¬ìš©: {gpu_e}")
                logging.info("ğŸ’¡ CPU ëª¨ë“œë¡œ ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤ (ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)")

            # ë ˆì´ë¸” ë¡œë“œ
            labels = np.array([])
            if labels_path and os.path.exists(labels_path):
                labels = np.load(labels_path, allow_pickle=True)
                logging.info(f"âœ… Faiss ì¸ë±ìŠ¤ ë° ë ˆì´ë¸” ë¡œë“œ ì™„ë£Œ. ì¸ë±ìŠ¤={index.ntotal}ê°œ ì„ë² ë”©, ë ˆì´ë¸”={len(labels)}ê°œ í¬í•¨.")
                if len(labels) == 0:
                    logging.error(f"âŒ ë ˆì´ë¸” íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë‹¤ì‹œ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.")
                elif index.ntotal != len(labels):
                    logging.warning(f"âš ï¸ ì¸ë±ìŠ¤ í¬ê¸°({index.ntotal})ì™€ ë ˆì´ë¸” í¬ê¸°({len(labels)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            else:
                logging.error(f"âŒ Faiss ë ˆì´ë¸” íŒŒì¼ ì—†ìŒ. ì¸ë±ìŠ¤ë§Œ ë¡œë“œ: {index.ntotal}ê°œ ì„ë² ë”©. ì–¼êµ´ ì¸ì‹ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")

            return index, labels
        except Exception as e:
            logging.error(f"Faiss ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
            # ë¹ˆ ì¸ë±ìŠ¤ ë°˜í™˜
            empty_index = faiss.IndexFlatIP(512)
            empty_labels = np.array([])
            return empty_index, empty_labels

    def cleanup(self):
        logging.info("SafetySystem ì •ë¦¬ë¨.")

    # --- í—¬í¼ í•¨ìˆ˜ (Static Methods) ---
    # ì´ í•¨ìˆ˜ë“¤ì€ server.pyì˜ process_single_frameì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.

    @staticmethod
    def _scale_boxes(
        boxes: Any, 
        w_scale: float, 
        h_scale: float, 
        names: Dict[int, str]
    ) -> Dict[str, List[Dict[str, Any]]]:
        scaled: Dict[str, List[Dict[str, Any]]] = defaultdict(list)
        if boxes is None or len(boxes) == 0:
            return scaled

        for box in boxes:
            try:
                class_name = names[int(box.cls[0])]
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                confidence = float(box.conf[0].cpu().numpy())
                scaled[class_name].append({
                    'bbox': (x1 * w_scale, y1 * h_scale, x2 * w_scale, y2 * h_scale),
                    'confidence': confidence
                })
            except Exception as e:
                logging.warning(f"ë°•ìŠ¤ ìŠ¤ì¼€ì¼ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return scaled

    @staticmethod
    def _scale_poses(
        pose_result: Any, 
        w_scale: float, 
        h_scale: float, 
        orig_shape: Tuple[int, int]
    ) -> List[Dict[str, Any]]:
        scaled: List[Dict[str, Any]] = []
        if pose_result.keypoints and pose_result.boxes is not None and pose_result.boxes.id is not None:
            tracker_ids = pose_result.boxes.id.int().cpu().numpy()
            for idx, (kpts, tracker_id) in enumerate(zip(pose_result.keypoints, tracker_ids)):
                try:
                    if torch.sum(kpts.conf > config.Thresholds.POSE_CONFIDENCE) >= config.Thresholds.MIN_VISIBLE_KEYPOINTS:
                        kpts_data = kpts.data.clone()
                        kpts_data[..., 0] *= w_scale
                        kpts_data[..., 1] *= h_scale
                        box = pose_result.boxes[idx].xyxy[0].cpu().numpy()
                        scaled_box = (box[0] * w_scale, box[1] * h_scale, box[2] * w_scale, box[3] * h_scale)

                        scaled.append({'keypoints': Keypoints(kpts_data, orig_shape), 'bbox_xyxy': scaled_box,
                                       'tracker_id': tracker_id})
                except Exception as e:
                    logging.warning(f"í¬ì¦ˆ ìŠ¤ì¼€ì¼ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        return scaled

    # ( ... _get_frame_batch, cleanup, _update_people_states, _draw_results, _create_grid_display ë“±ë“± ... ëª¨ë‘ ì‚­ì œ ...)
    # ( ... _match_and_update_people, _check_fall_status, _check_safety_gear_status ë“±ë“± ... ëª¨ë‘ ì‚­ì œ ...)
    # SafetySystem í´ë˜ìŠ¤ëŠ” ì´ì œ ëª¨ë¸ ë¡œë”©ê³¼ í—¬í¼ í•¨ìˆ˜(_scale_boxes, _scale_poses)ë§Œ ì œê³µí•©ë‹ˆë‹¤.
