# ai_processors.py - AI ì²˜ë¦¬ ë¡œì§
"""
AI ëª¨ë¸ ì²˜ë¦¬ í•¨ìˆ˜ ëª¨ë“ˆ
PPE ê°ì§€, ì–¼êµ´ ì¸ì‹, ìœ„í—˜ í–‰ë™ ê°ì§€ ë“±
"""
import logging
import time
from typing import Dict, List, Tuple, Optional, Any, Set

import cv2
import numpy as np
from ultralytics.engine.results import Keypoints

import utils
import config
from utils import find_best_match_faiss
from exceptions import (
    ProcessingError,
    FaceRecognitionError
)
from state import (
    fall_start_times,
    FALL_DURATION_THRESHOLD
)
from fast_face_recognizer import FastIndustrialRecognizer


def _process_ppe_detection(
    person_box: Tuple[int, int, int, int], 
    all_detections: Dict[str, List[Dict[str, Any]]],
    used_ppe_boxes: Optional[Set[Tuple[int, int, int, int]]] = None,
    person_id: Optional[str] = None
) -> Tuple[List[str], List[Dict[str, Any]]]:
    """
    PPE ê°ì§€ ì „ìš© í•¨ìˆ˜ (ì–¼êµ´ ì¸ì‹ê³¼ ë…ë¦½ì ìœ¼ë¡œ í•­ìƒ ì‹¤í–‰)
    ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒë„ ì˜ ì¡ê¸° ìœ„í•´ ìµœê³  ì„±ëŠ¥ ì„¤ì •
    
    Args:
        person_box: ì‚¬ëŒ ë°”ìš´ë”© ë°•ìŠ¤ (x1, y1, x2, y2)
        all_detections: ëª¨ë“  ê°ì§€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        used_ppe_boxes: ì´ë¯¸ ì‚¬ìš©ëœ PPE ë°•ìŠ¤ ì§‘í•©
        person_id: ì‚¬ëŒ ì‹ë³„ì (ë¡œê¹…ìš©)
    
    Returns:
        ppe_violations: PPE ìœ„ë°˜ ëª©ë¡ (ì˜ˆ: ["ì•ˆì „ëª¨"])
        ppe_boxes: PPE ê°ì§€ëœ ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"bbox": (x1,y1,x2,y2), "class": "Safety Vest", "conf": 0.9}, ...]
    """
    ppe_violations = []
    ppe_boxes: List[Dict[str, Any]] = []  # PPE ê°ì§€ ë°•ìŠ¤ ì •ë³´
    person_id_text = person_id or "UNKNOWN"
    
    try:
        x1, y1, x2, y2 = person_box
        box_w = x2 - x1
        box_h = y2 - y1
        box_area = box_w * box_h
        box_center_x = (x1 + x2) / 2
        box_center_y = (y1 + y2) / 2
        
        logging.debug(f"[PPE {person_id_text}] PPE ê°ì§€ ì‹œì‘: person_box=({x1},{y1},{x2},{y2}), "
                     f"í¬ê¸°={box_w}x{box_h}, ë©´ì ={box_area:.0f}pxÂ²")
        
        # ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒ(ì‘ì€ ë°•ìŠ¤)ì„ ìœ„í•œ ë™ì  IoU ì„ê³„ê°’ ì¡°ì •
        # ì°©ìš©í•œ PPE ê°ì§€ì™€ ì˜¤íƒì§€ ë°©ì§€ì˜ ê· í˜• ìœ ì§€
        if box_area < 5000:  # ë§¤ìš° ì‘ì€ ë°•ìŠ¤ (ë©€ë¦¬ ìˆëŠ” ì‚¬ëŒ)
            ppe_iou_threshold = 0.05  # ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ : 0.10 -> 0.05
        elif box_area < 10000:  # ì‘ì€ ë°•ìŠ¤
            ppe_iou_threshold = 0.08  # ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ : 0.15 -> 0.08
        elif box_area < 20000:  # ì¤‘ê°„ ë°•ìŠ¤
            ppe_iou_threshold = 0.12  # ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ : 0.20 -> 0.12
        else:
            ppe_iou_threshold = 0.15  # ì¼ë°˜ ë°•ìŠ¤ (ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ : 0.25 -> 0.15)
        
        relaxed_iou_threshold = ppe_iou_threshold * 0.5  # ì™„í™”ëœ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚°
        
        logging.debug(f"[PPE {person_id_text}] IoU ì„ê³„ê°’ ì„¤ì •: ê¸°ë³¸={ppe_iou_threshold:.3f}, "
                     f"ì™„í™”={relaxed_iou_threshold:.3f}, ë°•ìŠ¤ë©´ì ={box_area:.0f}pxÂ²")
        
        # ì´ë¯¸ ì‚¬ìš©ëœ PPE ë°•ìŠ¤ ì¶”ì  (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
        if used_ppe_boxes is None:
            used_ppe_boxes = set()
        
        # ëª¨ë“  PPE í´ë˜ìŠ¤ ìˆ˜ì§‘ (ì¤€ìˆ˜ ë° ìœ„ë°˜ ëª¨ë‘) - ë§ˆìŠ¤í¬ ì œì™¸
        ppe_class_names = set()
        for rule, classes in config.Constants.SAFETY_RULES_MAP.items():
            # ë§ˆìŠ¤í¬ëŠ” ì œì™¸
            if rule == "ë§ˆìŠ¤í¬":
                continue
            ppe_class_names.add(classes["compliance"])
            ppe_class_names.add(classes["violation"])
        
        # person_boxì™€ ê²¹ì¹˜ëŠ” ëª¨ë“  PPE ë°•ìŠ¤ ìˆ˜ì§‘ (ì¤€ìˆ˜ í´ë˜ìŠ¤ë§Œ, ìœ„ë°˜ í´ë˜ìŠ¤ëŠ” ìœ„ë°˜ íŒì • ë‹¨ê³„ì—ì„œ ì²˜ë¦¬)
        compliance_classes = set()
        violation_classes = set()
        for rule, classes in config.Constants.SAFETY_RULES_MAP.items():
            if rule == "ë§ˆìŠ¤í¬":
                continue
            compliance_classes.add(classes["compliance"])
            violation_classes.add(classes["violation"])
        
        for ppe_class in ppe_class_names:
            # ìœ„ë°˜ í´ë˜ìŠ¤ëŠ” ìœ„ë°˜ íŒì • ë‹¨ê³„ì—ì„œë§Œ ì²˜ë¦¬ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
            if ppe_class in violation_classes:
                continue
                
            if ppe_class in all_detections and all_detections[ppe_class]:
                detection_count = len(all_detections[ppe_class])
                logging.debug(f"[PPE {person_id_text}] {ppe_class} í´ë˜ìŠ¤ ê°ì§€: {detection_count}ê°œ")
                
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ì°©ìš©í•œ PPE ê°ì§€ì™€ ì˜¤íƒì§€ ë°©ì§€ì˜ ê· í˜•)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                # ê±°ë¦¬ ì„ê³„ê°’ ì¡°ì • (ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ : 0.4/0.3 -> 0.5/0.4)
                distance_threshold = box_diagonal * (0.5 if box_area < 10000 else 0.4)
                
                for det_idx, det in enumerate(all_detections[ppe_class]):
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            logging.debug(f"[PPE {person_id_text}] {ppe_class}[{det_idx}] ìŠ¤í‚µ: ì´ë¯¸ ì‚¬ìš©ëœ ë°•ìŠ¤")
                            continue
                        
                        conf = det.get('conf', 0.9)
                        
                        # PPE ë°•ìŠ¤ í¬ê¸° ë° ìœ„ì¹˜ ê²€ì¦ ì¶”ê°€ (ì˜¤íƒì§€ ë°©ì§€)
                        det_w = dx2 - dx1
                        det_h = dy2 - dy1
                        det_area = det_w * det_h
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # PPE ë°•ìŠ¤ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í¬ë©´ ì œì™¸ (ì˜¤íƒì§€ ë°©ì§€, í•˜ì§€ë§Œ ì™„í™”)
                        # ì‚¬ëŒ ë°•ìŠ¤ì˜ 0.5% ë¯¸ë§Œì´ê±°ë‚˜ 60% ì´ˆê³¼ë©´ ì œì™¸ (ì°©ìš©í•œ PPE ê°ì§€ ê°œì„ )
                        min_ppe_area = box_area * 0.005  # ìµœì†Œ 0.5% (1% -> 0.5%, ì‘ì€ PPEë„ ê°ì§€)
                        max_ppe_area = box_area * 0.60  # ìµœëŒ€ 60% (50% -> 60%, í° PPEë„ ê°ì§€)
                        area_ratio = (det_area / box_area) * 100 if box_area > 0 else 0
                        
                        if det_area < min_ppe_area or det_area > max_ppe_area:
                            logging.debug(f"[PPE {person_id_text}] {ppe_class}[{det_idx}] ìŠ¤í‚µ: í¬ê¸° ë²”ìœ„ ì´ˆê³¼ "
                                        f"(ë©´ì ={det_area:.0f}pxÂ², ë¹„ìœ¨={area_ratio:.2f}%, "
                                        f"ë²”ìœ„={min_ppe_area:.0f}~{max_ppe_area:.0f}pxÂ²)")
                            continue
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€, ì˜ì ë“± ì˜¤íƒì§€ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            logging.debug(f"[PPE {person_id_text}] {ppe_class}[{det_idx}] ìŠ¤í‚µ: person_box ë°–ì˜ PPE (ì¤‘ì‹¬ì =({det_center_x:.1f},{det_center_y:.1f}), person_box=({x1},{y1},{x2},{y2}))")
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ (ì˜ì ë“± ì˜¤íƒì§€ ë°©ì§€)
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê³„ì‚°
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        # IoU ê³„ì‚°
                        iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                        
                        is_match = False
                        match_reason = ""
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        if center_distance < distance_threshold:
                            is_match = True
                            match_reason = f"ê±°ë¦¬ê·¼ì ‘({center_distance:.1f}<{distance_threshold:.1f})"
                        else:
                            # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                            if iou > ppe_iou_threshold:
                                is_match = True
                                match_reason = f"IoU({iou:.3f}>{ppe_iou_threshold:.3f})"
                            else:
                                match_reason = f"IoUë¶€ì¡±({iou:.3f}<={ppe_iou_threshold:.3f})"
                        
                        logging.debug(f"[PPE {person_id_text}] {ppe_class}[{det_idx}] í‰ê°€: "
                                    f"bbox=({dx1},{dy1},{dx2},{dy2}), conf={conf:.3f}, "
                                    f"IoU={iou:.3f}, ì¤‘ì‹¬ê±°ë¦¬={center_distance:.1f}px, "
                                    f"ë©´ì ë¹„ìœ¨={area_ratio:.2f}%, ë§¤ì¹­={'âœ…' if is_match else 'âŒ'}({match_reason})")
                        
                        if is_match:
                            # PPE ë°•ìŠ¤ ì •ë³´ ì €ì¥ ë° ì‚¬ìš©ëœ ë°•ìŠ¤ë¡œ í‘œì‹œ
                            ppe_boxes.append({
                                "bbox": det_bbox_tuple,
                                "class": ppe_class,
                                "conf": conf
                            })
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            logging.info(f"[PPE {person_id_text}] âœ… {ppe_class} ë§¤ì¹­ ì„±ê³µ: "
                                       f"bbox=({dx1},{dy1},{dx2},{dy2}), conf={conf:.3f}, IoU={iou:.3f}")
        
        # PPE ë°•ìŠ¤ ì¤‘ë³µ ì œê±° (IoU ê¸°ë°˜, ê°™ì€ í´ë˜ìŠ¤ ë‚´ì—ì„œë§Œ)
        if len(ppe_boxes) > 1:
            # í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
            ppe_by_class: Dict[str, List[Dict[str, Any]]] = {}
            for ppe_box in ppe_boxes:
                ppe_class = ppe_box['class']
                if ppe_class not in ppe_by_class:
                    ppe_by_class[ppe_class] = []
                ppe_by_class[ppe_class].append(ppe_box)
            
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ì¤‘ë³µ ì œê±° (IoU > 0.6ì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼, confidenceê°€ ë†’ì€ ê²ƒë§Œ ìœ ì§€)
            # IoU ì„ê³„ê°’ì„ 0.5 -> 0.6ìœ¼ë¡œ ìƒí–¥í•˜ì—¬ ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°
            filtered_ppe_boxes: List[Dict[str, Any]] = []
            for ppe_class, boxes in ppe_by_class.items():
                if len(boxes) == 1:
                    filtered_ppe_boxes.append(boxes[0])
                else:
                    # confidence ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ê²ƒë¶€í„°)
                    boxes_sorted = sorted(boxes, key=lambda x: x['conf'], reverse=True)
                    kept_indices: List[int] = []
                    
                    for i, box1 in enumerate(boxes_sorted):
                        bx1, by1, bx2, by2 = box1['bbox']
                        is_duplicate = False
                        
                        # ì´ë¯¸ ìœ ì§€ëœ ë°•ìŠ¤ì™€ IoU ê³„ì‚°
                        for j in kept_indices:
                            box2 = boxes_sorted[j]
                            bx3, by3, bx4, by4 = box2['bbox']
                            iou = utils.calculate_iou((bx1, by1, bx2, by2), (bx3, by3, bx4, by4))
                            
                            # IoUê°€ 0.6 ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼ (0.5 -> 0.6, ë” ì—„ê²©í•œ ì¤‘ë³µ ì œê±°)
                            if iou > 0.6:
                                is_duplicate = True
                                break
                        
                        if not is_duplicate:
                            kept_indices.append(i)
                    
                    # ìœ ì§€ëœ ë°•ìŠ¤ë§Œ ì¶”ê°€
                    for idx in kept_indices:
                        filtered_ppe_boxes.append(boxes_sorted[idx])
            
            ppe_boxes = filtered_ppe_boxes
        
        # ìœ„ë°˜ íŒì • ë¡œì§ - ë§ˆìŠ¤í¬ ì œì™¸
        logging.debug(f"[PPE {person_id_text}] ìœ„ë°˜ íŒì • ì‹œì‘: ê·œì¹™ ìˆ˜={len([r for r in config.Constants.SAFETY_RULES_MAP.keys() if r != 'ë§ˆìŠ¤í¬'])}")
        
        for rule, classes in config.Constants.SAFETY_RULES_MAP.items():
            # ë§ˆìŠ¤í¬ëŠ” ì œì™¸
            if rule == "ë§ˆìŠ¤í¬":
                continue
            comp_cls, viol_cls = classes["compliance"], classes["violation"]
            is_compliance = False
            is_violation = False
            
            logging.debug(f"[PPE {person_id_text}] ê·œì¹™ '{rule}' í‰ê°€ ì‹œì‘: "
                        f"ì¤€ìˆ˜í´ë˜ìŠ¤={comp_cls}, ìœ„ë°˜í´ë˜ìŠ¤={viol_cls}")
            
            # ì¤€ìˆ˜(ì°©ìš©) íŒì •: ì¤‘ì‹¬ì  ê±°ë¦¬ ë¨¼ì € ê³„ì‚°, IoUëŠ” ë‚˜ì¤‘ì— (ì„±ëŠ¥ ìµœì í™”)
            if comp_cls in all_detections and all_detections[comp_cls]:
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€: ë” ì—„ê²©í•˜ê²Œ)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                distance_threshold = box_diagonal * (0.6 if box_area < 10000 else 0.5)  # 0.5->0.6, 0.4->0.5 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                
                for det in all_detections[comp_cls]:
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            continue
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€, ì˜ì ë“± ì˜¤íƒì§€ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ
                        
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        if center_distance < distance_threshold:
                            is_compliance = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            logging.debug(f"[PPE {person_id_text}] âœ… PPE ì¤€ìˆ˜ ë§¤ì¹­ ì„±ê³µ: {rule} - ê±°ë¦¬={center_distance:.1f}, ppe_box={det_bbox_tuple}, person_box=({x1},{y1},{x2},{y2})")
                            break
                        
                        # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                        iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                        if iou > ppe_iou_threshold:
                            is_compliance = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            logging.debug(f"[PPE {person_id_text}] âœ… PPE ì¤€ìˆ˜ ë§¤ì¹­ ì„±ê³µ: {rule} - IoU={iou:.4f}, ppe_box={det_bbox_tuple}, person_box=({x1},{y1},{x2},{y2})")
                            break
            
            # ìœ„ë°˜(ë¯¸ì°©ìš©) íŒì •: ì¤‘ì‹¬ì  ê±°ë¦¬ ë¨¼ì € ê³„ì‚°, IoUëŠ” ë‚˜ì¤‘ì— (ì„±ëŠ¥ ìµœì í™”)
            if viol_cls in all_detections and all_detections[viol_cls]:
                # ê±°ë¦¬ ì„ê³„ê°’ ë¯¸ë¦¬ ê³„ì‚° (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€: ë” ì—„ê²©í•˜ê²Œ)
                box_diagonal = ((box_w ** 2 + box_h ** 2) ** 0.5)
                distance_threshold = box_diagonal * (0.6 if box_area < 10000 else 0.5)  # 0.5->0.6, 0.4->0.5 (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€)
                
                for det in all_detections[viol_cls]:
                    if det and 'bbox' in det and det['bbox'] and len(det['bbox']) == 4:
                        dx1, dy1, dx2, dy2 = det['bbox']
                        det_bbox_tuple = (int(dx1), int(dy1), int(dx2), int(dy2))
                        
                        # ì´ë¯¸ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ë§¤ì¹­ëœ PPE ë°•ìŠ¤ëŠ” ì œì™¸ (ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€)
                        if det_bbox_tuple in used_ppe_boxes:
                            continue
                        
                        # ì¤‘ì‹¬ì  ê±°ë¦¬ ê¸°ë°˜ íŒì • ë¨¼ì € (IoUë³´ë‹¤ ë¹ ë¦„)
                        det_center_x = (dx1 + dx2) / 2
                        det_center_y = (dy1 + dy2) / 2
                        
                        # person_box ë‚´ë¶€ í¬í•¨ ì¡°ê±´ ì¶”ê°€ (ë‹¤ë¥¸ ì‚¬ëŒ PPE ì˜¤ë§¤ì¹­ ë°©ì§€, ì˜ì ë“± ì˜¤íƒì§€ ë°©ì§€)
                        # PPE ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì ì´ person_box ë‚´ë¶€ì— ìˆì–´ì•¼ í•¨
                        ppe_center_in_person = (x1 <= det_center_x <= x2 and y1 <= det_center_y <= y2)
                        if not ppe_center_in_person:
                            continue  # person_box ë°–ì˜ PPEëŠ” ë¬´ì‹œ
                        
                        center_distance = ((box_center_x - det_center_x) ** 2 + (box_center_y - det_center_y) ** 2) ** 0.5
                        
                        if center_distance < distance_threshold:
                            is_violation = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            # ìœ„ë°˜ í´ë˜ìŠ¤ë„ ppe_boxesì— ì¶”ê°€ (ë¡œê¹… ë° ì‹œê°í™”ìš©)
                            ppe_boxes.append({
                                "bbox": det_bbox_tuple,
                                "class": viol_cls,
                                "conf": det.get('conf', 0.9)
                            })
                            logging.info(f"[PPE {person_id_text}] âœ… {viol_cls} ìœ„ë°˜ ë§¤ì¹­ ì„±ê³µ: "
                                       f"bbox=({dx1},{dy1},{dx2},{dy2}), conf={det.get('conf', 0.9):.3f}, ê±°ë¦¬={center_distance:.1f}")
                            break
                        
                        # ê±°ë¦¬ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ IoU ê³„ì‚° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
                        iou = utils.calculate_iou((x1, y1, x2, y2), (dx1, dy1, dx2, dy2))
                        if iou > ppe_iou_threshold:
                            is_violation = True
                            used_ppe_boxes.add(det_bbox_tuple)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                            # ìœ„ë°˜ í´ë˜ìŠ¤ë„ ppe_boxesì— ì¶”ê°€ (ë¡œê¹… ë° ì‹œê°í™”ìš©)
                            ppe_boxes.append({
                                "bbox": det_bbox_tuple,
                                "class": viol_cls,
                                "conf": det.get('conf', 0.9)
                            })
                            logging.info(f"[PPE {person_id_text}] âœ… {viol_cls} ìœ„ë°˜ ë§¤ì¹­ ì„±ê³µ: "
                                       f"bbox=({dx1},{dy1},{dx2},{dy2}), conf={det.get('conf', 0.9):.3f}, IoU={iou:.3f}")
                            break
            
            # [ìˆ˜ì •] ì¤€ìˆ˜ ìš°ì„  ì •ì±… (Compliance Priority)
            # ì°©ìš©(Compliance)ì´ ê°ì§€ë˜ì—ˆë‹¤ë©´, ìœ„ë°˜(Violation) ê°ì§€ê°€ ìˆë”ë¼ë„ ë¬´ì‹œ (ì˜¤íƒì§€ ë°©ì§€)
            # ì˜ˆ: ì¡°ë¼ë¥¼ ì…ì—ˆëŠ”ë° ì¡°ë¼ ì£¼ë¦„ ë•Œë¬¸ì— NO-Vestë¡œ ì˜¤ì¸ì‹ë˜ëŠ” ê²½ìš° ë°©ì§€
            if is_compliance:
                is_violation = False
                logging.debug(f"[PPE {person_id_text}] PPE ì¤€ìˆ˜ ê°ì§€: {rule} (Compliance Priority ì ìš©, ìœ„ë°˜ ë¬´ì‹œ)")

            if is_violation:
                ppe_violations.append(rule)
                # ìœ„ë°˜ ê°ì§€ëŠ” ì¤‘ìš”í•˜ë¯€ë¡œ info ë ˆë²¨ ìœ ì§€ (ë‹¨, ë§¤ í”„ë ˆì„ë§ˆë‹¤ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ ì¡°ì ˆ í•„ìš”)
                logging.debug(f"[PPE {person_id_text}] PPE ìœ„ë°˜ ê°ì§€: {rule}")
        
        logging.info(f"[PPE {person_id_text}] âœ… PPE ê°ì§€ ì™„ë£Œ: ìœ„ë°˜={len(ppe_violations)}ê°œ{ppe_violations if ppe_violations else ''}, "
                    f"ë§¤ì¹­ëœ PPE ë°•ìŠ¤={len(ppe_boxes)}ê°œ")
        
        return ppe_violations, ppe_boxes
    except Exception as e:
        logging.warning(f"PPE ê°ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return [], []


def _process_face_recognition(
    person_img_for_detection: np.ndarray, 
    person_id_text: str,
    face_model: Any, 
    face_analyzer: Any, 
    face_database: Any,
    use_adaface: bool = False,
    adaface_model_path: Optional[str] = None,
    fast_recognizer: Optional[Any] = None,
    pre_detected_face: Optional[Any] = None,
    original_frame: Optional[np.ndarray] = None,
    face_uses_trt: bool = False
) -> Tuple[str, float, Optional[np.ndarray], Optional[Tuple[int, int, int, int]]]:
    """
    ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥, ìµœì í™” ë²„ì „)
    """
    
    try:
        import time
        import cv2
        import numpy as np
        import config
        from utils import find_best_match_faiss
        
        # 0. Fast Path: ë¯¸ë¦¬ ê°ì§€ëœ ì–¼êµ´ ì •ë³´ ì‚¬ìš© (ì¤‘ë³µ ê°ì§€ ì œê±°)
        # frame_processorì—ì„œ ì´ë¯¸ ì–¼êµ´ì„ ì°¾ì•˜ìœ¼ë¯€ë¡œ, ëœë“œë§ˆí¬ë¥¼ ì´ìš©í•´ ë°”ë¡œ ì„ë² ë”© ì¶”ì¶œ
        if pre_detected_face and original_frame is not None and fast_recognizer is not None:
            has_kps = hasattr(pre_detected_face, 'kps') and pre_detected_face.kps is not None
            
            if has_kps:
                try:
                    # ì›ë³¸ í”„ë ˆì„ê³¼ ì ˆëŒ€ ì¢Œí‘œ ëœë“œë§ˆí¬ ì‚¬ìš© -> í™”ì§ˆ ì €í•˜ ì—†ìŒ, ì†ë„ ìµœìƒ
                    result = fast_recognizer.get_embedding_fast(original_frame, pre_detected_face.kps)
                    
                    if result is not None:
                        embedding, aligned_face = result
                        if embedding is not None:
                            # ì •ê·œí™”
                            embedding = embedding / np.linalg.norm(embedding)
                            
                            # FAISS ë§¤ì¹­
                            adaptive_threshold = config.Thresholds.SIMILARITY
                            faiss_start = time.time()
                            person_name, similarity_score = find_best_match_faiss(
                                embedding, face_database, adaptive_threshold
                            )
                            faiss_time = (time.time() - faiss_start) * 1000  # ms
                            
                            logging.info(f"[FACE {person_id_text}] [Fast Path] FAISS ê²€ìƒ‰ ì™„ë£Œ: {faiss_time:.1f}ms, "
                                       f"ê²°ê³¼={person_name}, ìœ ì‚¬ë„={similarity_score:.3f}, "
                                       f"ì„ê³„ê°’={adaptive_threshold:.3f}, í†µê³¼={'âœ…' if similarity_score >= adaptive_threshold else 'âŒ'}")
                            
                            # bboxëŠ” ì •ìˆ˜í˜• íŠœí”Œë¡œ ë³€í™˜
                            face_bbox = tuple(map(int, pre_detected_face.bbox))
                            return person_name, similarity_score, embedding, face_bbox
                except Exception:
                    pass
        
        # ---------------------------------------------------------
        # Fallback: YOLOë¡œ ë‹¤ì‹œ ê°ì§€í•˜ì—¬ ëœë“œë§ˆí¬ ì¶”ì¶œ (ì¸¡ë©´ ì–¼êµ´ ì§€ì›, MPS ìµœì í™”)
        # ---------------------------------------------------------
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê°œì„ : ë°ê¸°/ëŒ€ë¹„ ì¡°ì • ë° ì—…ìŠ¤ì¼€ì¼ë§ (MPS ìµœì í™”)
        import cv2
        img_h, img_w = person_img_for_detection.shape[:2]
        min_size = 64  # ìµœì†Œ 64x64 í”½ì…€ (MPS ìµœì í™”: 32 -> 64ë¡œ ì¦ê°€)
        
        # ì´ë¯¸ì§€ê°€ ì‘ìœ¼ë©´ ì—…ìŠ¤ì¼€ì¼ë§ (ë” í° í•´ìƒë„ë¡œ ê°ì§€ ì„±ê³µë¥  í–¥ìƒ)
        processed_img = person_img_for_detection.copy()
        if img_h < min_size or img_w < min_size:
            scale = max(min_size / img_h, min_size / img_w)
            new_h, new_w = int(img_h * scale), int(img_w * scale)
            processed_img = cv2.resize(processed_img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
            logging.debug(f"ğŸ” {person_id_text} ì´ë¯¸ì§€ í™•ëŒ€: {img_h}x{img_w} -> {new_h}x{new_w}")
        
        # ì´ë¯¸ì§€ í’ˆì§ˆ ê°œì„ : CLAHE (ëŒ€ë¹„ í–¥ìƒ) - ì‘ì€ ì–¼êµ´ ê°ì§€ ê°œì„ 
        if processed_img.shape[0] < 128 or processed_img.shape[1] < 128:
            # ì‘ì€ ì´ë¯¸ì§€ëŠ” CLAHEë¡œ ëŒ€ë¹„ í–¥ìƒ
            lab = cv2.cvtColor(processed_img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            l = clahe.apply(l)
            processed_img = cv2.merge([l, a, b])
            processed_img = cv2.cvtColor(processed_img, cv2.COLOR_LAB2BGR)
            logging.debug(f"ğŸ” {person_id_text} CLAHE ì ìš©: ëŒ€ë¹„ í–¥ìƒ")
        
        h, w = processed_img.shape[:2]
        min_size_check = config.Thresholds.MIN_FACE_SIZE  # ìµœì†Œ 16í”½ì…€ ì´ìƒ
        if h < min_size_check or w < min_size_check:
            return "Unknown", 0.0, None, None
        
        # confidenceë¥¼ ë§¤ìš° ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ìµœëŒ€í•œ ì–¼êµ´ ê°ì§€ ì‹œë„ (MPS ìµœì í™”)
        # YOLO Face ëª¨ë¸ì€ 640x640ìœ¼ë¡œ ONNX ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ 640ë§Œ ì‚¬ìš©
        face_start_time = time.time()
        if face_model is None:
            logging.warning(f"{person_id_text} ì–¼êµ´ ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤")
            return "Unknown", 0.0, None, None
        
        yolo_results = None
        conf_levels = [0.005, 0.01, 0.02]  # ë‚®ì€ confidenceë¶€í„° ì‹œë„ (MPS ìµœì í™”)
        imgsz_options = [640]  # YOLO Face ëª¨ë¸ì€ 640x640ìœ¼ë¡œ ê³ ì • (MPS ìµœì í™”)
        
        for conf in conf_levels:
            for imgsz in imgsz_options:
                try:
                    yolo_results = face_model(processed_img, verbose=False, imgsz=imgsz, conf=conf)
                    if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                        logging.debug(f"ğŸ” {person_id_text} YOLO Face ê°ì§€ ì„±ê³µ: conf={conf}, imgsz={imgsz}")
                        break
                except Exception as e:
                    logging.debug(f"ğŸ” {person_id_text} YOLO Face ì‹œë„ ì‹¤íŒ¨: conf={conf}, imgsz={imgsz}, error={e}")
                    continue
                if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                    break
            if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
                break
        
        face_detection_time = time.time() - face_start_time
        
        # ë””ë²„ê¹…: YOLO Face ê°ì§€ ê²°ê³¼ í™•ì¸
        if yolo_results and len(yolo_results) > 0:
            result = yolo_results[0]
            box_count = len(result.boxes) if result.boxes is not None else 0
            has_keypoints = result.keypoints is not None
            kp_count = 0
            if has_keypoints and box_count > 0:
                try:
                    kp_count = len(result.keypoints.xy[0]) if len(result.keypoints.xy) > 0 else 0
                except:
                    pass
            logging.debug(f"ğŸ” {person_id_text} YOLO Face ê²°ê³¼: ë°•ìŠ¤={box_count}ê°œ, í‚¤í¬ì¸íŠ¸={kp_count}ê°œ")
        
        # YOLO ì–¼êµ´ ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ (MPS ìµœì í™”)
        if yolo_results and yolo_results[0].boxes:
            best_idx = yolo_results[0].boxes.xywh.prod(1).argmax()
            face_bbox_raw = yolo_results[0].boxes.xyxy[best_idx].cpu().numpy()
            face_bbox = tuple(map(int, face_bbox_raw))
            
            # í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (ì¸¡ë©´ ì–¼êµ´ ì§€ì›: 2ê°œ ì´ìƒì´ë©´ ì‚¬ìš©)
            kps = None
            if yolo_results[0].keypoints is not None:
                try:
                    kps = yolo_results[0].keypoints.xy[best_idx].cpu().numpy()
                    # ì¸¡ë©´ ì–¼êµ´ ì§€ì›: ìµœì†Œ 2ê°œ í‚¤í¬ì¸íŠ¸ë§Œ ìˆì–´ë„ ì²˜ë¦¬
                    if kps.shape[0] < 2:
                        kps = None
                except Exception as e:
                    logging.debug(f"Fallback í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    kps = None
            
            # í‚¤í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ ì •ë ¬ ì‹œë„ (ì¸¡ë©´ ì–¼êµ´ ì§€ì›)
            if fast_recognizer is not None:
                if kps is not None:
                    result = fast_recognizer.get_embedding_fast(
                        processed_img, 
                        kps
                    )
                    if result is not None:
                        embedding, _ = result
                        if embedding is not None:
                            return "Unknown", 0.0, embedding, face_bbox
                else:
                    # í‚¤í¬ì¸íŠ¸ê°€ ì—†ì–´ë„ ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì‹œë„ (ì¸¡ë©´ ì–¼êµ´)
                    # ì–¼êµ´ ë°•ìŠ¤ ì¤‘ì‹¬ì„ í‚¤í¬ì¸íŠ¸ë¡œ ì‚¬ìš©
                    fx1, fy1, fx2, fy2 = face_bbox
                    face_center = np.array([(fx1 + fx2) / 2, (fy1 + fy2) / 2], dtype=np.float32)
                    face_size = max(fx2 - fx1, fy2 - fy1) * 0.3
                    # ê°€ìƒ í‚¤í¬ì¸íŠ¸ ìƒì„± (ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜)
                    fake_kps = np.array([
                        [face_center[0] - face_size, face_center[1] - face_size * 0.3],  # ì™¼ìª½ ëˆˆ ìœ„ì¹˜ ì¶”ì •
                        [face_center[0] + face_size, face_center[1] - face_size * 0.3],  # ì˜¤ë¥¸ìª½ ëˆˆ ìœ„ì¹˜ ì¶”ì •
                        [face_center[0], face_center[1]],  # ì½”
                        [face_center[0] - face_size * 0.5, face_center[1] + face_size * 0.5],  # ì™¼ìª½ ì…ê¼¬ë¦¬
                        [face_center[0] + face_size * 0.5, face_center[1] + face_size * 0.5],  # ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬
                    ], dtype=np.float32)
                    
                    result = fast_recognizer.get_embedding_fast(
                        processed_img, 
                        fake_kps
                    )
                    if result is not None:
                        embedding, _ = result
                        if embedding is not None:
                            logging.debug(f"ì¸¡ë©´ ì–¼êµ´: ì–¼êµ´ ë°•ìŠ¤ ê¸°ë°˜ ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ")
                            return "Unknown", 0.0, embedding, face_bbox
        
        # ìµœì¢… ì‹œë„: person_img_for_detection ì „ì²´ ì˜ì—­ì„ ì–¼êµ´ë¡œ ê°„ì£¼í•˜ê³  ì‹œë„
        # (YOLO Faceê°€ ì‹¤íŒ¨í•´ë„ person_box ì˜ì—­ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ìˆì„ ìˆ˜ ìˆìŒ)
        if fast_recognizer is not None and processed_img.shape[0] >= 32 and processed_img.shape[1] >= 32:
            try:
                # person_boxì˜ ìƒë‹¨ 1/3 ì˜ì—­ì„ ì–¼êµ´ë¡œ ê°„ì£¼ (ì¼ë°˜ì ì¸ ì–¼êµ´ ìœ„ì¹˜)
                face_region = processed_img[:processed_img.shape[0] // 3, :]
                if face_region.shape[0] >= 32 and face_region.shape[1] >= 32:
                    # ì–¼êµ´ ì˜ì—­ ì¤‘ì‹¬ì„ í‚¤í¬ì¸íŠ¸ë¡œ ì‚¬ìš©
                    face_center = np.array([face_region.shape[1] / 2, face_region.shape[0] / 2], dtype=np.float32)
                    face_size = min(face_region.shape[0], face_region.shape[1]) * 0.3
                    fake_kps = np.array([
                        [face_center[0] - face_size, face_center[1] - face_size * 0.3],
                        [face_center[0] + face_size, face_center[1] - face_size * 0.3],
                        [face_center[0], face_center[1]],
                        [face_center[0] - face_size * 0.5, face_center[1] + face_size * 0.5],
                        [face_center[0] + face_size * 0.5, face_center[1] + face_size * 0.5],
                    ], dtype=np.float32)
                    
                    result = fast_recognizer.get_embedding_fast(
                        face_region, 
                        fake_kps
                    )
                    if result is not None:
                        embedding, _ = result
                        if embedding is not None:
                            # ì–¼êµ´ ì˜ì—­ì˜ bbox ê³„ì‚° (ì›ë³¸ person_img ê¸°ì¤€)
                            face_bbox = (0, 0, processed_img.shape[1], processed_img.shape[0] // 3)
                            logging.debug(f"ìµœì¢… ì‹œë„ ì„±ê³µ: person_box ìƒë‹¨ ì˜ì—­ ê¸°ë°˜ ì„ë² ë”© ì¶”ì¶œ")
                            return "Unknown", 0.0, embedding, face_bbox
            except Exception as e:
                logging.debug(f"ìµœì¢… ì‹œë„ ì‹¤íŒ¨: {e}")
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ InsightFace ë°©ì‹ìœ¼ë¡œ í´ë°±
        # YOLO ê²°ê³¼ê°€ ìˆê³  fast_recognizerë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰
        if yolo_results and yolo_results[0].boxes and len(yolo_results[0].boxes) > 0:
            # YOLO ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬ (InsightFace fallback)
            boxes = yolo_results[0].boxes
            best_idx = boxes.xywh.prod(1).argmax()
            face_bbox_raw = boxes.xyxy[best_idx].cpu().numpy()
            fx1, fy1, fx2, fy2 = int(face_bbox_raw[0]), int(face_bbox_raw[1]), int(face_bbox_raw[2]), int(face_bbox_raw[3])
            face_bbox = (fx1, fy1, fx2, fy2)
            
            # 2ë‹¨ê³„: ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ (ì–¼êµ´ ìë¥´ê¸°) - ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”
            # íŒ¨ë”© ìµœì†Œí™”: ë°°ê²½ í¬í•¨ì„ ì¤„ì—¬ ì„ë² ë”© í’ˆì§ˆ í–¥ìƒ (5% íŒ¨ë”©ìœ¼ë¡œ ê°ì†Œ)
            face_w = fx2 - fx1
            face_h = fy2 - fy1
            
            # ë™ì  íŒ¨ë”©: ì‘ì€ ì–¼êµ´ì¼ìˆ˜ë¡ íŒ¨ë”©ì„ ëŠ˜ë ¤ ì´ë§ˆ/í„± í¬í•¨ë¥  í–¥ìƒ (ì¸ì‹ë¥  ìµœëŒ€í™”)
            # ì§§ì€ ë³€ì´ 60px ë¯¸ë§Œì´ë©´ 15%, ì•„ë‹ˆë©´ 8% (ë” ë§ì€ ì–¼êµ´ ì˜ì—­ í¬í•¨)
            padding_ratio = 0.15 if min(face_w, face_h) < 60 else 0.08
            padding_w = int(face_w * padding_ratio)
            padding_h = int(face_h * padding_ratio)
            
            # ê²½ê³„ ì²´í¬ ë° íŒ¨ë”© ì ìš© (ë°˜ë“œì‹œ intë¡œ ë³€í™˜)
            h, w = processed_img.shape[:2]
            fx1_padded = int(max(0, fx1 - padding_w))
            fy1_padded = int(max(0, fy1 - padding_h))
            fx2_padded = int(min(w, fx2 + padding_w))
            fy2_padded = int(min(h, fy2 + padding_h))
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ (íŒ¨ë”© í¬í•¨)
            face_img = processed_img[fy1_padded:fy2_padded, fx1_padded:fx2_padded]
            if face_img.size == 0:
                return "Unknown", 0.0, None, None
            
            # í™”ì§ˆ ê°œì„ : í¬ë¡­ í›„ ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ (ì¸ì‹ë¥  ê°œì„ )
            # 1. ë…¸ì´ì¦ˆ ì œê±° (Bilateral Filter) - ë„ˆë¬´ ëŠë ¤ì„œ ì œê±° (GPUë¡œ ì²˜ë¦¬í•˜ê±°ë‚˜ ìƒëµ)
            # face_img = cv2.bilateralFilter(face_img, d=5, sigmaColor=50, sigmaSpace=50)
            
            # 2. ëŒ€ë¹„ í–¥ìƒ (CLAHE: Contrast Limited Adaptive Histogram Equalization) - ë¹ ë¥´ê³  íš¨ê³¼ ì¢‹ìŒ (ìœ ì§€)
            # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°ê¸° ì±„ë„ë§Œ ì²˜ë¦¬ (ìƒ‰ìƒ ì™œê³¡ ë°©ì§€)
            try:
                lab = cv2.cvtColor(face_img, cv2.COLOR_BGR2LAB)
                l_channel, a, b = cv2.split(lab)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                l_channel = clahe.apply(l_channel)
                face_img = cv2.merge([l_channel, a, b])
                face_img = cv2.cvtColor(face_img, cv2.COLOR_LAB2BGR)
            except Exception:
                pass # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì‚¬ìš©
            
            # 3. ìƒ¤í”„ë‹ (Unsharp Masking) - ëŠë ¤ì„œ ì œê±°
            # gaussian = cv2.GaussianBlur(face_img, (0, 0), 2.0)
            # face_img = cv2.addWeighted(face_img, 1.5, gaussian, -0.5, 0)
            
            # logging.info(f"ğŸ” {person_id_text} í™”ì§ˆ ê°œì„  ì™„ë£Œ: ë…¸ì´ì¦ˆ ì œê±° + ëŒ€ë¹„ í–¥ìƒ + ìƒ¤í”„ë‹")
            
            # ìµœì†Œ ì–¼êµ´ í¬ê¸° í™•ì¸ ë° ë¦¬ì‚¬ì´ì¦ˆ (ë„ˆë¬´ ì‘ìœ¼ë©´ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì²˜ë¦¬)
            min_face_size = 32  # ìµœì†Œ ì–¼êµ´ í¬ê¸° (40 -> 32ë¡œ ì™„í™”: ë” ë§ì€ ì–¼êµ´ ì¸ì‹)
            if face_img.shape[0] < min_face_size or face_img.shape[1] < min_face_size:
                # ë„ˆë¬´ ì‘ì€ ì–¼êµ´ì€ ìµœì†Œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€)
                scale = min_face_size / min(face_img.shape[0], face_img.shape[1])
                new_h = max(min_face_size, int(face_img.shape[0] * scale))
                new_w = max(min_face_size, int(face_img.shape[1] * scale))
                # ì‘ì€ ì–¼êµ´ ì—…ìŠ¤ì¼€ì¼ì€ ì†ë„ë¥¼ ìœ„í•´ Linear ì‚¬ìš© (LANCZOS4 -> LINEAR)
                face_img = cv2.resize(face_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
                # logging.debug(f"ğŸ” {person_id_text} ì–¼êµ´ ë¦¬ì‚¬ì´ì¦ˆ (ì‘ì€ ì–¼êµ´): {face_img.shape[1]}x{face_img.shape[0]}")
            
            # InsightFace ìµœì  í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (112x112 ê¶Œì¥)
            # ëª¨ë“  ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ 112x112ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ì¼ê´€ì„± ìœ ì§€ (InsightFace ìµœì  í¬ê¸°)
            target_size = 112  # InsightFace buffalo_L ëª¨ë¸ ìµœì  í¬ê¸°
            if face_img.shape[0] != target_size or face_img.shape[1] != target_size:
                # ëª¨ë“  ì–¼êµ´ì„ 112x112ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë¹„ìœ¨ ìœ ì§€í•˜ì§€ ì•Šê³  ì •í™•íˆ 112x112)
                # ì†ë„ë¥¼ ìœ„í•´ Linear ì‚¬ìš© (LANCZOS4 -> LINEAR)
                face_img = cv2.resize(face_img, (target_size, target_size), interpolation=cv2.INTER_LINEAR)
                # logging.debug(f"ğŸ” {person_id_text} ì–¼êµ´ ë¦¬ì‚¬ì´ì¦ˆ: {face_img.shape[1]}x{face_img.shape[0]}")
            
            # 3ë‹¨ê³„: buffalo_L ëª¨ë¸(InsightFace)ë¡œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
            embedding_start_time = time.time()
            if face_analyzer is None:
                logging.warning(f"{person_id_text} InsightFace ë¶„ì„ê¸°ê°€ Noneì…ë‹ˆë‹¤")
                return "Unknown", 0.0, None, face_bbox
            if face_database is None:
                logging.error(f"{person_id_text} FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ Noneì…ë‹ˆë‹¤ - ì–¼êµ´ ì¸ì‹ ë¶ˆê°€ëŠ¥!")
                return "Unknown", 0.0, None, face_bbox
            
            # InsightFace recognition ëª¨ë“ˆë¡œ ì„ë² ë”© ì¶”ì¶œ (buffalo_L ëª¨ë¸ ì‚¬ìš©)
            # ì´ë¯¸ í¬ë¡­ëœ ì–¼êµ´ ì´ë¯¸ì§€ì´ë¯€ë¡œ rec_modelì„ ì§ì ‘ ì‚¬ìš©í•´ì•¼ í•¨
            embedding: Optional[np.ndarray] = None
            try:
                # rec_model ì ‘ê·¼ ë°©ë²•: face_analyzer.models['recognition'] ë˜ëŠ” face_analyzer.rec_model
                rec_model = None
                if hasattr(face_analyzer, 'models') and 'recognition' in face_analyzer.models:
                    rec_model = face_analyzer.models['recognition']
                elif hasattr(face_analyzer, 'rec_model'):
                    rec_model = face_analyzer.rec_model
                
                if rec_model is not None:
                    # ì´ë¯¸ í¬ë¡­ëœ ì–¼êµ´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì§ì ‘ ì„ë² ë”© ì¶”ì¶œ
                    # face_imgëŠ” ì´ë¯¸ 112x112ë¡œ ë¦¬ì‚¬ì´ì¦ˆëœ ì–¼êµ´ ì´ë¯¸ì§€
                    embedding = rec_model.get_feat(face_img)
                    if embedding is not None:
                        # ì •ê·œí™” (L2 norm)
                        embedding = embedding / np.linalg.norm(embedding)
                    else:
                        logging.warning(f"âš ï¸ {person_id_text} rec_model.get_feat() ë°˜í™˜ê°’ì´ Noneì…ë‹ˆë‹¤")
                        return "Unknown", 0.0, None, face_bbox
                else:
                    # rec_modelì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° fallback: get() ë©”ì„œë“œ ì‚¬ìš©
                    # í•˜ì§€ë§Œ ì´ë¯¸ í¬ë¡­ëœ ì´ë¯¸ì§€ì´ë¯€ë¡œ ì‹¤íŒ¨í•  ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                    logging.warning(f"âš ï¸ {person_id_text} rec_modelì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. face_analyzer.get() ì‚¬ìš© (fallback, ì‹¤íŒ¨ ê°€ëŠ¥ì„± ë†’ìŒ)")
                    faces = face_analyzer.get(face_img)
                    if faces and len(faces) > 0:
                        biggest_face = max(faces, key=lambda f: (f.bbox[2] - f.bbox[0]) * (f.bbox[3] - f.bbox[1]))
                        embedding = biggest_face.normed_embedding
                    else:
                        logging.warning(f"âš ï¸ {person_id_text} face_analyzer.get() ì‹¤íŒ¨: ì–¼êµ´ ê°ì§€ ê²°ê³¼ ì—†ìŒ (ì´ë¯¸ í¬ë¡­ëœ ì´ë¯¸ì§€ì´ë¯€ë¡œ ì •ìƒ)")
                        return "Unknown", 0.0, None, face_bbox
            except Exception as e:
                logging.error(f"âŒ {person_id_text} InsightFace ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
                raise FaceRecognitionError(
                    f"ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {e}",
                    error_code="EMBEDDING_EXTRACTION_FAILED",
                    details={"person_id": person_id_text}
                ) from e
            
            embedding_time = time.time() - embedding_start_time
            
            # ì„ë² ë”© ì¶”ì¶œ ê²°ê³¼ ìƒì„¸ ë¡œê¹…
            if embedding is not None and embedding.size > 0:
                embedding_norm = np.linalg.norm(embedding)
                embedding_dim = embedding.shape[0] if embedding.ndim == 1 else embedding.shape[1]
                logging.info(f"[FACE {person_id_text}] âœ… ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ: {embedding_time*1000:.1f}ms, "
                           f"shape={embedding.shape}, dim={embedding_dim}, norm={embedding_norm:.3f}, "
                           f"ì–¼êµ´ í¬ê¸°={face_img.shape[:2]}")
            else:
                logging.warning(f"[FACE {person_id_text}] âŒ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: embedding=None ë˜ëŠ” ë¹ˆ ë°°ì—´")
            
            # ì„ë² ë”© ì¶”ì¶œ í™•ì¸ ë¡œê¹…
            if embedding is None or embedding.size == 0:
                raise FaceRecognitionError(
                    f"ì„ë² ë”©ì´ Noneì´ê±°ë‚˜ ë¹„ì–´ìˆìŒ",
                    error_code="EMPTY_EMBEDDING",
                    details={"person_id": person_id_text}
                )
            
            # 4ë‹¨ê³„: FAISS ì¸ë±ìŠ¤(face_index.faiss)ì™€ ë ˆì´ë¸”(face_index.faiss.labels.npy)ì„ ì‚¬ìš©í•˜ì—¬ ë§¤ì¹­
            # face_databaseëŠ” íŠœí”Œ (index, labels) í˜•íƒœ
            try:
                if face_database is None:
                    raise FaceRecognitionError(
                        "FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ Noneì…ë‹ˆë‹¤",
                        error_code="FAISS_DATABASE_NONE",
                        details={"person_id": person_id_text}
                    )
                
                # face_databaseê°€ íŠœí”Œì¸ì§€ í™•ì¸
                if isinstance(face_database, tuple):
                    faiss_index, faiss_labels = face_database
                    if faiss_index is None:
                        raise FaceRecognitionError(
                            "FAISS ì¸ë±ìŠ¤ê°€ Noneì…ë‹ˆë‹¤",
                            error_code="FAISS_INDEX_NONE",
                            details={"person_id": person_id_text}
                        )
                    if not hasattr(faiss_index, 'ntotal'):
                        raise FaceRecognitionError(
                            "FAISS ì¸ë±ìŠ¤ì— ntotal ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤",
                            error_code="FAISS_INDEX_INVALID",
                            details={"person_id": person_id_text}
                        )
                else:
                    raise FaceRecognitionError(
                        f"FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ íŠœí”Œì´ ì•„ë‹™ë‹ˆë‹¤: {type(face_database)}",
                        error_code="FAISS_DATABASE_INVALID",
                        details={"person_id": person_id_text}
                    )
                
                # ì‘ì€ ì–¼êµ´ì€ ì•½ê°„ ë‚®ì¶˜ ì„ê³„ê°’ ì ìš© (ì˜¤ì¸ì‹ ë°©ì§€ì™€ ì¸ì‹ë¥  ê· í˜•)
                base_threshold = config.Thresholds.SIMILARITY
                adaptive_threshold = base_threshold
                fh, fw = face_img.shape[:2]
                face_min_size = min(fh, fw)
                # ì‘ì€ ì–¼êµ´ì—ë§Œ ì œí•œì ìœ¼ë¡œ ë‚®ì¶˜ ì„ê³„ê°’ ì ìš© (ì˜¤ì¸ì‹ ë°©ì§€ ê°•í™”)
                if face_min_size < 80:
                    # ì‘ì€ ì–¼êµ´ì¼ìˆ˜ë¡ ì•½ê°„ ë‚®ì€ ì„ê³„ê°’ ì ìš© (ì˜¤ì¸ì‹ ë°©ì§€ ê°•í™”)
                    if face_min_size < 50:
                        adaptive_threshold = max(0.32, adaptive_threshold - 0.04)  # ë§¤ìš° ì‘ì€ ì–¼êµ´: -0.04 (ìµœì†Œ 0.32 ìœ ì§€, 0.28 -> 0.32)
                    elif face_min_size < 65:
                        adaptive_threshold = max(0.32, adaptive_threshold - 0.02)  # ì‘ì€ ì–¼êµ´: -0.02 (ìµœì†Œ 0.32 ìœ ì§€, 0.30 -> 0.32)
                    else:
                        adaptive_threshold = max(0.30, adaptive_threshold)  # ì¤‘ê°„ í¬ê¸°: ê¸°ë³¸ê°’ ìœ ì§€ (0.30)
                
                logging.info(f"[FACE {person_id_text}] FAISS ê²€ìƒ‰ ì‹œì‘: ì„ê³„ê°’={adaptive_threshold:.3f} "
                           f"(ê¸°ë³¸={base_threshold:.3f}, ì–¼êµ´í¬ê¸°={face_min_size}px)")
                
                faiss_start = time.time()
                person_name, similarity_score = find_best_match_faiss(
                    embedding, face_database, adaptive_threshold
                )
                faiss_time = (time.time() - faiss_start) * 1000  # ms
                
                logging.info(f"[FACE {person_id_text}] FAISS ê²€ìƒ‰ ì™„ë£Œ: {faiss_time:.1f}ms, "
                           f"ê²°ê³¼={person_name}, ìœ ì‚¬ë„={similarity_score:.3f}, "
                           f"ì„ê³„ê°’={adaptive_threshold:.3f}, í†µê³¼={'âœ…' if similarity_score >= adaptive_threshold else 'âŒ'}")
            except FaceRecognitionError:
                # ì´ë¯¸ FaceRecognitionErrorì´ë©´ ê·¸ëŒ€ë¡œ ì „íŒŒ
                raise
            except Exception as e:
                logging.error(f"âŒ {person_id_text} FAISS ë§¤ì¹­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
                raise FaceRecognitionError(
                    f"FAISS ë§¤ì¹­ ì‹¤íŒ¨: {e}",
                    error_code="FAISS_MATCHING_FAILED",
                    details={"person_id": person_id_text}
                ) from e
            
            # ì–¼êµ´ ì¸ì‹ ê²°ê³¼ ë¡œê¹… (ì„±ëŠ¥ ìµœì í™”: DEBUG ë ˆë²¨ë¡œ ë³€ê²½)
            if person_name == "Unknown":
                pass
                # logging.debug(f"âš ï¸ {person_id_text} ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: Unknown (ìœ ì‚¬ë„={similarity_score:.3f})")
            else:
                pass
                # logging.debug(f"âœ… {person_id_text} ì–¼êµ´ ì¸ì‹ ì„±ê³µ: {person_name} (ìœ ì‚¬ë„={similarity_score:.3f})")
            
            total_time = face_detection_time + embedding_time
            if total_time > 1.0:  # 1.0ì´ˆ ì´ìƒ ê±¸ë¦° ê²½ìš°ë§Œ ë¡œê¹… (0.5 -> 1.0)
                logging.warning(f"{person_id_text} ì–¼êµ´ ì¸ì‹ ì‹œê°„: {total_time:.3f}s (YOLO: {face_detection_time:.3f}s, Embedding: {embedding_time:.3f}s) -> {person_name}")
            
            return person_name, similarity_score, embedding, face_bbox
        else:
            logging.warning(f"âš ï¸ {person_id_text} ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨: YOLO ê²°ê³¼ ì—†ìŒ ë˜ëŠ” ë°•ìŠ¤ ì—†ìŒ (yolo_results={yolo_results is not None}, len={len(yolo_results) if yolo_results else 0}, boxes={len(yolo_results[0].boxes) if yolo_results and len(yolo_results) > 0 else 0})")
            return "Unknown", 0.0, None, None
    except FaceRecognitionError:
        # FaceRecognitionErrorëŠ” ê·¸ëŒ€ë¡œ ì „íŒŒ (í˜¸ì¶œìê°€ ì²˜ë¦¬)
        raise
    except Exception as e:
        logging.warning(f"{person_id_text} ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ëŠ” ProcessingErrorë¡œ ë³€í™˜
        raise ProcessingError(
            f"ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}",
            error_code="FACE_RECOGNITION_UNEXPECTED_ERROR",
            details={"person_id": person_id_text}
        ) from e


def _process_dangerous_behavior(
    keypoints: Keypoints, 
    person_box: Tuple[int, int, int, int], 
    cam_id: int, 
    person_box_key: str
) -> Tuple[bool, str]:
    """
    ìœ„í—˜ í–‰ë™ ê°ì§€ ì²˜ë¦¬ í•¨ìˆ˜ (ë„˜ì–´ì§ ë“±) - ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
    ìœ„í—˜í•  ë•Œë§Œ True ë°˜í™˜í•˜ì—¬ ì•Œë¦¼ ìƒì„±
    
    Returns:
        (is_dangerous, violation_type)
        - is_dangerous: ìœ„í—˜ í–‰ë™ ê°ì§€ ì—¬ë¶€ (ìœ„í—˜í•  ë•Œë§Œ True)
        - violation_type: ìœ„ë°˜ ìœ í˜• (ì˜ˆ: "ë„˜ì–´ì§")
    """
    try:
        if keypoints is None:
            return False, ""
        
        x1, y1, x2, y2 = person_box
        is_fallen_horizontal = utils.is_person_horizontal(keypoints, (x1, y1, x2, y2))
        
        now_ts = time.time()
        
        if is_fallen_horizontal:
            # ë„˜ì–´ì§ ê°ì§€ ì‹œê°„ ì¶”ì 
            if cam_id not in fall_start_times:
                fall_start_times[cam_id] = {}
            if person_box_key not in fall_start_times[cam_id]:
                fall_start_times[cam_id][person_box_key] = now_ts
            
            # 0.5ì´ˆ ì´ìƒ ì§€ì†ë˜ë©´ ë„˜ì–´ì§ìœ¼ë¡œ íŒì • (ìœ„í—˜í•  ë•Œë§Œ True ë°˜í™˜)
            fall_duration = now_ts - fall_start_times[cam_id][person_box_key]
            if fall_duration >= FALL_DURATION_THRESHOLD:
                # ìœ„í—˜ ê°ì§€: ì•Œë¦¼ ìƒì„±
                logging.warning(f"âš ï¸ ìœ„í—˜ í–‰ë™ ê°ì§€: {person_box_key} - ë„˜ì–´ì§ (ì§€ì† ì‹œê°„: {fall_duration:.2f}ì´ˆ)")
                return True, "ë„˜ì–´ì§"
            else:
                # ì•„ì§ ì‹œê°„ì´ ë¶€ì¡±í•˜ë©´ False (ìœ„í—˜í•˜ì§€ ì•ŠìŒ)
                return False, ""
        else:
            # ë„˜ì–´ì§ì´ ì•„ë‹ˆë©´ ì‹œê°„ ì¶”ì  ì´ˆê¸°í™”
            if cam_id in fall_start_times and person_box_key in fall_start_times[cam_id]:
                del fall_start_times[cam_id][person_box_key]
        
        return False, ""
    except Exception:
        return False, ""

