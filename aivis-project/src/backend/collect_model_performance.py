"""
ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ìˆ˜ì§‘í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
Precision, Recall, F1-Scoreë¥¼ í¬í•¨í•œ ì •í™•ë„ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
"""
import sys
import os
import json
import time
import logging
import glob
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict
import numpy as np
import cv2

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from core import SafetySystem

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def calculate_iou(box1: Tuple[int, int, int, int], box2: Tuple[int, int, int, int]) -> float:
    """ë‘ ë°”ìš´ë”© ë°•ìŠ¤ì˜ IoU (Intersection over Union) ê³„ì‚°"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    inter_x_min = max(x1_min, x2_min)
    inter_y_min = max(y1_min, y2_min)
    inter_x_max = min(x1_max, x2_max)
    inter_y_max = min(y1_max, y2_max)
    
    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
        return 0.0
    
    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
    
    # ê° ë°•ìŠ¤ì˜ ë„“ì´
    box1_area = (x1_max - x1_min) * (y1_max - y1_min)
    box2_area = (x2_max - x2_min) * (y2_max - y2_min)
    
    # í•©ì§‘í•© ì˜ì—­
    union_area = box1_area + box2_area - inter_area
    
    if union_area == 0:
        return 0.0
    
    return inter_area / union_area


def match_detections(
    pred_boxes: List[Tuple[int, int, int, int]],
    gt_boxes: List[Tuple[int, int, int, int]],
    iou_threshold: float = 0.5
) -> Tuple[int, int, int]:
    """
    ì˜ˆì¸¡ ë°•ìŠ¤ì™€ Ground Truth ë°•ìŠ¤ë¥¼ ë§¤ì¹­í•˜ì—¬ TP, FP, FN ê³„ì‚°
    
    Returns:
        (TP, FP, FN) íŠœí”Œ
    """
    if not gt_boxes:
        return (0, len(pred_boxes), 0)
    if not pred_boxes:
        return (0, 0, len(gt_boxes))
    
    # ë§¤ì¹­ëœ GT ë°•ìŠ¤ ì¶”ì 
    matched_gt = set()
    tp = 0
    
    # ê° ì˜ˆì¸¡ ë°•ìŠ¤ì— ëŒ€í•´ ê°€ì¥ ë†’ì€ IoUë¥¼ ê°€ì§„ GT ë°•ìŠ¤ ì°¾ê¸°
    for pred_box in pred_boxes:
        best_iou = 0.0
        best_gt_idx = -1
        
        for gt_idx, gt_box in enumerate(gt_boxes):
            if gt_idx in matched_gt:
                continue
            
            iou = calculate_iou(pred_box, gt_box)
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = gt_idx
        
        if best_iou >= iou_threshold and best_gt_idx != -1:
            tp += 1
            matched_gt.add(best_gt_idx)
    
    fp = len(pred_boxes) - tp
    fn = len(gt_boxes) - len(matched_gt)
    
    return (tp, fp, fn)


def calculate_metrics(tp: int, fp: int, fn: int) -> Dict[str, float]:
    """Precision, Recall, F1-Score ê³„ì‚°"""
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
    
    return {
        "precision": round(precision, 4),
        "recall": round(recall, 4),
        "f1_score": round(f1_score, 4),
        "tp": tp,
        "fp": fp,
        "fn": fn
    }


def get_model_info(safety_system: SafetySystem) -> Dict[str, Any]:
    """ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘"""
    model_info = {
        "violation_model": {
            "name": "YOLO Violation (PPE ê°ì§€)",
            "path": config.Paths.YOLO_VIOLATION_MODEL,
            "exists": os.path.exists(config.Paths.YOLO_VIOLATION_MODEL),
            "device": str(safety_system.device) if safety_system.violation_model else None,
            "uses_trt": safety_system.violation_uses_trt if hasattr(safety_system, 'violation_uses_trt') else False
        },
        "pose_model": {
            "name": "YOLO Pose (ì‚¬ëŒ ê°ì§€)",
            "path": config.Paths.YOLO_POSE_MODEL,
            "exists": os.path.exists(config.Paths.YOLO_POSE_MODEL),
            "device": str(safety_system.device) if safety_system.pose_model else None,
            "uses_trt": safety_system.pose_uses_trt if hasattr(safety_system, 'pose_uses_trt') else False
        },
        "face_model": {
            "name": "YOLO Face (ì–¼êµ´ ê°ì§€)",
            "path": config.Paths.YOLO_FACE_MODEL,
            "exists": os.path.exists(config.Paths.YOLO_FACE_MODEL),
            "device": str(safety_system.device) if safety_system.face_model else None,
            "uses_trt": safety_system.face_uses_trt if hasattr(safety_system, 'face_uses_trt') else False
        },
        "face_recognition": {
            "name": "AdaFace/InsightFace (ì–¼êµ´ ì¸ì‹)",
            "adaface_path": config.Paths.ADAFACE_MODEL,
            "adaface_exists": os.path.exists(config.Paths.ADAFACE_MODEL),
            "device": str(safety_system.device) if safety_system.face_analyzer else None
        }
    }
    
    # ëª¨ë¸ íŒŒì¼ í¬ê¸° ì¶”ê°€
    for key, info in model_info.items():
        if key == "face_recognition":
            if info["adaface_exists"]:
                info["adaface_size_mb"] = round(os.path.getsize(info["adaface_path"]) / (1024 * 1024), 2)
        else:
            if info["exists"]:
                info["size_mb"] = round(os.path.getsize(info["path"]) / (1024 * 1024), 2)
    
    return model_info


def benchmark_model(
    model: Any,
    model_name: str,
    input_size: tuple = (640, 480),
    num_iterations: int = 50,
    warmup: int = 5
) -> Dict[str, Any]:
    """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    if model is None:
        return {
            "error": "ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤",
            "avg_inference_time_ms": 0.0,
            "fps": 0.0,
            "min_time_ms": 0.0,
            "max_time_ms": 0.0,
            "std_time_ms": 0.0
        }
    
    try:
        # ë”ë¯¸ ì…ë ¥ ìƒì„±
        dummy_input = np.random.randint(0, 255, (input_size[1], input_size[0], 3), dtype=np.uint8)
        
        # Warmup
        for _ in range(warmup):
            try:
                _ = model(dummy_input, verbose=False)
            except:
                pass
        
        # ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬
        inference_times = []
        for i in range(num_iterations):
            start_time = time.time()
            try:
                _ = model(dummy_input, verbose=False)
                inference_time = (time.time() - start_time) * 1000  # ms
                inference_times.append(inference_time)
            except Exception as e:
                logger.warning(f"{model_name} ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ (ë°˜ë³µ {i+1}): {e}")
                continue
        
        if not inference_times:
            return {
                "error": "ëª¨ë“  ì¶”ë¡ ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
                "avg_inference_time_ms": 0.0,
                "fps": 0.0,
                "min_time_ms": 0.0,
                "max_time_ms": 0.0,
                "std_time_ms": 0.0
            }
        
        avg_time = np.mean(inference_times)
        min_time = np.min(inference_times)
        max_time = np.max(inference_times)
        std_time = np.std(inference_times)
        fps = 1000.0 / avg_time if avg_time > 0 else 0.0
        
        return {
            "avg_inference_time_ms": round(avg_time, 2),
            "fps": round(fps, 2),
            "min_time_ms": round(min_time, 2),
            "max_time_ms": round(max_time, 2),
            "std_time_ms": round(std_time, 2),
            "num_iterations": len(inference_times),
            "success_rate": round(len(inference_times) / num_iterations * 100, 1)
        }
    except Exception as e:
        logger.error(f"{model_name} ë²¤ì¹˜ë§ˆí¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {
            "error": str(e),
            "avg_inference_time_ms": 0.0,
            "fps": 0.0,
            "min_time_ms": 0.0,
            "max_time_ms": 0.0,
            "std_time_ms": 0.0
        }


def benchmark_face_recognition(
    face_analyzer: Any,
    model_name: str,
    input_size: tuple = (640, 480),
    num_iterations: int = 50,
    warmup: int = 5
) -> Dict[str, Any]:
    """ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    if face_analyzer is None:
        return {
            "error": "ì–¼êµ´ ì¸ì‹ ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤",
            "avg_inference_time_ms": 0.0,
            "fps": 0.0
        }
    
    try:
        # ë”ë¯¸ ì–¼êµ´ ì´ë¯¸ì§€ ìƒì„± (112x112, InsightFace ì…ë ¥ í¬ê¸°)
        dummy_face = np.random.randint(0, 255, (112, 112, 3), dtype=np.uint8)
        
        # rec_model ì ‘ê·¼
        rec_model = None
        if hasattr(face_analyzer, 'models') and 'recognition' in face_analyzer.models:
            rec_model = face_analyzer.models['recognition']
        elif hasattr(face_analyzer, 'rec_model'):
            rec_model = face_analyzer.rec_model
        
        if rec_model is None:
            return {
                "error": "recognition ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "avg_inference_time_ms": 0.0,
                "fps": 0.0
            }
        
        # Warmup
        for _ in range(warmup):
            try:
                _ = rec_model.get_feat(dummy_face)
            except:
                pass
        
        # ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬
        inference_times = []
        for i in range(num_iterations):
            start_time = time.time()
            try:
                _ = rec_model.get_feat(dummy_face)
                inference_time = (time.time() - start_time) * 1000  # ms
                inference_times.append(inference_time)
            except Exception as e:
                logger.warning(f"{model_name} ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ (ë°˜ë³µ {i+1}): {e}")
                continue
        
        if not inference_times:
            return {
                "error": "ëª¨ë“  ì¶”ë¡ ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
                "avg_inference_time_ms": 0.0,
                "fps": 0.0
            }
        
        avg_time = np.mean(inference_times)
        fps = 1000.0 / avg_time if avg_time > 0 else 0.0
        
        return {
            "avg_inference_time_ms": round(avg_time, 2),
            "fps": round(fps, 2),
            "min_time_ms": round(np.min(inference_times), 2),
            "max_time_ms": round(np.max(inference_times), 2),
            "std_time_ms": round(np.std(inference_times), 2),
            "num_iterations": len(inference_times),
            "success_rate": round(len(inference_times) / num_iterations * 100, 1)
        }
    except Exception as e:
        logger.error(f"{model_name} ë²¤ì¹˜ë§ˆí¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {
            "error": str(e),
            "avg_inference_time_ms": 0.0,
            "fps": 0.0
        }


def evaluate_model_on_images(
    model: Any,
    model_name: str,
    image_paths: List[str],
    task_type: str = "detect",
    confidence_threshold: float = 0.25,
    iou_threshold: float = 0.5
) -> Dict[str, Any]:
    """
    ì‹¤ì œ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    Ground truthê°€ ì—†ìœ¼ë¯€ë¡œ, ëª¨ë¸ì˜ ì¼ê´€ì„±ê³¼ ê°ì§€ìœ¨ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
    """
    if model is None:
        return {
            "error": "ëª¨ë¸ì´ Noneì…ë‹ˆë‹¤",
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "avg_detections": 0.0,
            "num_images": 0
        }
    
    if not image_paths:
        return {
            "error": "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤",
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "avg_detections": 0.0,
            "num_images": 0
        }
    
    total_detections = 0
    successful_detections = 0
    total_images = 0
    detection_counts = []
    
    logger.info(f"  {len(image_paths)}ê°œ ì´ë¯¸ì§€ë¡œ {model_name} í‰ê°€ ì¤‘...")
    
    for img_path in image_paths[:50]:  # ìµœëŒ€ 50ê°œ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
        try:
            if not os.path.exists(img_path):
                continue
            
            img = cv2.imread(img_path)
            if img is None:
                continue
            
            # ëª¨ë¸ ì¶”ë¡ 
            results = model(img, conf=confidence_threshold, verbose=False)
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        if conf >= confidence_threshold:
                            detections.append((int(x1), int(y1), int(x2), int(y2)))
            
            if detections:
                successful_detections += 1
                total_detections += len(detections)
                detection_counts.append(len(detections))
            
            total_images += 1
            
        except Exception as e:
            logger.warning(f"  ì´ë¯¸ì§€ {img_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    if total_images == 0:
        return {
            "error": "ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤",
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "avg_detections": 0.0,
            "num_images": 0
        }
    
    # Ground truthê°€ ì—†ìœ¼ë¯€ë¡œ, ê°ì§€ìœ¨ê³¼ ì¼ê´€ì„±ì„ ì¸¡ì •
    detection_rate = successful_detections / total_images if total_images > 0 else 0.0
    avg_detections = total_detections / total_images if total_images > 0 else 0.0
    
    # ì¼ê´€ì„± ì¸¡ì • (í‘œì¤€ í¸ì°¨)
    std_detections = np.std(detection_counts) if detection_counts else 0.0
    
    # Ground truthê°€ ì—†ìœ¼ë¯€ë¡œ, ê°ì§€ìœ¨ì„ recallë¡œ ê·¼ì‚¬
    # Precisionì€ ê°ì§€ëœ ê°ì²´ì˜ í‰ê·  ì‹ ë¢°ë„ë¡œ ê·¼ì‚¬
    # ì‹¤ì œë¡œëŠ” ground truthê°€ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°ì§€ìœ¨ ê¸°ë°˜ ì§€í‘œ ì œê³µ
    
    return {
        "detection_rate": round(detection_rate, 4),  # ê°ì§€ìœ¨ (Recall ê·¼ì‚¬)
        "avg_detections": round(avg_detections, 2),
        "std_detections": round(std_detections, 2),
        "num_images": total_images,
        "successful_images": successful_detections,
        "total_detections": total_detections,
        "note": "Ground truthê°€ ì—†ì–´ ì •í™•í•œ Precision/Recall/F1 ê³„ì‚° ë¶ˆê°€. ê°ì§€ìœ¨ ê¸°ë°˜ ì§€í‘œ ì œê³µ."
    }


def get_test_images(log_folder: str, max_images: int = 50) -> List[str]:
    """ë¡œê·¸ í´ë”ì—ì„œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘"""
    image_extensions = ['*.jpg', '*.jpeg', '*.png']
    image_paths = []
    
    for ext in image_extensions:
        pattern = os.path.join(log_folder, '**', ext)
        image_paths.extend(glob.glob(pattern, recursive=True))
    
    # ìµœì‹  ì´ë¯¸ì§€ ìš°ì„  ì„ íƒ
    image_paths.sort(key=os.path.getmtime, reverse=True)
    
    return image_paths[:max_images]


def collect_performance_metrics(safety_system: SafetySystem) -> Dict[str, Any]:
    """ì „ì²´ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
    logger.info("=" * 60)
    logger.info("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹œì‘")
    logger.info("=" * 60)
    
    # ëª¨ë¸ ì •ë³´ ìˆ˜ì§‘
    model_info = get_model_info(safety_system)
    
    # ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
    input_size = (640, 480)  # ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ì…ë ¥ í¬ê¸°
    num_iterations = 50  # ë²¤ì¹˜ë§ˆí¬ ë°˜ë³µ íšŸìˆ˜
    warmup = 5  # ì›Œë°ì—… íšŸìˆ˜
    
    performance_results = {
        "timestamp": datetime.now().isoformat(),
        "system_info": {
            "device": str(safety_system.device),
            "input_size": f"{input_size[0]}x{input_size[1]}"
        },
        "models": {}
    }
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜ì§‘
    test_images = get_test_images(config.Paths.LOG_FOLDER, max_images=50)
    logger.info(f"\nğŸ“¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ {len(test_images)}ê°œ ë°œê²¬")
    
    # 1. Violation ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
    logger.info("\nğŸ“Š Violation ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
    if safety_system.violation_model:
        violation_perf = benchmark_model(
            safety_system.violation_model,
            "Violation ëª¨ë¸",
            input_size,
            num_iterations,
            warmup
        )
        
        # ì‹¤ì œ ì´ë¯¸ì§€ í‰ê°€
        if test_images:
            violation_eval = evaluate_model_on_images(
                safety_system.violation_model,
                "Violation ëª¨ë¸",
                test_images,
                task_type="detect",
                confidence_threshold=config.Thresholds.YOLO_CONFIDENCE
            )
            violation_perf.update(violation_eval)
        
        performance_results["models"]["violation"] = {
            **model_info["violation_model"],
            **violation_perf
        }
        logger.info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {violation_perf.get('avg_inference_time_ms', 0):.2f}ms")
        logger.info(f"   FPS: {violation_perf.get('fps', 0):.2f}")
        if "detection_rate" in violation_perf:
            logger.info(f"   ê°ì§€ìœ¨: {violation_perf.get('detection_rate', 0):.2%}")
    else:
        performance_results["models"]["violation"] = {
            **model_info["violation_model"],
            "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        }
    
    # 2. Pose ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
    logger.info("\nğŸ“Š Pose ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
    if safety_system.pose_model:
        pose_perf = benchmark_model(
            safety_system.pose_model,
            "Pose ëª¨ë¸",
            input_size,
            num_iterations,
            warmup
        )
        
        # ì‹¤ì œ ì´ë¯¸ì§€ í‰ê°€
        if test_images:
            pose_eval = evaluate_model_on_images(
                safety_system.pose_model,
                "Pose ëª¨ë¸",
                test_images,
                task_type="pose",
                confidence_threshold=config.Thresholds.POSE_CONFIDENCE
            )
            pose_perf.update(pose_eval)
        
        performance_results["models"]["pose"] = {
            **model_info["pose_model"],
            **pose_perf
        }
        logger.info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {pose_perf.get('avg_inference_time_ms', 0):.2f}ms")
        logger.info(f"   FPS: {pose_perf.get('fps', 0):.2f}")
        if "detection_rate" in pose_perf:
            logger.info(f"   ê°ì§€ìœ¨: {pose_perf.get('detection_rate', 0):.2%}")
    else:
        performance_results["models"]["pose"] = {
            **model_info["pose_model"],
            "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        }
    
    # 3. Face ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
    logger.info("\nğŸ“Š Face ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
    if safety_system.face_model:
        face_perf = benchmark_model(
            safety_system.face_model,
            "Face ëª¨ë¸",
            input_size,
            num_iterations,
            warmup
        )
        
        # ì‹¤ì œ ì´ë¯¸ì§€ í‰ê°€
        if test_images:
            face_eval = evaluate_model_on_images(
                safety_system.face_model,
                "Face ëª¨ë¸",
                test_images,
                task_type="detect",
                confidence_threshold=config.Thresholds.FACE_DETECTION_CONFIDENCE
            )
            face_perf.update(face_eval)
        
        performance_results["models"]["face_detection"] = {
            **model_info["face_model"],
            **face_perf
        }
        logger.info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {face_perf.get('avg_inference_time_ms', 0):.2f}ms")
        logger.info(f"   FPS: {face_perf.get('fps', 0):.2f}")
        if "detection_rate" in face_perf:
            logger.info(f"   ê°ì§€ìœ¨: {face_perf.get('detection_rate', 0):.2%}")
    else:
        performance_results["models"]["face_detection"] = {
            **model_info["face_model"],
            "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        }
    
    # 4. Face Recognition ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬
    logger.info("\nğŸ“Š Face Recognition ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì¤‘...")
    if safety_system.face_analyzer:
        face_rec_perf = benchmark_face_recognition(
            safety_system.face_analyzer,
            "Face Recognition ëª¨ë¸",
            input_size,
            num_iterations,
            warmup
        )
        performance_results["models"]["face_recognition"] = {
            **model_info["face_recognition"],
            **face_rec_perf
        }
        logger.info(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {face_rec_perf.get('avg_inference_time_ms', 0):.2f}ms")
        logger.info(f"   FPS: {face_rec_perf.get('fps', 0):.2f}")
    else:
        performance_results["models"]["face_recognition"] = {
            **model_info["face_recognition"],
            "error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        }
    
    return performance_results


def generate_report(performance_results: Dict[str, Any], output_file: Optional[str] = None) -> str:
    """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ë¦¬í¬íŠ¸")
    report_lines.append("=" * 80)
    report_lines.append(f"ìƒì„± ì‹œê°„: {performance_results['timestamp']}")
    report_lines.append(f"ë””ë°”ì´ìŠ¤: {performance_results['system_info']['device']}")
    report_lines.append(f"ì…ë ¥ í¬ê¸°: {performance_results['system_info']['input_size']}")
    report_lines.append("")
    
    for model_key, model_data in performance_results["models"].items():
        report_lines.append("-" * 80)
        report_lines.append(f"ëª¨ë¸: {model_data.get('name', model_key)}")
        report_lines.append("-" * 80)
        
        if "error" in model_data:
            report_lines.append(f"  âŒ ì˜¤ë¥˜: {model_data['error']}")
        else:
            if "path" in model_data:
                report_lines.append(f"  ê²½ë¡œ: {model_data['path']}")
                if model_data.get('exists'):
                    report_lines.append(f"  íŒŒì¼ í¬ê¸°: {model_data.get('size_mb', 'N/A')} MB")
            if "adaface_path" in model_data:
                report_lines.append(f"  AdaFace ê²½ë¡œ: {model_data['adaface_path']}")
                if model_data.get('adaface_exists'):
                    report_lines.append(f"  AdaFace íŒŒì¼ í¬ê¸°: {model_data.get('adaface_size_mb', 'N/A')} MB")
            
            report_lines.append(f"  ë””ë°”ì´ìŠ¤: {model_data.get('device', 'N/A')}")
            report_lines.append(f"  TensorRT ì‚¬ìš©: {model_data.get('uses_trt', False)}")
            report_lines.append("")
            report_lines.append("  ì„±ëŠ¥ ì§€í‘œ (ì¶”ë¡  ì†ë„):")
            report_lines.append(f"    - í‰ê·  ì¶”ë¡  ì‹œê°„: {model_data.get('avg_inference_time_ms', 0):.2f} ms")
            report_lines.append(f"    - FPS: {model_data.get('fps', 0):.2f}")
            report_lines.append(f"    - ìµœì†Œ ì‹œê°„: {model_data.get('min_time_ms', 0):.2f} ms")
            report_lines.append(f"    - ìµœëŒ€ ì‹œê°„: {model_data.get('max_time_ms', 0):.2f} ms")
            report_lines.append(f"    - í‘œì¤€ í¸ì°¨: {model_data.get('std_time_ms', 0):.2f} ms")
            report_lines.append(f"    - ì„±ê³µë¥ : {model_data.get('success_rate', 0):.1f}%")
            report_lines.append(f"    - ë°˜ë³µ íšŸìˆ˜: {model_data.get('num_iterations', 0)}")
            
            # ì •í™•ë„ ì§€í‘œ (Precision, Recall, F1-Score)
            if "precision" in model_data:
                report_lines.append("")
                report_lines.append("  ì •í™•ë„ ì§€í‘œ:")
                report_lines.append(f"    - Precision: {model_data.get('precision', 0):.4f}")
                report_lines.append(f"    - Recall: {model_data.get('recall', 0):.4f}")
                report_lines.append(f"    - F1-Score: {model_data.get('f1_score', 0):.4f}")
                report_lines.append(f"    - TP: {model_data.get('tp', 0)}")
                report_lines.append(f"    - FP: {model_data.get('fp', 0)}")
                report_lines.append(f"    - FN: {model_data.get('fn', 0)}")
            elif "detection_rate" in model_data:
                report_lines.append("")
                report_lines.append("  ì •í™•ë„ ì§€í‘œ (Ground Truth ì—†ìŒ):")
                report_lines.append(f"    - ê°ì§€ìœ¨ (Detection Rate): {model_data.get('detection_rate', 0):.2%}")
                report_lines.append(f"    - í‰ê·  ê°ì§€ ìˆ˜: {model_data.get('avg_detections', 0):.2f}")
                report_lines.append(f"    - ê°ì§€ í‘œì¤€ í¸ì°¨: {model_data.get('std_detections', 0):.2f}")
                report_lines.append(f"    - í‰ê°€ ì´ë¯¸ì§€ ìˆ˜: {model_data.get('num_images', 0)}")
                if "note" in model_data:
                    report_lines.append(f"    - ì°¸ê³ : {model_data.get('note', '')}")
        
        report_lines.append("")
    
    # ì „ì²´ ìš”ì•½
    report_lines.append("=" * 80)
    report_lines.append("ì „ì²´ ìš”ì•½")
    report_lines.append("=" * 80)
    
    total_inference_time = 0.0
    for model_data in performance_results["models"].values():
        if "avg_inference_time_ms" in model_data:
            total_inference_time += model_data["avg_inference_time_ms"]
    
    report_lines.append(f"ì „ì²´ ì¶”ë¡  ì‹œê°„ (ë³‘ë ¬ ì‹¤í–‰ ì‹œ): {total_inference_time:.2f} ms")
    report_lines.append(f"ì˜ˆìƒ ì „ì²´ FPS: {1000.0 / total_inference_time if total_inference_time > 0 else 0:.2f}")
    report_lines.append("")
    
    report_text = "\n".join(report_lines)
    
    # íŒŒì¼ë¡œ ì €ì¥
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = os.path.join(config.Paths.LOG_FOLDER, f"model_performance_{timestamp}.txt")
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    # JSON íŒŒì¼ë„ ì €ì¥
    json_file = output_file.replace('.txt', '.json')
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(performance_results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ:")
    logger.info(f"   í…ìŠ¤íŠ¸: {output_file}")
    logger.info(f"   JSON: {json_file}")
    
    return report_text


def estimate_rtx2080ti_performance(
    current_performance: Dict[str, Any],
    use_tensorrt: bool = False,
    multi_gpu: bool = True
) -> Dict[str, Any]:
    """
    RTX 2080Ti 2ëŒ€ í™˜ê²½ì—ì„œì˜ ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°
    
    ì„±ëŠ¥ í–¥ìƒ ê³„ìˆ˜:
    - MPS -> CUDA: ì•½ 1.5-2.0ë°° (CUDAê°€ ë” ìµœì í™”ë¨)
    - CUDA -> TensorRT: ì•½ 2.0-3.0ë°° (TensorRT ìµœì í™”)
    - Multi-GPU: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì§€ì—° ì‹œê°„ ê°ì†Œ (ì•½ 1.3-1.5ë°°)
    """
    if "error" in current_performance or "avg_inference_time_ms" not in current_performance:
        return current_performance
    
    base_time = current_performance["avg_inference_time_ms"]
    
    # MPS -> CUDA ë³€í™˜ ê³„ìˆ˜ (CUDAê°€ ì¼ë°˜ì ìœ¼ë¡œ ë” ë¹ ë¦„)
    cuda_speedup = 1.7  # CUDAê°€ MPSë³´ë‹¤ ì•½ 1.7ë°° ë¹ ë¦„
    
    # TensorRT ì‚¬ìš© ì‹œ ì¶”ê°€ ì†ë„ í–¥ìƒ
    if use_tensorrt:
        tensorrt_speedup = 2.5  # TensorRTê°€ PyTorchë³´ë‹¤ ì•½ 2.5ë°° ë¹ ë¦„
        estimated_time = base_time / (cuda_speedup * tensorrt_speedup)
        speedup_factor = cuda_speedup * tensorrt_speedup
    else:
        estimated_time = base_time / cuda_speedup
        speedup_factor = cuda_speedup
    
    # Multi-GPU ë¶„ì‚° ì²˜ë¦¬ (ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì§€ì—° ì‹œê°„ ê°ì†Œ)
    if multi_gpu:
        # GPU 0: Violation/Pose, GPU 1: Face/Face Recognition
        # ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„ ê°ì†Œ
        multi_gpu_speedup = 1.4  # ì•½ 1.4ë°° í–¥ìƒ
        estimated_time = estimated_time / multi_gpu_speedup
        speedup_factor *= multi_gpu_speedup
    
    estimated_fps = 1000.0 / estimated_time if estimated_time > 0 else 0.0
    
    result = current_performance.copy()
    result.update({
        "estimated_rtx2080ti_time_ms": round(estimated_time, 2),
        "estimated_rtx2080ti_fps": round(estimated_fps, 2),
        "speedup_factor": round(speedup_factor, 2),
        "use_tensorrt": use_tensorrt,
        "multi_gpu": multi_gpu,
        "gpu_config": "RTX 2080Ti x2 (CUDA)" + (" + TensorRT" if use_tensorrt else "")
    })
    
    return result


def generate_rtx2080ti_report(
    performance_results: Dict[str, Any],
    use_tensorrt: bool = False,
    output_file: Optional[str] = None
) -> str:
    """RTX 2080Ti 2ëŒ€ í™˜ê²½ ì˜ˆìƒ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("RTX 2080Ti 2ëŒ€ í™˜ê²½ ì˜ˆìƒ ì„±ëŠ¥ ì§€í‘œ ë¦¬í¬íŠ¸")
    report_lines.append("=" * 80)
    report_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().isoformat()}")
    report_lines.append(f"GPU ì„¤ì •: RTX 2080Ti x2 (CUDA)" + (" + TensorRT" if use_tensorrt else " (PyTorch)"))
    report_lines.append(f"Multi-GPU: í™œì„±í™” (GPU 0: Violation/Pose, GPU 1: Face/Face Recognition)")
    report_lines.append("")
    report_lines.append("âš ï¸  ì°¸ê³ : ì´ëŠ” í˜„ì¬ MPS í™˜ê²½ ì„±ëŠ¥ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¶”ì •ì¹˜ì…ë‹ˆë‹¤.")
    report_lines.append("âš ï¸  ì‹¤ì œ ì„±ëŠ¥ì€ í™˜ê²½, ëª¨ë¸ ë²„ì „, ë“œë¼ì´ë²„ ë“±ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    report_lines.append("")
    
    total_estimated_time = 0.0
    
    for model_key, model_data in performance_results["models"].items():
        if "error" in model_data:
            continue
        
        estimated = estimate_rtx2080ti_performance(model_data, use_tensorrt, multi_gpu=True)
        
        report_lines.append("-" * 80)
        report_lines.append(f"ëª¨ë¸: {model_data.get('name', model_key)}")
        report_lines.append("-" * 80)
        
        if "estimated_rtx2080ti_time_ms" in estimated:
            report_lines.append(f"  í˜„ì¬ í™˜ê²½ (MPS):")
            report_lines.append(f"    - ì¶”ë¡  ì‹œê°„: {model_data.get('avg_inference_time_ms', 0):.2f} ms")
            report_lines.append(f"    - FPS: {model_data.get('fps', 0):.2f}")
            report_lines.append("")
            report_lines.append(f"  ì˜ˆìƒ ì„±ëŠ¥ (RTX 2080Ti x2):")
            report_lines.append(f"    - ì¶”ë¡  ì‹œê°„: {estimated['estimated_rtx2080ti_time_ms']:.2f} ms")
            report_lines.append(f"    - FPS: {estimated['estimated_rtx2080ti_fps']:.2f}")
            report_lines.append(f"    - ì†ë„ í–¥ìƒ: {estimated['speedup_factor']:.2f}x")
            report_lines.append(f"    - TensorRT: {'ì‚¬ìš©' if use_tensorrt else 'ë¯¸ì‚¬ìš©'}")
            
            if model_key != "face_recognition":  # Face Recognitionì€ ë³„ë„ GPUì—ì„œ ì‹¤í–‰
                total_estimated_time += estimated['estimated_rtx2080ti_time_ms']
        
        report_lines.append("")
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ (ë³‘ë ¬ ì‹¤í–‰ ê³ ë ¤)
    report_lines.append("=" * 80)
    report_lines.append("ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜ˆìƒ ì„±ëŠ¥")
    report_lines.append("=" * 80)
    
    # GPU 0: Violation + Pose (ìˆœì°¨ ì‹¤í–‰)
    violation_time = 0.0
    pose_time = 0.0
    face_time = 0.0
    
    for model_key, model_data in performance_results["models"].items():
        if "error" in model_data:
            continue
        estimated = estimate_rtx2080ti_performance(model_data, use_tensorrt, multi_gpu=False)
        if "estimated_rtx2080ti_time_ms" in estimated:
            if model_key == "violation":
                violation_time = estimated['estimated_rtx2080ti_time_ms']
            elif model_key == "pose":
                pose_time = estimated['estimated_rtx2080ti_time_ms']
            elif model_key == "face_detection":
                face_time = estimated['estimated_rtx2080ti_time_ms']
    
    # GPU 0ì—ì„œ Violationê³¼ PoseëŠ” ìˆœì°¨ ì‹¤í–‰
    gpu0_time = violation_time + pose_time
    
    # GPU 1ì—ì„œ FaceëŠ” ë³„ë„ ì‹¤í–‰ (ë³‘ë ¬)
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„ = max(GPU0 ì‹œê°„, GPU1 ì‹œê°„) + ê¸°íƒ€ ì²˜ë¦¬ ì‹œê°„
    pipeline_time = max(gpu0_time, face_time) + 5.0  # ê¸°íƒ€ ì²˜ë¦¬ ì‹œê°„ 5ms ì¶”ê°€
    pipeline_fps = 1000.0 / pipeline_time if pipeline_time > 0 else 0.0
    
    report_lines.append(f"GPU 0 (Violation + Pose): {gpu0_time:.2f} ms")
    report_lines.append(f"GPU 1 (Face Detection): {face_time:.2f} ms")
    report_lines.append(f"ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„: {pipeline_time:.2f} ms")
    report_lines.append(f"ì˜ˆìƒ ì „ì²´ FPS: {pipeline_fps:.2f}")
    report_lines.append("")
    
    report_text = "\n".join(report_lines)
    
    # íŒŒì¼ë¡œ ì €ì¥
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        tensorrt_suffix = "_tensorrt" if use_tensorrt else ""
        output_file = os.path.join(
            config.Paths.LOG_FOLDER, 
            f"rtx2080ti_performance{tensorrt_suffix}_{timestamp}.txt"
        )
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    logger.info(f"\nâœ… RTX 2080Ti ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    return report_text


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--test-dataset', type=str, default=None,
                        help='í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ (Ground Truth í¬í•¨)')
    parser.add_argument('--ground-truth', type=str, default=None,
                        help='Ground Truth JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--rtx2080ti', action='store_true',
                        help='RTX 2080Ti 2ëŒ€ í™˜ê²½ ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°')
    parser.add_argument('--tensorrt', action='store_true',
                        help='TensorRT ì‚¬ìš© ì‹œ ì˜ˆìƒ ì„±ëŠ¥ (--rtx2080tiì™€ í•¨ê»˜ ì‚¬ìš©)')
    args = parser.parse_args()
    
    logger.info("ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    logger.info("=" * 60)
    
    if args.ground_truth:
        logger.info(f"âš ï¸  Ground Truth íŒŒì¼ ì§€ì •ë¨: {args.ground_truth}")
        logger.info("âš ï¸  Ground Truth ì§€ì›ì€ í–¥í›„ êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")
        logger.info("âš ï¸  í˜„ì¬ëŠ” ê°ì§€ìœ¨(Detection Rate) ê¸°ë°˜ ì§€í‘œë§Œ ì œê³µë©ë‹ˆë‹¤.")
    
    try:
        # SafetySystem ì´ˆê¸°í™”
        logger.info("\nğŸ”§ SafetySystem ì´ˆê¸°í™” ì¤‘...")
        safety_system = SafetySystem()
        logger.info("âœ… SafetySystem ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
        performance_results = collect_performance_metrics(safety_system)
        
        # RTX 2080Ti ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚°
        if args.rtx2080ti:
            logger.info("\nğŸš€ RTX 2080Ti 2ëŒ€ í™˜ê²½ ì˜ˆìƒ ì„±ëŠ¥ ê³„ì‚° ì¤‘...")
            rtx2080ti_report = generate_rtx2080ti_report(
                performance_results,
                use_tensorrt=args.tensorrt
            )
            print("\n" + rtx2080ti_report)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        logger.info("\nğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        report_text = generate_report(performance_results)
        
        # ì½˜ì†”ì— ì¶œë ¥
        print("\n" + report_text)
        
        logger.info("\nâœ… ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info("\nğŸ’¡ ì°¸ê³ : ì •í™•í•œ Precision, Recall, F1-Scoreë¥¼ ê³„ì‚°í•˜ë ¤ë©´ Ground Truth ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        logger.info("ğŸ’¡ í˜„ì¬ëŠ” ì €ì¥ëœ ë¡œê·¸ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì§€ìœ¨(Detection Rate)ì„ ì¸¡ì •í•©ë‹ˆë‹¤.")
        if not args.rtx2080ti:
            logger.info("ğŸ’¡ RTX 2080Ti ì˜ˆìƒ ì„±ëŠ¥ì„ ë³´ë ¤ë©´ --rtx2080ti ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
