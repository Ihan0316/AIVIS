import os
import sys
import platform
import cv2
import numpy as np
import onnxruntime
from ultralytics import YOLO  # YOLOv8n-Face: í‚¤í¬ì¸íŠ¸ ì œê³µ + 3ë°° ë¹ ë¦„!
import time
import faiss  # Faiss ì„í¬íŠ¸

# config ì„í¬íŠ¸ ê²½ë¡œ ìˆ˜ì •
base_dir = os.path.dirname(os.path.abspath(__file__))  # scripts/
parent_dir = os.path.dirname(base_dir)  # final/
backend_dir = os.path.join(parent_dir, 'src', 'backend')

# sys.pathì— ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.abspath(backend_dir))
sys.path.insert(0, os.path.abspath(parent_dir))

# config ì„í¬íŠ¸ (ê²½ë¡œ ì„¤ì •ìš©)
try:
    import config
except ImportError:
    # configê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
    config = None

# --- ì„¤ì • ---
# data/imagesë¥¼ ì°¸ì¡°í•˜ë„ë¡ ê²½ë¡œ ìˆ˜ì •
base_dir = os.path.dirname(os.path.abspath(__file__))  # scripts/
parent_dir = os.path.dirname(base_dir)  # face/
project_root = os.path.dirname(parent_dir)  # aivis-project/ (í”„ë¡œì íŠ¸ ë£¨íŠ¸)

# ì–¼êµ´ ì´ë¯¸ì§€ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ (PPE í•©ì„± ì´ë¯¸ì§€ í¬í•¨)
# new_faces í´ë” ìš°ì„  í™•ì¸ â†’ data/images â†’ image ìˆœì„œë¡œ í™•ì¸
new_faces_dir = os.path.join(parent_dir, "data", "new_faces")  # new_faces í´ë”
image_dir = os.path.join(parent_dir, "image")  # ì›ë³¸ ì´ë¯¸ì§€ í´ë”
data_images_dir = os.path.join(parent_dir, "data", "images")  # PPE í•©ì„± ì´ë¯¸ì§€ í¬í•¨ í´ë”

# new_faces í´ë” ì²˜ë¦¬: new_facesì˜ ì´ë¯¸ì§€ë¥¼ data/imagesë¡œ ì´ë™
if os.path.exists(new_faces_dir) and os.listdir(new_faces_dir):
    print(f"ğŸ“ new_faces í´ë” ë°œê²¬: {new_faces_dir}")
    print(f"   â†’ data/imagesë¡œ ì´ë™í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
    
    # data/images í´ë” ìƒì„±
    os.makedirs(data_images_dir, exist_ok=True)
    
    # new_facesì˜ ê° ì‘ì—…ì í´ë”ë¥¼ data/imagesë¡œ ì´ë™
    import shutil
    moved_count = 0
    for person_folder in os.listdir(new_faces_dir):
        person_path = os.path.join(new_faces_dir, person_folder)
        if os.path.isdir(person_path):
            dest_path = os.path.join(data_images_dir, person_folder)
            if os.path.exists(dest_path):
                # ì´ë¯¸ ì¡´ì¬í•˜ë©´ íŒŒì¼ë§Œ ì´ë™
                for filename in os.listdir(person_path):
                    src_file = os.path.join(person_path, filename)
                    if os.path.isfile(src_file):
                        dest_file = os.path.join(dest_path, filename)
                        if not os.path.exists(dest_file):
                            shutil.move(src_file, dest_file)
                            moved_count += 1
                # ë¹ˆ í´ë” ì‚­ì œ
                try:
                    if not os.listdir(person_path):
                        os.rmdir(person_path)
                except:
                    pass
            else:
                # í´ë” ì „ì²´ ì´ë™
                shutil.move(person_path, dest_path)
                moved_count += 1
                print(f"   âœ… '{person_folder}' í´ë” ì´ë™ ì™„ë£Œ")
    
    if moved_count > 0:
        print(f"   âœ… ì´ {moved_count}ê°œ í´ë”/íŒŒì¼ ì´ë™ ì™„ë£Œ")

# DB_PATH ìš°ì„ ìˆœìœ„: data/images > image > new_faces
if os.path.exists(data_images_dir) and os.listdir(data_images_dir):
    DB_PATH = data_images_dir  # PPE í•©ì„± ì´ë¯¸ì§€ í¬í•¨ í´ë” ì‚¬ìš© (ì›ë³¸ + PPE í•©ì„± ëª¨ë‘ í¬í•¨)
    print(f"âœ… PPE í•©ì„± ì´ë¯¸ì§€ í¬í•¨ í´ë” ì‚¬ìš©: {DB_PATH}")
elif os.path.exists(image_dir) and os.listdir(image_dir):
    DB_PATH = image_dir  # ì›ë³¸ ì´ë¯¸ì§€ í´ë” ì‚¬ìš© (PPE í•©ì„± ì—†ì„ ë•Œ)
    print(f"âœ… ì›ë³¸ ì´ë¯¸ì§€ í´ë” ì‚¬ìš©: {DB_PATH}")
elif os.path.exists(new_faces_dir) and os.listdir(new_faces_dir):
    DB_PATH = new_faces_dir  # new_faces í´ë” ì§ì ‘ ì‚¬ìš© (í´ë°±)
    print(f"âœ… new_faces í´ë” ì‚¬ìš©: {DB_PATH}")
else:
    DB_PATH = data_images_dir  # í´ë°±
    print(f"âœ… ë³µì‚¬ëœ ì´ë¯¸ì§€ í´ë” ì‚¬ìš©: {DB_PATH}")

# FAISS íŒŒì¼ ì €ì¥ ê²½ë¡œ: face/data í´ë”ì— ì €ì¥ (ë°±ì—”ë“œì™€ í†µì¼)
# face/data: face/data/face_index.faiss, face/data/face_index.faiss.labels.npy
face_data_dir = os.path.join(parent_dir, "data")  # face/data í´ë”
os.makedirs(face_data_dir, exist_ok=True)
FAISS_INDEX_FILE = os.path.join(face_data_dir, "face_index.faiss")  # face/dataì— ì €ì¥
FAISS_LABELS_FILE = os.path.join(face_data_dir, "face_index.faiss.labels.npy")  # face/dataì— ì €ì¥

# ë°±ì—…ìš© ì›ë³¸ ì„ë² ë”© (face/data/embeddingsì— ì €ì¥ - ì°¸ê³ ìš©)
OUTPUT_EMBEDDINGS = os.path.join(parent_dir, "data", "embeddings", "face_embeddings.npy")  # ë°±ì—…ìš© ì›ë³¸ (ì ˆëŒ€ ê²½ë¡œ)
embeddings_dir = os.path.join(parent_dir, "data", "embeddings")
os.makedirs(embeddings_dir, exist_ok=True)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— FAISS íŒŒì¼ ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ í™•ì¸
os.makedirs(project_root, exist_ok=True)

# ì¦ë¶„ ì—…ë°ì´íŠ¸ ì„¤ì •
INCREMENTAL_UPDATE = False  # True: ìƒˆ ì´ë¯¸ì§€ë§Œ ì¶”ê°€, False: ì „ì²´ ì¬êµ¬ì¶• (ìµœê³  ì„±ëŠ¥ ì¬ìƒì„±)
PROCESSED_IMAGES_FILE = "processed_images.txt"  # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê¸°ë¡ íŒŒì¼

# PPE í•©ì„± ìë™ ì‹¤í–‰ ì„¤ì •
AUTO_PPE_SYNTHESIS = True  # True: new_facesì—ì„œ ì´ë™í•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ìë™ìœ¼ë¡œ PPE í•©ì„± ìˆ˜í–‰

# CCTV í™˜ê²½ ìµœì í™” ì„¤ì •
USE_SMART_AUGMENTATION = True  # True: ìŠ¤ë§ˆíŠ¸ ì¦ê°• (í’ˆì§ˆì— ë”°ë¼ ì„ íƒì ), False: ëª¨ë“  ì¦ê°•
AUGMENTATION_MODE = "full"  # "full": 12ê°€ì§€, "balanced": 8ê°€ì§€, "fast": 5ê°€ì§€ (ì†ë„ ìš°ì„ )
# â­ full ëª¨ë“œ: ìµœê³  í’ˆì§ˆ (12ê°€ì§€ ì¦ê°•, ì¸ì‹ë¥  ìµœëŒ€í™”) - ê¶Œì¥!
# balanced ëª¨ë“œ: í’ˆì§ˆê³¼ ì†ë„ ê· í˜• (8ê°€ì§€ ì¦ê°•, ì•½ 30-40% ì‹œê°„ ë‹¨ì¶• ì˜ˆìƒ)
# fast ëª¨ë“œ: ì†ë„ ìš°ì„  (5ê°€ì§€ ì¦ê°•, ì•½ 50-60% ì‹œê°„ ë‹¨ì¶• ì˜ˆìƒ)

# ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ ì„¤ì • (ì‹œê°í™”/ê²°ê³¼ ì •ë¦¬ìš©)
SAVE_AUGMENTED_IMAGES = True  # True: ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥, False: ì €ì¥ ì•ˆ í•¨
AUGMENTED_IMAGES_DIR = os.path.join(parent_dir, "data", "augmented")  # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ

# ëŒ€í‘œ ì„ë² ë”©(ì„¼íŠ¸ë¡œì´ë“œ) ì‚¬ìš© ì„¤ì •
# â­ ë“±ë¡ ì¸ì›ì´ ì ìœ¼ë©´(~10ëª…) ëª¨ë“  ì„ë² ë”© ì €ì¥ì´ ì¸ì‹ë¥  í–¥ìƒì— ìœ ë¦¬!
USE_REPRESENTATIVE_EMBEDDING = False  # False: ëª¨ë“  ì„ë² ë”© ì €ì¥ (ì¸ì‹ë¥  ìµœëŒ€í™”)
STORE_CENTROID_ONLY = False           # (USE_REPRESENTATIVE_EMBEDDING=Falseë©´ ë¬´ì‹œë¨)
TOP_N_PER_PERSON = 15                 # (USE_REPRESENTATIVE_EMBEDDING=Falseë©´ ë¬´ì‹œë¨)

# í’ˆì§ˆ í–¥ìƒ ì˜µì…˜
ENABLE_CLAHE = True                   # ì¡°ëª… í‘œì¤€í™” (Y ì±„ë„ CLAHE)
ENABLE_TTA_FLIP = True                # Test-Time Augmentation: ì¢Œìš° í”Œë¦½ í‰ê· 
MIN_BLUR_VARIANCE = 40.0              # íë¦¼(ë¸”ëŸ¬) ì„ê³„ê°’ (Variance of Laplacian)
MIN_BRIGHTNESS = 20.0                 # ìµœì†Œ ë°ê¸° (0~255, í‰ê· )
MAX_BRIGHTNESS = 235.0                # ìµœëŒ€ ë°ê¸° (0~255, í‰ê· )

def is_low_quality(img: np.ndarray) -> bool:
    """ê°„ë‹¨í•œ í’ˆì§ˆ ì²´í¬: ë¸”ëŸ¬/ë°ê¸° ê¸°ì¤€ìœ¼ë¡œ ì €í’ˆì§ˆ íŒì •"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # ë¸”ëŸ¬ ì¸¡ì •
        var = cv2.Laplacian(gray, cv2.CV_64F).var()
        # ë°ê¸° ì¸¡ì •
        mean_brightness = float(np.mean(gray))
        if var < MIN_BLUR_VARIANCE:
            return True
        if mean_brightness < MIN_BRIGHTNESS or mean_brightness > MAX_BRIGHTNESS:
            return True
        return False
    except Exception:
        return False

def apply_clahe_bgr(img: np.ndarray) -> np.ndarray:
    """Y ì±„ë„ CLAHEë¡œ ì¡°ëª… í‘œì¤€í™”"""
    if img is None or img.size == 0:
        return img
    try:
        ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)
        y, cr, cb = cv2.split(ycrcb)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        y = clahe.apply(y)
        ycrcb = cv2.merge([y, cr, cb])
        out = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)
        return out
    except Exception:
        return img

def extract_embedding_with_tta(rec_model, face_img: np.ndarray) -> np.ndarray:
    """
    rec_model.get_feat()ì— ëŒ€í•´ TTA(flip) ì ìš© í›„ í‰ê·  ì„ë² ë”© ë°˜í™˜.
    ë°˜í™˜ì€ float32 512ì°¨ì›, L2 ì •ê·œí™”ë¨.
    
    âš ï¸ ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” InsightFace ëª¨ë¸ìš©ì…ë‹ˆë‹¤. AdaFaceëŠ” FastIndustrialRecognizerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        embs = []
        # ì›ë³¸
        emb0 = rec_model.get_feat(face_img)
        if emb0 is not None:
            embs.append(emb0.astype(np.float32))
        # ì¢Œìš° í”Œë¦½
        if ENABLE_TTA_FLIP:
            flipped = cv2.flip(face_img, 1)
            emb1 = rec_model.get_feat(flipped)
            if emb1 is not None:
                embs.append(emb1.astype(np.float32))
        if not embs:
            return None
        embs = np.array(embs, dtype=np.float32)
        avg = np.mean(embs, axis=0)
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(avg)
        if norm > 0:
            avg = (avg / norm).astype(np.float32)
        return avg
    except Exception:
        return None


def extract_embedding_adaface_tta(fast_recognizer, frame: np.ndarray, kps: np.ndarray, face_analyzer=None) -> tuple:
    """
    AdaFace ëª¨ë¸ì— TTA(flip) ì ìš© í›„ í‰ê·  ì„ë² ë”© ë°˜í™˜.
    ì‹¤ì‹œê°„ ì¸ì‹ê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš©.
    ë°˜í™˜: (embedding, aligned_face) - embeddingì€ float32 512ì°¨ì›, L2 ì •ê·œí™”ë¨
    """
    try:
        embs = []
        aligned_face = None
        
        # ì›ë³¸ ì„ë² ë”©
        result = fast_recognizer.get_embedding_fast(frame, kps, face_analyzer=face_analyzer)
        if result is not None and len(result) >= 2:
            emb0, aligned_face = result[0], result[1]
            if emb0 is not None and isinstance(emb0, np.ndarray):
                embs.append(emb0.astype(np.float32))
        
        # ì¢Œìš° í”Œë¦½ ì„ë² ë”©
        if ENABLE_TTA_FLIP:
            flipped_frame = cv2.flip(frame, 1)
            # í‚¤í¬ì¸íŠ¸ë„ ì¢Œìš° ë°˜ì „ (x ì¢Œí‘œ ë°˜ì „)
            h, w = frame.shape[:2]
            flipped_kps = kps.copy()
            flipped_kps[:, 0] = w - flipped_kps[:, 0]
            # ì™¼ìª½/ì˜¤ë¥¸ìª½ ëˆˆ, ì…ê¼¬ë¦¬ ìŠ¤ì™‘ (0<->1, 3<->4)
            flipped_kps[[0, 1]] = flipped_kps[[1, 0]]
            flipped_kps[[3, 4]] = flipped_kps[[4, 3]]
            
            result = fast_recognizer.get_embedding_fast(flipped_frame, flipped_kps, face_analyzer=face_analyzer)
            if result is not None and len(result) >= 2:
                emb1, _ = result[0], result[1]
                if emb1 is not None and isinstance(emb1, np.ndarray):
                    embs.append(emb1.astype(np.float32))
        
        if not embs:
            return None, None
        
        embs = np.array(embs, dtype=np.float32)
        avg = np.mean(embs, axis=0)
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(avg)
        if norm > 0:
            avg = (avg / norm).astype(np.float32)
        return avg, aligned_face
        
    except Exception as e:
        print(f"  âš ï¸ AdaFace TTA ì˜¤ë¥˜: {e}")
        return None, None


def extract_rotated_embeddings(fast_recognizer, aligned_face: np.ndarray) -> list:
    """
    ì •ë ¬ëœ ì–¼êµ´(112x112)ì„ 90ë„ íšŒì „ì‹œì¼œì„œ ì¶”ê°€ ì„ë² ë”© ìƒì„±.
    ë„˜ì–´ì§„ ì‚¬ëŒ ì¸ì‹ì„ ìœ„í•œ ì¦ê°•.
    ë°˜í™˜: íšŒì „ëœ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ [(embedding, rotation_label), ...]
    """
    rotated_embeddings = []
    
    if aligned_face is None or aligned_face.size == 0:
        return rotated_embeddings
    
    try:
        # ì‹œê³„ë°©í–¥ 90ë„ íšŒì „ (ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë„˜ì–´ì§)
        rotated_cw = cv2.rotate(aligned_face, cv2.ROTATE_90_CLOCKWISE)
        # TensorRT ìš°ì„ , ONNX í´ë°±
        emb_cw = None
        if fast_recognizer.use_tensorrt:
            emb_cw = fast_recognizer._get_embedding_from_tensorrt(rotated_cw)
        if emb_cw is None and fast_recognizer.use_direct_onnx:
            emb_cw = fast_recognizer._get_embedding_from_onnx(rotated_cw)
        if emb_cw is not None:
            norm_val = np.linalg.norm(emb_cw)
            if norm_val > 0:
                emb_cw = (emb_cw / norm_val).astype(np.float32)
                rotated_embeddings.append((emb_cw, "rotate_90_cw"))
        
        # ë°˜ì‹œê³„ë°©í–¥ 90ë„ íšŒì „ (ì™¼ìª½ìœ¼ë¡œ ë„˜ì–´ì§)
        rotated_ccw = cv2.rotate(aligned_face, cv2.ROTATE_90_COUNTERCLOCKWISE)
        # TensorRT ìš°ì„ , ONNX í´ë°±
        emb_ccw = None
        if fast_recognizer.use_tensorrt:
            emb_ccw = fast_recognizer._get_embedding_from_tensorrt(rotated_ccw)
        if emb_ccw is None and fast_recognizer.use_direct_onnx:
            emb_ccw = fast_recognizer._get_embedding_from_onnx(rotated_ccw)
        if emb_ccw is not None:
            norm_val = np.linalg.norm(emb_ccw)
            if norm_val > 0:
                emb_ccw = (emb_ccw / norm_val).astype(np.float32)
                rotated_embeddings.append((emb_ccw, "rotate_90_ccw"))
        
    except Exception as e:
        print(f"  âš ï¸ 90ë„ íšŒì „ ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
    
    return rotated_embeddings


def load_processed_images():
    """ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(PROCESSED_IMAGES_FILE):
        return set()
    
    processed_set = set()
    base_dir = os.path.dirname(os.path.abspath(__file__))  # scripts/
    parent_dir = os.path.dirname(base_dir)  # project root/
    
    with open(PROCESSED_IMAGES_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if line.startswith('../'):
                abs_path = os.path.normpath(os.path.join(base_dir, line))
            else:
                abs_path = os.path.normpath(line)
            processed_set.add(abs_path)
    
    return processed_set


def save_processed_image(image_path):
    """ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤."""
    with open(PROCESSED_IMAGES_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{image_path}\n")


def update_processed_images(image_paths):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì¼ê´„ ê¸°ë¡í•©ë‹ˆë‹¤."""
    with open(PROCESSED_IMAGES_FILE, 'a', encoding='utf-8') as f:
        for path in image_paths:
            f.write(f"{path}\n")


def create_augmentation_grid(images, labels, output_path, max_size=200):
    """ì¦ê°• ì´ë¯¸ì§€ë“¤ì„ ê·¸ë¦¬ë“œ í˜•íƒœë¡œ í•©ì³ì„œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not images:
        return
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ê·¸ë¦¬ë“œìš©)
    resized_images = []
    for img in images:
        h, w = img.shape[:2]
        if h > max_size or w > max_size:
            scale = min(max_size / h, max_size / w)
            new_h, new_w = int(h * scale), int(w * scale)
            resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        else:
            resized = img.copy()
        resized_images.append(resized)
    
    # ê·¸ë¦¬ë“œ í¬ê¸° ê³„ì‚° (ê°€ë¡œ 4ê°œì”©)
    cols = 4
    rows = (len(resized_images) + cols - 1) // cols
    
    # ê° ì´ë¯¸ì§€ í¬ê¸° í†µì¼
    target_h = max_size
    target_w = max_size
    
    # ë¹ˆ ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ìƒì„±
    grid_img = np.zeros((rows * target_h, cols * target_w, 3), dtype=np.uint8)
    
    # ì´ë¯¸ì§€ë“¤ì„ ê·¸ë¦¬ë“œì— ë°°ì¹˜
    for idx, (img, label) in enumerate(zip(resized_images, labels)):
        row = idx // cols
        col = idx % cols
        
        h, w = img.shape[:2]
        y_offset = (target_h - h) // 2
        x_offset = (target_w - w) // 2
        
        # ì´ë¯¸ì§€ ë°°ì¹˜
        grid_img[row * target_h + y_offset:row * target_h + y_offset + h,
                 col * target_w + x_offset:col * target_w + x_offset + w] = img
        
        # ë ˆì´ë¸” í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.putText(grid_img, label, 
                   (col * target_w + 5, row * target_h + 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
    
    # ê·¸ë¦¬ë“œ ì´ë¯¸ì§€ ì €ì¥ (í•œê¸€ ê²½ë¡œ ì§€ì›)
    try:
        # cv2.imwriteëŠ” í•œê¸€ ê²½ë¡œë¥¼ ì œëŒ€ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ë¯€ë¡œ imencode + tofile ì‚¬ìš©
        ext = os.path.splitext(output_path)[1]
        result, encoded_img = cv2.imencode(ext, grid_img)
        if result:
            encoded_img.tofile(output_path)
    except Exception as e:
        # í´ë°±: ì¼ë°˜ imwrite ì‹œë„
        cv2.imwrite(output_path, grid_img)


def load_existing_database():
    """ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ì™€ ë¼ë²¨ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    # face/data í´ë”ì—ì„œ FAISS íŒŒì¼ ë¡œë“œ (ë°±ì—”ë“œì™€ í†µì¼)
    index_path = FAISS_INDEX_FILE
    labels_path = FAISS_LABELS_FILE
    
    # face/dataì— ì—†ìœ¼ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë„ í™•ì¸ (í•˜ìœ„ í˜¸í™˜ì„±)
    if not os.path.exists(index_path):
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        project_index = os.path.join(project_root, "face_index.faiss")
        project_labels = os.path.join(project_root, "face_index.faiss.labels.npy")
        if os.path.exists(project_index):
            index_path = project_index
            labels_path = project_labels
            print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬ (í•˜ìœ„ í˜¸í™˜ì„±): {index_path}")
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ë„ ì—†ìœ¼ë©´ face/data/embeddings ê²½ë¡œë„ í™•ì¸ (ë” ì˜¤ë˜ëœ ë²„ì „ í˜¸í™˜ì„±)
    if not os.path.exists(index_path):
        embeddings_dir = os.path.join(parent_dir, "data", "embeddings")
        old_index_path = os.path.join(embeddings_dir, "face_index.faiss")
        old_labels_path = os.path.join(embeddings_dir, "face_index.faiss.labels.npy")
        if os.path.exists(old_index_path):
            index_path = old_index_path
            labels_path = old_labels_path
            print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬ (í•˜ìœ„ í˜¸í™˜ì„±): {index_path}")
    
    if not os.path.exists(index_path) or not os.path.exists(labels_path):
        return None, None, set()
    
    try:
        index = faiss.read_index(index_path)
        labels = np.load(labels_path, allow_pickle=True)
        
        # ê¸°ì¡´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ëª©ë¡ ë¡œë“œ
        processed = load_processed_images()
        
        print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {index.ntotal}ê°œ ì„ë² ë”©, {len(processed)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ë¨ (ê²½ë¡œ: {index_path})")
        return index, labels, processed
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None, set()


def build_database():
    """
    DB_PATHì— ìˆëŠ” ëª¨ë“  ì´ë¯¸ì§€ë¡œë¶€í„° ì–¼êµ´ íŠ¹ì§•(ì„ë² ë”©)ì„ ì¶”ì¶œí•˜ì—¬ Faiss ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì›ë³¸, ì¢Œìš° ë°˜ì „, ë°ê¸° ì¡°ì ˆ ë“± ë°ì´í„° ì¦ê°•ì„ ì ìš©í•©ë‹ˆë‹¤.
    new_faces í´ë”ì˜ ì´ë¯¸ì§€ëŠ” ìë™ìœ¼ë¡œ data/imagesë¡œ ì´ë™í•˜ê³ , PPE í•©ì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    # Windows ì½˜ì†” ìœ ë‹ˆì½”ë“œ ì¶œë ¥ ëŒ€ì‘
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except Exception:
        pass

    # PPE í•©ì„± ìë™ ì‹¤í–‰ (new_facesì—ì„œ ì´ë™í•œ ì´ë¯¸ì§€ì— ëŒ€í•´)
    if AUTO_PPE_SYNTHESIS and DB_PATH == data_images_dir:
        print("\n" + "=" * 70)
        print("ğŸ› ï¸ PPE í•©ì„± ìë™ ì‹¤í–‰")
        print("=" * 70)
        try:
            # ppe_synthesis_and_embedding.pyì˜ PPE í•©ì„± í•¨ìˆ˜ ì„í¬íŠ¸
            ppe_script_path = os.path.join(os.path.dirname(__file__), "ppe_synthesis_and_embedding.py")
            if os.path.exists(ppe_script_path):
                # PPE í•©ì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì„œë¸Œí”„ë¡œì„¸ìŠ¤ë¡œ ì‹¤í–‰
                import subprocess
                print(f"   PPE í•©ì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: {ppe_script_path}")
                result = subprocess.run(
                    [sys.executable, ppe_script_path],
                    cwd=os.path.dirname(ppe_script_path),
                    capture_output=False,  # ì‹¤ì‹œê°„ ì¶œë ¥ì„ ìœ„í•´ False
                    text=True
                )
                if result.returncode == 0:
                    print("âœ… PPE í•©ì„± ì™„ë£Œ")
                else:
                    print(f"âš ï¸ PPE í•©ì„± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): returncode={result.returncode}")
            else:
                print(f"âš ï¸ PPE í•©ì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ppe_script_path}")
                print("   (ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤)")
        except Exception as e:
            print(f"âš ï¸ PPE í•©ì„± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
            import traceback
            traceback.print_exc()
        print("=" * 70 + "\n")

    print("ëª¨ë¸ì„ ë¡œë”©í•©ë‹ˆë‹¤. ëª‡ ì´ˆ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
    
    # 1. YOLOv8n-Face ëª¨ë¸ ë¡œë“œ (Mac MPS ì§€ì›)
    import torch
    # Mac MPS ë””ë°”ì´ìŠ¤ í™•ì¸
    use_mps = torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False
    device = 'mps' if use_mps else 'cpu'
    
    yolo_face_engine_path = os.path.join(project_root, "model", "yolov8n-face.engine")
    yolo_face_pt_path = os.path.join(project_root, "model", "yolov8n-face.pt")
    
    if os.path.exists(yolo_face_pt_path):
        print(f"YOLOv8n-Face PT ëª¨ë¸ ë¡œë”© ì¤‘: {yolo_face_pt_path} (ë””ë°”ì´ìŠ¤: {device})")
        yolo_face_model = YOLO(yolo_face_pt_path)
        # YOLO ëª¨ë¸ì€ device íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ë¡  ì‹œì— ì „ë‹¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œë“œë§Œ
        print(f"âœ… YOLOv8n-Face PT ë¡œë“œ ì™„ë£Œ (ì¶”ë¡  ì‹œ {device.upper()} ì‚¬ìš©)")
    elif os.path.exists(yolo_face_engine_path):
        # TensorRT ì—”ì§„ì€ Macì—ì„œ ì‘ë™í•˜ì§€ ì•Šì§€ë§Œ, í´ë°±ìœ¼ë¡œ ì‹œë„
        print(f"âš ï¸ TensorRT ì—”ì§„ì€ Macì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. PT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        print(f"YOLOv8n-Face TensorRT ì—”ì§„ ë¡œë”© ì‹œë„: {yolo_face_engine_path}")
        yolo_face_model = YOLO(yolo_face_engine_path, task='pose')
        print(f"âœ… YOLOv8n-Face TensorRT ë¡œë“œ ì™„ë£Œ")
    else:
        print(f"âŒ YOLOv8n-Face ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print(f"   í™•ì¸ ê²½ë¡œ: {yolo_face_engine_path} ë˜ëŠ” {yolo_face_pt_path}")
        return
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    # 2. AdaFace ëª¨ë¸ (ì„ë² ë”© ì¶”ì¶œìš©) - TensorRT ì—”ì§„ ìš°ì„ 
    adaface_engine_path = os.path.join(project_root, "model", "adaface_ir50_ms1mv2.engine")
    adaface_onnx_path = os.path.join(project_root, "model", "adaface_ir50_ms1mv2.onnx")
    
    # FastIndustrialRecognizerëŠ” .onnx ê²½ë¡œë¥¼ ë°›ìœ¼ë©´ ìë™ìœ¼ë¡œ .engineì„ ì°¾ìŒ
    # í•˜ì§€ë§Œ .engineë§Œ ìˆëŠ” ê²½ìš°ë¥¼ ìœ„í•´ .engine ê²½ë¡œ ì§ì ‘ ì „ë‹¬
    if os.path.exists(adaface_engine_path):
        adaface_model_path = adaface_engine_path
        print(f"âœ… AdaFace TensorRT ì—”ì§„ ì‚¬ìš©: {adaface_model_path}")
    elif os.path.exists(adaface_onnx_path):
        adaface_model_path = adaface_onnx_path
        print(f"âœ… AdaFace ONNX ëª¨ë¸ ì‚¬ìš©: {adaface_model_path}")
    else:
        print(f"âŒ AdaFace ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print(f"   í™•ì¸ ê²½ë¡œ: {adaface_engine_path} ë˜ëŠ” {adaface_onnx_path}")
        return
    
    # 3. FastIndustrialRecognizer ì´ˆê¸°í™” (ì„ë² ë”© ì¶”ì¶œ)
    fast_recognizer = None
    try:
        backend_dir = os.path.join(project_root, "src", "backend")
        if backend_dir not in sys.path:
            sys.path.insert(0, backend_dir)
        from fast_face_recognizer import FastIndustrialRecognizer
        fast_recognizer = FastIndustrialRecognizer(
            model_path=adaface_model_path,
            ctx_id=0,  # GPU ì‚¬ìš© (TensorRT ìš°ì„ )
            use_adaface=True
        )
        print(f"âœ… FastIndustrialRecognizer ì´ˆê¸°í™” ì™„ë£Œ (AdaFace TensorRT/GPU)")
    except Exception as e:
        print(f"âŒ FastIndustrialRecognizer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (YOLOv8n-Face í‚¤í¬ì¸íŠ¸ + AdaFace ì„ë² ë”© - ì‹¤ì‹œê°„ ì‹œìŠ¤í…œê³¼ ë™ì¼!)")
    
    # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
    if SAVE_AUGMENTED_IMAGES:
        os.makedirs(AUGMENTED_IMAGES_DIR, exist_ok=True)
        print(f"ğŸ“¸ ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í™œì„±í™”: {AUGMENTED_IMAGES_DIR}")
    
    # ì¦ë¶„ ì—…ë°ì´íŠ¸ ëª¨ë“œ í™•ì¸
    if INCREMENTAL_UPDATE:
        index, existing_labels, processed_images = load_existing_database()
        if index is not None and existing_labels is not None:
            print(f"ğŸ“Œ ì¦ë¶„ ì—…ë°ì´íŠ¸ ëª¨ë“œ: ê¸°ì¡´ {index.ntotal}ê°œ ì„ë² ë”© ìœ ì§€")
        else:
            print("ğŸ“Œ ìƒˆ ì¸ë±ìŠ¤ ìƒì„± ëª¨ë“œ: ì „ì²´ ì¬êµ¬ì¶•")
            index = None
            existing_labels = None
            processed_images = set()
    else:
        print("ğŸ“Œ ì „ì²´ ì¬êµ¬ì¶• ëª¨ë“œ")
        index = None
        existing_labels = None
        processed_images = set()

    # DBì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© ì¶”ì¶œ
    face_database = {}  # ì„ì‹œ ì €ì¥ìš©
    start_time = time.time()
    processed_files_count = 0
    new_files_count = 0
    embedding_count = 0
    new_image_paths = []
    # ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì¶”ì 
    person_face_detection_stats = {}  # {person_name: {'total_images': 0, 'faces_found': 0, 'faces_not_found': 0}}

    # os.walkë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ìœ„ í´ë”ê¹Œì§€ ëª¨ë‘ íƒìƒ‰
    for root, dirs, files in os.walk(DB_PATH):
        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        if not image_files:
            continue

        for file in image_files:
            image_path = os.path.join(root, file)
            # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            image_path = os.path.abspath(os.path.normpath(image_path))
            
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ ëª¨ë“œì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ëŠ” ê±´ë„ˆë›°ê¸°
            if image_path in processed_images:
                continue
            
            person_name = os.path.basename(root)  # í´ë” ì´ë¦„ì„ ì‚¬ëŒ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
            new_files_count += 1
            new_image_paths.append(image_path)
            
            # í†µê³„ ì´ˆê¸°í™”
            if person_name not in person_face_detection_stats:
                person_face_detection_stats[person_name] = {'total_images': 0, 'faces_found': 0, 'faces_not_found': 0, 'low_quality': 0}
            person_face_detection_stats[person_name]['total_images'] += 1

            print(f"ì²˜ë¦¬ ì¤‘: {image_path} (ì›ë³¸ + ì¦ê°• 3ì¢…)")

            # OpenCVë¡œ ì´ë¯¸ì§€ ì½ê¸° (í•œê¸€ ê²½ë¡œ ì§€ì›)
            # cv2.imreadëŠ” í•œê¸€ ê²½ë¡œë¥¼ ì œëŒ€ë¡œ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ë¯€ë¡œ numpyë¡œ ë¨¼ì € ì½ìŒ
            try:
                img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            except Exception as e:
                img = None
                print(f"  [ê²½ê³ ] ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            
            if img is None:
                # í´ë°±: ì¼ë°˜ imread ì‹œë„
                img = cv2.imread(image_path)
            
            if img is None:
                print(f"  [ê²½ê³ ] ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                continue

            # â­ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ì™€ ë™ì¼í•œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (640x480)
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ 640x480ì— ë§ì¶”ê³  ê²€ì • íŒ¨ë”©
            TARGET_W, TARGET_H = 640, 480
            h, w = img.shape[:2]
            scale = min(TARGET_W / w, TARGET_H / h)
            new_w, new_h = int(w * scale), int(h * scale)
            resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
            
            # ê²€ì • ë°°ê²½ì— ì¤‘ì•™ ë°°ì¹˜
            canvas = np.zeros((TARGET_H, TARGET_W, 3), dtype=np.uint8)
            x_offset = (TARGET_W - new_w) // 2
            y_offset = (TARGET_H - new_h) // 2
            canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
            img = canvas
            print(f"  âœ… 640x480 ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ (ì›ë³¸: {w}x{h} â†’ {new_w}x{new_h}, íŒ¨ë”© ì ìš©)")

            processed_files_count += 1
            new_files_count += 1
            new_image_paths.append(image_path)

            # --- [CCTV ìµœì í™”] ì‚°ì—…í˜„ì¥ CCTV í™˜ê²½ì— ë§ì¶˜ ë°ì´í„° ì¦ê°• (ìŠ¤ë§ˆíŠ¸ ëª¨ë“œ) ---
            # ì²˜ë¦¬í•  ì´ë¯¸ì§€ë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŠµë‹ˆë‹¤.
            images_to_process = []
            augmentation_labels = []  # ì¦ê°• íƒ€ì… ë ˆì´ë¸” (ì €ì¥ìš©)

            # í•­ìƒ í¬í•¨: ì›ë³¸ê³¼ ì¢Œìš°ë°˜ì „ (í•µì‹¬)
            images_to_process.append(img)
            augmentation_labels.append("original")
            images_to_process.append(cv2.flip(img, 1))
            augmentation_labels.append("flip")
            
            # â­ 90ë„ íšŒì „ ì¶”ê°€ (ë„˜ì–´ì§„ ì‚¬ëŒ ì¸ì‹ìš©)
            # ì‹œê³„ë°©í–¥ 90ë„ (ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë„˜ì–´ì§)
            rotated_cw = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
            images_to_process.append(rotated_cw)
            augmentation_labels.append("rotate_90_cw")
            
            # ë°˜ì‹œê³„ë°©í–¥ 90ë„ (ì™¼ìª½ìœ¼ë¡œ ë„˜ì–´ì§)
            rotated_ccw = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
            images_to_process.append(rotated_ccw)
            augmentation_labels.append("rotate_90_ccw")
            
            # ì¦ê°• ëª¨ë“œì— ë”°ë¼ ì„ íƒì  ì ìš©
            if AUGMENTATION_MODE == "full":
                # ì „ì²´ ì¦ê°• (12ê°€ì§€) - ìµœê³  í’ˆì§ˆ, ëŠë¦¼
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=25))
                augmentation_labels.append("bright_+25")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=45))
                augmentation_labels.append("bright_+45")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=-25))
                augmentation_labels.append("bright_-25")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=-45))
                augmentation_labels.append("bright_-45")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.15, beta=0))
                augmentation_labels.append("contrast_+1.15")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=0.85, beta=0))
                augmentation_labels.append("contrast_0.85")
                blurred = cv2.GaussianBlur(img, (3, 3), 0)
                images_to_process.append(blurred)
                augmentation_labels.append("blur")
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                sharpened = cv2.filter2D(img, -1, kernel)
                images_to_process.append(sharpened)
                augmentation_labels.append("sharpen")
                h, w = img.shape[:2]
                # ì¹´ë©”ë¼ í•´ìƒë„ ì‹œë®¬ë ˆì´ì…˜ (640 ê¸°ì¤€) - ì‹¤ì‹œê°„ ì¸ì‹ê³¼ ë™ì¼ ì¡°ê±´
                if h > 400 or w > 400:
                    # 640 í”½ì…€ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìš´ìŠ¤ì¼€ì¼ (ì¹´ë©”ë¼ ì‹œë®¬ë ˆì´ì…˜)
                    target_size = 640
                    scale = target_size / max(h, w)
                    new_h, new_w = int(h * scale), int(w * scale)
                    downscaled_cam = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
                    upscaled_cam = cv2.resize(downscaled_cam, (w, h), interpolation=cv2.INTER_LINEAR)
                    images_to_process.append(upscaled_cam)
                    augmentation_labels.append("cam_sim_640")
                    
                    # ì¶”ê°€: 480 í”½ì…€ ê¸°ì¤€ (ë” ì €í•´ìƒë„)
                    scale_480 = 480 / max(h, w)
                    new_h_480, new_w_480 = int(h * scale_480), int(w * scale_480)
                    downscaled_480 = cv2.resize(img, (new_w_480, new_h_480), interpolation=cv2.INTER_AREA)
                    upscaled_480 = cv2.resize(downscaled_480, (w, h), interpolation=cv2.INTER_LINEAR)
                    images_to_process.append(upscaled_480)
                    augmentation_labels.append("cam_sim_480")
                if len(img.shape) == 2:
                    equalized = cv2.equalizeHist(img)
                else:
                    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                    yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
                    equalized = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
                images_to_process.append(equalized)
                augmentation_labels.append("hist_equal")
                
                # ===== ğŸ”† ì¶”ê°€ ì¡°ëª… ì¦ê°• (9ê°€ì§€) =====
                
                # 1. ê°ë§ˆ ë³´ì • (ì‹¤ë‚´/ì‹¤ì™¸ ì¡°ëª… ì°¨ì´)
                # ê°ë§ˆ < 1: ë°ê²Œ (ì‹¤ì™¸/ì°½ê°€)
                # ê°ë§ˆ > 1: ì–´ë‘¡ê²Œ (ì‹¤ë‚´/ê·¸ëŠ˜)
                for gamma_val, gamma_label in [(0.7, "gamma_0.7"), (1.5, "gamma_1.5"), (2.0, "gamma_2.0")]:
                    inv_gamma = 1.0 / gamma_val
                    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
                    gamma_img = cv2.LUT(img, table)
                    images_to_process.append(gamma_img)
                    augmentation_labels.append(gamma_label)
                
                # 2. ìƒ‰ì˜¨ë„ ë³€ê²½ (í˜•ê´‘ë“±/ë°±ì—´ë“±/ìì—°ê´‘)
                # ë”°ëœ»í•œ ìƒ‰ì˜¨ë„ (ë°±ì—´ë“±, 2700K) - R ì¦ê°€, B ê°ì†Œ
                warm_img = img.copy()
                warm_img[:,:,2] = np.clip(warm_img[:,:,2] * 1.1, 0, 255).astype(np.uint8)  # R ì¦ê°€
                warm_img[:,:,0] = np.clip(warm_img[:,:,0] * 0.9, 0, 255).astype(np.uint8)  # B ê°ì†Œ
                images_to_process.append(warm_img)
                augmentation_labels.append("color_warm")
                
                # ì°¨ê°€ìš´ ìƒ‰ì˜¨ë„ (í˜•ê´‘ë“±, 6500K) - B ì¦ê°€, R ê°ì†Œ
                cool_img = img.copy()
                cool_img[:,:,0] = np.clip(cool_img[:,:,0] * 1.15, 0, 255).astype(np.uint8)  # B ì¦ê°€
                cool_img[:,:,2] = np.clip(cool_img[:,:,2] * 0.85, 0, 255).astype(np.uint8)  # R ê°ì†Œ
                images_to_process.append(cool_img)
                augmentation_labels.append("color_cool")
                
                # 3. ê·¸ë¦¼ì í•©ì„± (ë¶€ë¶„ ì¡°ëª… - ì¢Œ/ìš° ê·¸ë¦¼ì)
                h, w = img.shape[:2]
                # ì™¼ìª½ ê·¸ë¦¼ì (ì™¼ìª½ì´ ì–´ë‘ì›€)
                shadow_left = img.copy().astype(np.float32)
                for col in range(w // 2):
                    factor = 0.5 + (col / (w // 2)) * 0.5  # 0.5 ~ 1.0
                    shadow_left[:, col] = shadow_left[:, col] * factor
                shadow_left = np.clip(shadow_left, 0, 255).astype(np.uint8)
                images_to_process.append(shadow_left)
                augmentation_labels.append("shadow_left")
                
                # ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì (ì˜¤ë¥¸ìª½ì´ ì–´ë‘ì›€)
                shadow_right = img.copy().astype(np.float32)
                for col in range(w // 2, w):
                    factor = 1.0 - ((col - w // 2) / (w // 2)) * 0.5  # 1.0 ~ 0.5
                    shadow_right[:, col] = shadow_right[:, col] * factor
                shadow_right = np.clip(shadow_right, 0, 255).astype(np.uint8)
                images_to_process.append(shadow_right)
                augmentation_labels.append("shadow_right")
                
                # 4. ë…¸ì´ì¦ˆ ì¶”ê°€ (ì €ì¡°ë„ ì‹œë®¬ë ˆì´ì…˜)
                # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (ì €ì¡°ë„ ì¹´ë©”ë¼ ì‹œë®¬ë ˆì´ì…˜)
                noise_img = img.copy().astype(np.float32)
                noise = np.random.normal(0, 15, noise_img.shape).astype(np.float32)  # í‘œì¤€í¸ì°¨ 15
                noise_img = np.clip(noise_img + noise, 0, 255).astype(np.uint8)
                images_to_process.append(noise_img)
                augmentation_labels.append("noise_low_light")
                
                # ë” ì‹¬í•œ ë…¸ì´ì¦ˆ (ë§¤ìš° ì–´ë‘ìš´ í™˜ê²½)
                noise_img_heavy = img.copy().astype(np.float32)
                noise_heavy = np.random.normal(0, 25, noise_img_heavy.shape).astype(np.float32)  # í‘œì¤€í¸ì°¨ 25
                noise_img_heavy = np.clip(noise_img_heavy + noise_heavy, 0, 255).astype(np.uint8)
                images_to_process.append(noise_img_heavy)
                augmentation_labels.append("noise_very_low")
                # ===== ì¶”ê°€ ì¡°ëª… ì¦ê°• ì™„ë£Œ =====
                
            elif AUGMENTATION_MODE == "balanced":
                # ê· í˜• ëª¨ë“œ (8ê°€ì§€) - í’ˆì§ˆê³¼ ì†ë„ ê· í˜•
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=30))  # ë°ê¸° ì¦ê°€
                augmentation_labels.append("bright_+30")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=-30))  # ë°ê¸° ê°ì†Œ
                augmentation_labels.append("bright_-30")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.2, beta=0))  # ëŒ€ë¹„ ì¦ê°€
                augmentation_labels.append("contrast_+1.2")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=0.8, beta=0))  # ëŒ€ë¹„ ê°ì†Œ
                augmentation_labels.append("contrast_0.8")
                kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                sharpened = cv2.filter2D(img, -1, kernel)
                images_to_process.append(sharpened)
                augmentation_labels.append("sharpen")
                if len(img.shape) == 2:
                    equalized = cv2.equalizeHist(img)
                else:
                    yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)
                    yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
                    equalized = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
                images_to_process.append(equalized)
                augmentation_labels.append("hist_equal")
                
            elif AUGMENTATION_MODE == "fast":
                # ë¹ ë¥¸ ëª¨ë“œ (5ê°€ì§€) - ì†ë„ ìš°ì„ 
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=30))
                augmentation_labels.append("bright_+30")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.0, beta=-30))
                augmentation_labels.append("bright_-30")
                images_to_process.append(cv2.convertScaleAbs(img, alpha=1.2, beta=0))
                augmentation_labels.append("contrast_+1.2")
            # --- [CCTV ìµœì í™” ì™„ë£Œ] ---
            
            # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ (ì‹œê°í™”ìš©)
            if SAVE_AUGMENTED_IMAGES:
                # ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
                person_aug_dir = os.path.join(AUGMENTED_IMAGES_DIR, person_name)
                os.makedirs(person_aug_dir, exist_ok=True)
                
                # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ëª… (í™•ì¥ì ì œê±°)
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                
                # ê° ì¦ê°• ì´ë¯¸ì§€ ì €ì¥
                for aug_img, aug_label in zip(images_to_process, augmentation_labels):
                    aug_filename = f"{base_name}_{aug_label}.jpg"
                    aug_filepath = os.path.join(person_aug_dir, aug_filename)
                    # í•œê¸€ ê²½ë¡œ ì§€ì›
                    try:
                        result, encoded_img = cv2.imencode('.jpg', aug_img)
                        if result:
                            encoded_img.tofile(aug_filepath)
                    except Exception:
                        cv2.imwrite(aug_filepath, aug_img)
                
                # ì¦ê°• ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ ìƒì„± (í•œëˆˆì— ë³´ê¸°)
                try:
                    grid_path = os.path.join(person_aug_dir, f"{base_name}_grid.jpg")
                    create_augmentation_grid(images_to_process, augmentation_labels, grid_path)
                    print(f"  âœ… ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {len(images_to_process)}ê°œ (ê·¸ë¦¬ë“œ í¬í•¨)")
                except Exception as e:
                    print(f"  [ê²½ê³ ] ì¦ê°• ê·¸ë¦¬ë“œ ìƒì„± ì‹¤íŒ¨: {e}")

            # ì›ë³¸ ë° ì¦ê°•ëœ ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (InsightFace ì‚¬ìš©)
            # â­ InsightFaceë¡œ ì–¼êµ´ ê°ì§€ â†’ ëœë“œë§ˆí¬ ì¶”ì¶œ â†’ AdaFaceë¡œ ì„ë² ë”© ì¶”ì¶œ
            face_found_in_any_augmentation = False
            for aug_idx, augmented_img in enumerate(images_to_process):
                aug_label = augmentation_labels[aug_idx] if aug_idx < len(augmentation_labels) else "unknown"
                
                # â­ YOLOv8n-Faceë¡œ ì–¼êµ´ ê°ì§€ (í‚¤í¬ì¸íŠ¸ í¬í•¨! + 3ë°° ë¹ ë¦„)
                face_bbox = None
                kps_for_adaface = None
                try:
                    # conf ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ ì–¼êµ´ ê°ì§€ ì‹œë„ (0.1ë¡œ ë‚®ì¶¤)
                    # Mac MPS ì‚¬ìš© ì‹œ device íŒŒë¼ë¯¸í„° ì¶”ê°€
                    yolo_results = yolo_face_model(augmented_img, conf=0.1, verbose=False, device=device)
                    if yolo_results and len(yolo_results) > 0:
                        result = yolo_results[0]
                        if result.boxes is not None and len(result.boxes) > 0:
                            # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                            boxes = result.boxes.xyxy.cpu().numpy()
                            confidences = result.boxes.conf.cpu().numpy() if hasattr(result.boxes, 'conf') else None
                            areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
                            best_idx = np.argmax(areas)
                            
                            fx1, fy1, fx2, fy2 = boxes[best_idx].astype(int)
                            face_bbox = (fx1, fy1, fx2, fy2)
                            face_found_in_any_augmentation = True
                            
                            # ë””ë²„ê¹…: ì–¼êµ´ ê°ì§€ ì„±ê³µ ë¡œê·¸ (ì›ë³¸ ì´ë¯¸ì§€ì—ì„œë§Œ)
                            if aug_label == "original":
                                conf_str = f", conf={confidences[best_idx]:.3f}" if confidences is not None else ""
                                print(f"  âœ… ì–¼êµ´ ê°ì§€ ì„±ê³µ ({aug_label}): bbox=({fx1},{fy1},{fx2},{fy2}){conf_str}")
                            
                            # YOLOv8n-Face í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ (5ê°œ í¬ì¸íŠ¸!)
                            if result.keypoints is not None and len(result.keypoints) > best_idx:
                                kps = result.keypoints[best_idx].xy.cpu().numpy()
                                # kps shape: (1, 5, 2) - ì²«ë²ˆì§¸ ì°¨ì› ì œê±°
                                if kps is not None:
                                    if len(kps.shape) == 3:
                                        kps = kps[0]  # (1, 5, 2) -> (5, 2)
                                    if len(kps) >= 5:
                                        kps_for_adaface = kps[:5].astype(np.float32)
                except Exception as e:
                    if aug_label == "original":
                        print(f"  âš ï¸ ì–¼êµ´ ê°ì§€ ì˜¤ë¥˜ ({aug_label}): {e}")
                
                if face_bbox is None:
                    # ì–¼êµ´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                    continue
                
                # ëœë“œë§ˆí¬ ê¸°ë°˜ ì„ë² ë”© ì¶”ì¶œ (FastIndustrialRecognizer + AdaFace)
                embedding = None
                aligned_face_for_rotation = None
                
                try:
                    if kps_for_adaface is not None and fast_recognizer is not None:
                        try:
                            # AdaFace + TTA (Test-Time Augmentation) ì ìš©
                            # ì›ë³¸ + ì¢Œìš°ë°˜ì „ í‰ê· ìœ¼ë¡œ ë” ì•ˆì •ì ì¸ ì„ë² ë”© ìƒì„±
                            embedding, aligned_face_for_rotation = extract_embedding_adaface_tta(
                                fast_recognizer, 
                                augmented_img, 
                                kps_for_adaface, 
                                face_analyzer=None
                            )
                            if embedding is not None:
                                print(f"  âœ… AdaFace+TTA ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ ({aug_label})")
                        except Exception as e:
                            print(f"  âš ï¸ AdaFace+TTA ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            import traceback
                            traceback.print_exc()
                            embedding = None
                            aligned_face_for_rotation = None
                    
                    # ëœë“œë§ˆí¬ê°€ ì—†ëŠ” ê²½ìš° - í’ˆì§ˆ í•„í„° ì ìš© í›„ ìŠ¤í‚µ
                    if embedding is None:
                        fx1, fy1, fx2, fy2 = face_bbox
                        img_h, img_w = augmented_img.shape[:2]
                        fx1 = max(0, fx1)
                        fy1 = max(0, fy1)
                        fx2 = min(img_w, fx2)
                        fy2 = min(img_h, fy2)
                        face_img = augmented_img[fy1:fy2, fx1:fx2]
                        if face_img.size > 0 and is_low_quality(face_img):
                            person_face_detection_stats[person_name]['low_quality'] += 1
                        continue
                            
                except Exception as e:
                    print(f"  âš ï¸ ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                    continue
                
                # embeddingì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ëœ ê²½ìš°ì—ë§Œ ì €ì¥
                if embedding is not None:
                    # face_database ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                    if person_name not in face_database:
                        face_database[person_name] = []
                    face_database[person_name].append(embedding)
                    embedding_count += 1
                    person_face_detection_stats[person_name]['faces_found'] += 1
                    
                    # â­ 90ë„ íšŒì „ ì„ë² ë”© ì¶”ê°€ (ë„˜ì–´ì§„ ì‚¬ëŒ ì¸ì‹ìš©)
                    # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œë§Œ 90ë„ íšŒì „ ì„ë² ë”© ìƒì„± (ì¦ê°• ì´ë¯¸ì§€ì—ì„œëŠ” ìƒëµ)
                    if aug_label == "original" and aligned_face_for_rotation is not None:
                        rotated_embs = extract_rotated_embeddings(fast_recognizer, aligned_face_for_rotation)
                        for rot_emb, rot_label in rotated_embs:
                            face_database[person_name].append(rot_emb)
                            embedding_count += 1
                            print(f"  âœ… 90ë„ íšŒì „ ì„ë² ë”© ì¶”ê°€: {rot_label}")
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬ í›„ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì—¬ë¶€ í™•ì¸
            if not face_found_in_any_augmentation:
                person_face_detection_stats[person_name]['faces_not_found'] += 1
                print(f"  âš ï¸ {person_name}: ì´ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {os.path.basename(image_path)}")

    if new_files_count == 0 and INCREMENTAL_UPDATE:
        print("âœ… ìƒˆë¡œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
        # ê¸°ì¡´ ì¸ë±ìŠ¤ì—ì„œ ì„ë² ë”©ì„ ë¡œë“œí•˜ì—¬ npy íŒŒì¼ ìƒì„±
        if index is not None and index.ntotal > 0:
            print("ê¸°ì¡´ ì¸ë±ìŠ¤ì—ì„œ ì„ë² ë”©ì„ ë¡œë“œí•˜ì—¬ npy íŒŒì¼ ìƒì„± ì¤‘...")
            # ê¸°ì¡´ ì¸ë±ìŠ¤ì˜ ëª¨ë“  ì„ë² ë”© ì¶”ì¶œ
            all_embeddings = index.reconstruct_n(0, index.ntotal)
            all_labels = existing_labels if existing_labels is not None else []
            
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            existing_db = {}
            for i, label in enumerate(all_labels):
                if label not in existing_db:
                    existing_db[label] = []
                existing_db[label].append(all_embeddings[i])
            
            # npy íŒŒì¼ ì €ì¥
            np.save(OUTPUT_EMBEDDINGS, existing_db)
            print(f"âœ… face_embeddings.npy íŒŒì¼ ìƒì„± ì™„ë£Œ: {OUTPUT_EMBEDDINGS}")
        return

    # ì–¼êµ´ ê°ì§€ í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ“Š ì–¼êµ´ ê°ì§€ í†µê³„")
    print("=" * 70)
    for person_name, stats in sorted(person_face_detection_stats.items()):
        total = stats['total_images']
        found = stats['faces_found']
        not_found = stats['faces_not_found']
        low_quality = stats['low_quality']
        success_rate = (found / total * 100) if total > 0 else 0
        status = "âœ…" if found > 0 else "âŒ"
        print(f"{status} {person_name}: ì´ë¯¸ì§€ {total}ê°œ, ì–¼êµ´ ë°œê²¬ {found}ê°œ, ë¯¸ë°œê²¬ {not_found}ê°œ, ì €í’ˆì§ˆ {low_quality}ê°œ (ì„±ê³µë¥ : {success_rate:.1f}%)")
    print("=" * 70 + "\n")

    if not face_database:
        print(f"ì˜¤ë¥˜: ì²˜ë¦¬í•  ìƒˆ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ë””ë²„ê¹… ì •ë³´:")
        print(f"  - ì²˜ë¦¬í•œ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {new_files_count}ê°œ")
        print(f"  - ì„ë² ë”© ì¶”ì¶œ ì„±ê³µ: {embedding_count}ê°œ")
        print(f"  - face_databaseì— ì €ì¥ëœ ì¸ë¬¼ ìˆ˜: {len(face_database)}ëª…")
        if new_files_count > 0 and embedding_count == 0:
            print(f"  âš ï¸ ì´ë¯¸ì§€ëŠ” ì²˜ë¦¬ë˜ì—ˆì§€ë§Œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print(f"     ì´ë¯¸ì§€ í’ˆì§ˆì´ë‚˜ ì–¼êµ´ì´ ëª…í™•í•˜ê²Œ ë³´ì´ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # ëŒ€í‘œ ì„ë² ë”©(ì„¼íŠ¸ë¡œì´ë“œ) ìƒì„±ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ ë° ë…¸ì´ì¦ˆ ê°ì†Œ
    if USE_REPRESENTATIVE_EMBEDDING:
        refined_database = {}
        for name, embeddings in face_database.items():
            if not embeddings:
                continue
            embs = np.array(embeddings, dtype=np.float32)
            # L2 ì •ê·œí™” ì¬í™•ì¸
            norms = np.linalg.norm(embs, axis=1, keepdims=True)
            norms[norms == 0] = 1.0
            embs = embs / norms

            # ì„¼íŠ¸ë¡œì´ë“œ ê³„ì‚° ë° ì •ê·œí™”
            centroid = embs.mean(axis=0)
            c_norm = np.linalg.norm(centroid)
            if c_norm > 0:
                centroid = centroid / c_norm

            if STORE_CENTROID_ONLY:
                refined_database[name] = [centroid]
            else:
                # ì„¼íŠ¸ë¡œì´ë“œì™€ì˜ ìœ ì‚¬ë„ ê¸°ì¤€ ìƒìœ„ Nê°œ + ì„¼íŠ¸ë¡œì´ë“œ
                sims = embs @ centroid.astype(np.float32)
                top_idx = np.argsort(-sims)[:TOP_N_PER_PERSON]
                top_embs = embs[top_idx].tolist()
                refined_database[name] = [centroid] + top_embs
        face_database = refined_database

    # Faiss ì¸ë±ìŠ¤ êµ¬ì¶•/ì—…ë°ì´íŠ¸ ë¡œì§
    print("DB êµ¬ì¶• ì™„ë£Œ. Faiss ì¸ë±ìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
    labels_list = []
    embeddings_list = []

    # ë”•ì…”ë„ˆë¦¬ë¥¼ Faissê°€ ì‚¬ìš©í•  ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    for name, embeddings in face_database.items():
        for embedding in embeddings:
            labels_list.append(name)
            embeddings_list.append(embedding)

    if not embeddings_list:
        print("ì˜¤ë¥˜: ì¶”ì¶œëœ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì„ë² ë”© ë°°ì—´ ì •ê·œí™” (ëª¨ë“  ì„ë² ë”©ì„ 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜)
    normalized_embeddings = []
    for emb in embeddings_list:
        if emb is None:
            continue
        emb = np.array(emb, dtype=np.float32)
        # 1ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜ (512,)
        if emb.ndim > 1:
            emb = emb.flatten()
        # ì°¨ì› í™•ì¸ (512ì°¨ì›)
        if emb.shape[0] != 512:
            print(f"âš ï¸ ì„ë² ë”© ì°¨ì› ì˜¤ë¥˜: {emb.shape}, ê±´ë„ˆëœ€")
            continue
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(emb)
        if norm > 0:
            emb = emb / norm
        normalized_embeddings.append(emb)
    
    if not normalized_embeddings:
        print("ì˜¤ë¥˜: ìœ íš¨í•œ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    embeddings_array = np.array(normalized_embeddings).astype('float32')
    labels_array = np.array(labels_list)
    
    # shape í™•ì¸ ë° ìˆ˜ì •
    if embeddings_array.ndim == 1:
        # 1ì°¨ì› ë°°ì—´ì¸ ê²½ìš° (512,) -> (1, 512)ë¡œ ë³€í™˜
        embeddings_array = embeddings_array.reshape(1, -1)
    elif embeddings_array.ndim > 2:
        # 3ì°¨ì› ì´ìƒì¸ ê²½ìš° í‰íƒ„í™”
        embeddings_array = embeddings_array.reshape(len(normalized_embeddings), -1)
    
    d = embeddings_array.shape[1]  # ì„ë² ë”© ì°¨ì› (512)

    # ì¸ë±ìŠ¤ ì²˜ë¦¬
    if index is None:
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
        print("ìƒˆ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        index = faiss.IndexFlatIP(d)
        index.add(embeddings_array)
        final_labels = labels_array
    else:
        # ê¸°ì¡´ ì¸ë±ìŠ¤ì— ì¶”ê°€
        print(f"ê¸°ì¡´ ì¸ë±ìŠ¤ì— {len(embeddings_list)}ê°œ ì„ë² ë”© ì¶”ê°€ ì¤‘...")
        index.add(embeddings_array)
        
        # ë¼ë²¨ ë³‘í•©
        final_labels = np.concatenate([existing_labels, labels_array])
    
    # Faiss ì¸ë±ìŠ¤ì™€ ë¼ë²¨ ë°°ì—´ ì €ì¥ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì €ì¥)
    print(f"ğŸ’¾ FAISS ì¸ë±ìŠ¤ ì €ì¥ ì¤‘: {FAISS_INDEX_FILE}")
    print(f"ğŸ’¾ FAISS ë ˆì´ë¸” ì €ì¥ ì¤‘: {FAISS_LABELS_FILE}")
    faiss.write_index(index, FAISS_INDEX_FILE)
    np.save(FAISS_LABELS_FILE, final_labels)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: face/data í´ë”ì— ì €ì¥ë¨")
    
    # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ëª©ë¡ ì—…ë°ì´íŠ¸
    update_processed_images(new_image_paths)

    # ê¸°ì¡´ .npy ì €ì¥ (ë°±ì—…ìš©)
    if os.path.exists(OUTPUT_EMBEDDINGS):
        existing_db = np.load(OUTPUT_EMBEDDINGS, allow_pickle=True).item()
    else:
        existing_db = {}
    
    # ìƒˆë¡œìš´ ë°ì´í„° ë³‘í•©
    for name, embeddings in face_database.items():
        if name not in existing_db:
            existing_db[name] = []
        existing_db[name].extend(embeddings)
    
    np.save(OUTPUT_EMBEDDINGS, existing_db)

    end_time = time.time()
    print("-" * 30)
    print("âœ… Faiss ì¸ë±ìŠ¤ ë° ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ì²˜ë¦¬í•œ ìƒˆ ì´ë¯¸ì§€ ìˆ˜: {new_files_count}ê°œ")
    print(f"ìƒˆë¡œ ì¶”ê°€ëœ ì¸ë¬¼ ìˆ˜: {len(face_database)}ëª…")
    print(f"ìƒˆë¡œ ì¶”ê°€ëœ ì„ë² ë”© ìˆ˜ (ì¦ê°• í¬í•¨): {len(labels_list)}ê°œ")
    print(f"ì¸ë±ìŠ¤ ì´ ì„ë² ë”© ìˆ˜: {index.ntotal}ê°œ")
    print(f"ì¸ë±ìŠ¤ ì´ ì¸ë¬¼ ìˆ˜: {len(np.unique(final_labels))}ëª…")
    print(f"ì €ì¥ëœ ì¸ë±ìŠ¤: {FAISS_INDEX_FILE}")
    print(f"ì €ì¥ëœ ë¼ë²¨: {FAISS_LABELS_FILE}")
    print(f"(ì°¸ê³ ìš©) ì›ë³¸ DB: {OUTPUT_EMBEDDINGS}")
    print("-" * 30)


if __name__ == "__main__":
    build_database()